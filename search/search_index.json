{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ECE 2400 / ENGRD 2140 Computer Systems Programming Docs Public Course Website: http://www.csl.cornell.edu/courses/ece2400 This is the ECE 2400 / ENGRD 2140 Computer Systems Programming documentation site. It includes topic notes, discussion section handouts, tutorials, and programming assignment handouts. If you find any bugs or errors with this documentation, please post on Piazza or feel free to create a pull request in the corresponding documentation repo .","title":"Home"},{"location":"#ece-2400-engrd-2140-computer-systems-programming-docs","text":"Public Course Website: http://www.csl.cornell.edu/courses/ece2400 This is the ECE 2400 / ENGRD 2140 Computer Systems Programming documentation site. It includes topic notes, discussion section handouts, tutorials, and programming assignment handouts. If you find any bugs or errors with this documentation, please post on Piazza or feel free to create a pull request in the corresponding documentation repo .","title":"ECE 2400 / ENGRD 2140 Computer Systems Programming Docs"},{"location":"ece2400-T01-intro-c-notes/","text":"Topic 1: Introduction to C The first few programming assignments for this course will use the C programming language. This tutorial begins by briefly reviewing the basics of C functions, conditional statements, and iteration statements. The tutorial then discusses the C preprocessor before describing how to compile and execute both single-file and multi-file C programs using the command line. All of the tools are installed and available on the ecelinux machines. This tutorial assumes that students have completed the Linux and Git tutorials. We strongly recommend students also read Chapters 1-6 in the course text book, ``All of Programming,'' by A. Hilton and A. Bracy (2015). Chapters 5-6 are particularly relevant since they discuss the general process of compiling, testing, and debugging C programs. To follow along with the tutorial, access the course computing resources, and type the commands without the % character (for the bash prompt). In addition to working through the commands in the tutorial, you should also try the more open-ended tasks marked To-Do On Your Own . Before you begin, make sure that you have sourced the setup-ece2400.sh script or that you have added it to your .bashrc script, which will then source the script every time you login. Sourcing the setup script sets up the environment required for this class. You should start by forking the tutorial repository on GitHub. Go to the GitHub page for the tutorial repository located here: https://github.com/cornell-ece2400/ece2400-tut3-c . Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a new repository in your account: https://github.com/ githubid /ece2400-tut3-c Where githubid is your GitHub username on github.com . Now access an ecelinux machine and clone your copy of the tutorial repository as follows: 1 2 3 4 5 6 % source setup-ece2400.sh % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone https://github.com/ githubid /ece2400-tut3-c.git tut3 % cd tut3 % TUTROOT = ${ PWD } Note It should be possible to experiment with this tutorial even if you are not enrolled in the course and/or do not have access to the course computing resources. All of the code for the tutorial is located on GitHub. You will not use the setup-ece2400.sh script, and your specific environment may be different from what is assumed in this tutorial. 1. C Basics C is a programming language that has a long history of use in computer systems programming . Computer systems programming involves developing software to connect the low-level computer hardware to high-level, user-facing application software and usually requires careful consideration of performance and resource constraints. Examples of computer systems software include compilers, operating systems, databases, numerical libraries, and embedded controllers. C was developed in the early 1970s at Bell Laboratories by Ken Thompson, Dennis Ritchie, and many others. C was originally developed for the purposes of writing an early version of the Unix operating system. The Linux operating system which you learned about in the first tutorial was inspired by these original versions of Unix, and the Linux kernel is also written in C. C provides a nice balance between high-level abstractions for productive software development and low-level control over the hardware, and thus it remains one of the primary languages chosen by computer systems programmers. In this section, we will briefly review some of the basic syntax and semantics of C. 1.1. Using Compiler Explorer and Repl.it to Experiment with C Programs Compiling a C program can be challenging, since it usually involves multiple command line tools and steps. So to get started, we will be using two online tools which will enable us to quickly experiment with small C programs. Later in the tutorial, we will see how to compile, build, test, debug, and evaluate both small and large C programs on the ecelinux machines. The first online tool is called Compiler Explorer, and it is accessed through the following link: https://godbolt.org . You can enter simple C functions in the left text box, and then Compiler Explorer will display the corresponding machine instructions (i.e., assembly code) in the right text box. This is a great way to quickly use your browser to see the connection between C programs and the low-level computer hardware. Compiler Explorer color codes the C program and the machine instructions, so it is possible to see which C statements compile into which machine instructions. There is a drop-down menu to choose different compilers. Choosing x86-64 gcc 7.2 roughly corresponds to the compiler we will be using on the ecelinux machines which is based on the Intel x86-64 instruction set. Choosing MIPS gcc 5.4 (el) roughly corresponds to the compiler used in ECE 2300 which is based on the MIPS instruction set. There is also a text box where you can enter various compiler command line options. The second online tool is called Repl.it, and it is accessed through the following link: http://repl.it . You can create a new \"repl\" by choosing the C programming language. You can enter simple C programs in the left text box. Clicking on the run button will first compile the C program into an executable binary, and then run this executable binary. This is a great way to quickly experiment with C programs in your browser. The output of running the program is shown in the right text box. C Functions The definition for a simple function to calculate the average of two integers is shown below. 1 2 3 4 5 int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } A C function definition specifies a named parameterized sequence of statements. C function definitions have four parts: a function name (e.g., avg on Line 1; a function parameter list (e.g., int x, int y on Line 1); a function return type (e.g., int at the beginning of Line 1); and the function body (e.g. Lines 2-5). In this tutorial, we will only use the int type for variables, but the C language supports a rich selection of different types for representing integer numbers, real numbers, characters, pointers, and composite structures. A function creates a new block and all variable declarations within the function are local to that scope. Line 3 is a variable initialization statement which first creates a new variable of type int named sum and then initializes this variable with the value of the expression x+y . Remember that all C statements end in a semicolon ( ; ). Line 4 is a return statement which causes the function to return the value of the corresponding expression (e.g., sum/2 ). Calling a C function involves setting the parameters in the parameter list, executing the sequence of statements in the function body, and then returning the return value. A C function call is just another kind of expression which evaluates to the function's return value. Enter the avg function into Compiler Explorer and take a look at the corresponding machine instructions for the Intel x86-64 instruction set. The avg function compiles to 15 machine instructions. In this course, you are not responsible for understanding these machine instructions, but it is still very important to recognize that C programs usually map relatively directly to machine instructions. Notice that the statement on Line 3 maps to four machine instructions (the C statement and the machine instructions are all colored yellow) including an add instruction. If you right click on one of the Intel x86-64 machine instructions and choose View Asm Doc , Compiler Explorer will display a detailed description of that machine instruction. Try finding out more about the add instruction. This instruction directly corresponds to the + operator in the avg function; this direct mapping from high-level syntax to low-level machine instructions is one of the key features of C. The + operator in a language such as Python or MATLAB would eventually correspond to hundreds of machine instructions! Enter -O3 into the Compiler options... text box and press return. This option tells the compiler to apply various optimizations to improve the performance of the compiled machine instructions. The avg function now compiles to six machine instructions, and we can see that Line 3 now maps to a single machine instruction (the C statement and the machine instruction are both are colored green). Even without understanding the details of these machine instructions, it should be obvious that reducing the number of machine instructions from 15 to six should improve performance. The definition for a simple main function to call the avg function and then print its result is shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include stdio.h int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } int main () { int a = 10 ; int b = 20 ; int c = avg ( a , b ); printf ( average of %d and %d is %d \\n , a , b , c , ); return 0 ; } Recall that the main function is special. The main function is always where program execution starts; in other words, the main function is always the first function to be called in any C program. Lines 11-13 are variable initialization statements. Line 13 calls the avg function with the values in variables a and b , and then the return value is used to initialize variable c . Line 14 calls the printf function to display text on the screen. The printf function is defined in the C standard library which is usually included along with every C compiler. More specifically, the printf function declaration is in a separate header file which is included on Line 1 using the C preprocessor. We will learn more about the C preprocessor later in this tutorial. The printf function always takes a format string as the first parameter, and then takes a variable number of parameters that are evaluated and substituted into the format string. The format string includes format specifiers (i.e., special codes) to indicate where to substitute these values. In this example, we are using the %d format specifier to indicate that we would like to substitute an integer into the format string. The format string can also include other special codes; for example, this format string includes a newline special code ( \\n ) which results in a line break. The return value of the main function is used as the exit status of the program; this is a way for a C program to tell the operating system whether or not the program ended successfully (by returning zero) or something went wrong (by returning a non-zero value). Enter the avg and main functions into Repl.it and then use the run button to compile and execute this C program. Try initializing a to 10 and b to 15. The average of these two integers is 12.5, but our program currently does not support arithmetic on non-integer values. In this case, the division operator (i.e., / ) truncates the result by always rounding towards zero. Quickly experimenting with small C programs can help illustrate subtle issues in C syntax and semantics. Question Write a simple function named avg3 to average three integers. Use Compiler Explorer to examine the corresponding machine instructions and identify how the + operators in the C program maps to add machine instructions. Use Repl.it to compile and execute a program with the avg3 function and a main function to call the average function and print its result. Experiment with averaging negative numbers, especially negative numbers where ideally the result would not be an integer (e.g., -7 , -5 , and -4 ). Problem 1.1: Writing an avg3 function Here is a programming question","title":"ece2400 T01 intro c notes"},{"location":"ece2400-T01-intro-c-notes/#topic-1-introduction-to-c","text":"The first few programming assignments for this course will use the C programming language. This tutorial begins by briefly reviewing the basics of C functions, conditional statements, and iteration statements. The tutorial then discusses the C preprocessor before describing how to compile and execute both single-file and multi-file C programs using the command line. All of the tools are installed and available on the ecelinux machines. This tutorial assumes that students have completed the Linux and Git tutorials. We strongly recommend students also read Chapters 1-6 in the course text book, ``All of Programming,'' by A. Hilton and A. Bracy (2015). Chapters 5-6 are particularly relevant since they discuss the general process of compiling, testing, and debugging C programs. To follow along with the tutorial, access the course computing resources, and type the commands without the % character (for the bash prompt). In addition to working through the commands in the tutorial, you should also try the more open-ended tasks marked To-Do On Your Own . Before you begin, make sure that you have sourced the setup-ece2400.sh script or that you have added it to your .bashrc script, which will then source the script every time you login. Sourcing the setup script sets up the environment required for this class. You should start by forking the tutorial repository on GitHub. Go to the GitHub page for the tutorial repository located here: https://github.com/cornell-ece2400/ece2400-tut3-c . Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a new repository in your account: https://github.com/ githubid /ece2400-tut3-c Where githubid is your GitHub username on github.com . Now access an ecelinux machine and clone your copy of the tutorial repository as follows: 1 2 3 4 5 6 % source setup-ece2400.sh % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone https://github.com/ githubid /ece2400-tut3-c.git tut3 % cd tut3 % TUTROOT = ${ PWD } Note It should be possible to experiment with this tutorial even if you are not enrolled in the course and/or do not have access to the course computing resources. All of the code for the tutorial is located on GitHub. You will not use the setup-ece2400.sh script, and your specific environment may be different from what is assumed in this tutorial.","title":"Topic 1: Introduction to C"},{"location":"ece2400-T01-intro-c-notes/#1-c-basics","text":"C is a programming language that has a long history of use in computer systems programming . Computer systems programming involves developing software to connect the low-level computer hardware to high-level, user-facing application software and usually requires careful consideration of performance and resource constraints. Examples of computer systems software include compilers, operating systems, databases, numerical libraries, and embedded controllers. C was developed in the early 1970s at Bell Laboratories by Ken Thompson, Dennis Ritchie, and many others. C was originally developed for the purposes of writing an early version of the Unix operating system. The Linux operating system which you learned about in the first tutorial was inspired by these original versions of Unix, and the Linux kernel is also written in C. C provides a nice balance between high-level abstractions for productive software development and low-level control over the hardware, and thus it remains one of the primary languages chosen by computer systems programmers. In this section, we will briefly review some of the basic syntax and semantics of C.","title":"1. C Basics"},{"location":"ece2400-T01-intro-c-notes/#11-using-compiler-explorer-and-replit-to-experiment-with-c-programs","text":"Compiling a C program can be challenging, since it usually involves multiple command line tools and steps. So to get started, we will be using two online tools which will enable us to quickly experiment with small C programs. Later in the tutorial, we will see how to compile, build, test, debug, and evaluate both small and large C programs on the ecelinux machines. The first online tool is called Compiler Explorer, and it is accessed through the following link: https://godbolt.org . You can enter simple C functions in the left text box, and then Compiler Explorer will display the corresponding machine instructions (i.e., assembly code) in the right text box. This is a great way to quickly use your browser to see the connection between C programs and the low-level computer hardware. Compiler Explorer color codes the C program and the machine instructions, so it is possible to see which C statements compile into which machine instructions. There is a drop-down menu to choose different compilers. Choosing x86-64 gcc 7.2 roughly corresponds to the compiler we will be using on the ecelinux machines which is based on the Intel x86-64 instruction set. Choosing MIPS gcc 5.4 (el) roughly corresponds to the compiler used in ECE 2300 which is based on the MIPS instruction set. There is also a text box where you can enter various compiler command line options. The second online tool is called Repl.it, and it is accessed through the following link: http://repl.it . You can create a new \"repl\" by choosing the C programming language. You can enter simple C programs in the left text box. Clicking on the run button will first compile the C program into an executable binary, and then run this executable binary. This is a great way to quickly experiment with C programs in your browser. The output of running the program is shown in the right text box.","title":"1.1. Using Compiler Explorer and Repl.it to Experiment with C Programs"},{"location":"ece2400-T01-intro-c-notes/#c-functions","text":"The definition for a simple function to calculate the average of two integers is shown below. 1 2 3 4 5 int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } A C function definition specifies a named parameterized sequence of statements. C function definitions have four parts: a function name (e.g., avg on Line 1; a function parameter list (e.g., int x, int y on Line 1); a function return type (e.g., int at the beginning of Line 1); and the function body (e.g. Lines 2-5). In this tutorial, we will only use the int type for variables, but the C language supports a rich selection of different types for representing integer numbers, real numbers, characters, pointers, and composite structures. A function creates a new block and all variable declarations within the function are local to that scope. Line 3 is a variable initialization statement which first creates a new variable of type int named sum and then initializes this variable with the value of the expression x+y . Remember that all C statements end in a semicolon ( ; ). Line 4 is a return statement which causes the function to return the value of the corresponding expression (e.g., sum/2 ). Calling a C function involves setting the parameters in the parameter list, executing the sequence of statements in the function body, and then returning the return value. A C function call is just another kind of expression which evaluates to the function's return value. Enter the avg function into Compiler Explorer and take a look at the corresponding machine instructions for the Intel x86-64 instruction set. The avg function compiles to 15 machine instructions. In this course, you are not responsible for understanding these machine instructions, but it is still very important to recognize that C programs usually map relatively directly to machine instructions. Notice that the statement on Line 3 maps to four machine instructions (the C statement and the machine instructions are all colored yellow) including an add instruction. If you right click on one of the Intel x86-64 machine instructions and choose View Asm Doc , Compiler Explorer will display a detailed description of that machine instruction. Try finding out more about the add instruction. This instruction directly corresponds to the + operator in the avg function; this direct mapping from high-level syntax to low-level machine instructions is one of the key features of C. The + operator in a language such as Python or MATLAB would eventually correspond to hundreds of machine instructions! Enter -O3 into the Compiler options... text box and press return. This option tells the compiler to apply various optimizations to improve the performance of the compiled machine instructions. The avg function now compiles to six machine instructions, and we can see that Line 3 now maps to a single machine instruction (the C statement and the machine instruction are both are colored green). Even without understanding the details of these machine instructions, it should be obvious that reducing the number of machine instructions from 15 to six should improve performance. The definition for a simple main function to call the avg function and then print its result is shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include stdio.h int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } int main () { int a = 10 ; int b = 20 ; int c = avg ( a , b ); printf ( average of %d and %d is %d \\n , a , b , c , ); return 0 ; } Recall that the main function is special. The main function is always where program execution starts; in other words, the main function is always the first function to be called in any C program. Lines 11-13 are variable initialization statements. Line 13 calls the avg function with the values in variables a and b , and then the return value is used to initialize variable c . Line 14 calls the printf function to display text on the screen. The printf function is defined in the C standard library which is usually included along with every C compiler. More specifically, the printf function declaration is in a separate header file which is included on Line 1 using the C preprocessor. We will learn more about the C preprocessor later in this tutorial. The printf function always takes a format string as the first parameter, and then takes a variable number of parameters that are evaluated and substituted into the format string. The format string includes format specifiers (i.e., special codes) to indicate where to substitute these values. In this example, we are using the %d format specifier to indicate that we would like to substitute an integer into the format string. The format string can also include other special codes; for example, this format string includes a newline special code ( \\n ) which results in a line break. The return value of the main function is used as the exit status of the program; this is a way for a C program to tell the operating system whether or not the program ended successfully (by returning zero) or something went wrong (by returning a non-zero value). Enter the avg and main functions into Repl.it and then use the run button to compile and execute this C program. Try initializing a to 10 and b to 15. The average of these two integers is 12.5, but our program currently does not support arithmetic on non-integer values. In this case, the division operator (i.e., / ) truncates the result by always rounding towards zero. Quickly experimenting with small C programs can help illustrate subtle issues in C syntax and semantics. Question Write a simple function named avg3 to average three integers. Use Compiler Explorer to examine the corresponding machine instructions and identify how the + operators in the C program maps to add machine instructions. Use Repl.it to compile and execute a program with the avg3 function and a main function to call the average function and print its result. Experiment with averaging negative numbers, especially negative numbers where ideally the result would not be an integer (e.g., -7 , -5 , and -4 ). Problem 1.1: Writing an avg3 function Here is a programming question","title":"C Functions"},{"location":"ece2400-coding-conventions/","text":"Coding Conventions Any significant programming project will usually require developers to use a standardized set of coding conventions. These conventions might be set by a company, the leaders of an open-source project, or simply through historical precedent. Standardized coding conventions enable code written by multiple developers to be consistent and improves readability, maintainability, and extensibility. We have developed a simple set of coding conventions for ECE 2400 that we would like you to use in all programming assignments. Keep in mind that these are just guidelines, and there may be situations where it is appropriate to defy a convention if this ultimately improves the overall code quality. Note that some of these conventions have been adapted from the Google C++ Style Guide . In general, anything not covered by the guidelines in this document should assume the Google style guide. 1. Directories and Files This section discusses the physical structure of how files should be organized in a project. 1.1. Directories All header, inline, data, and source files should be in a single src directory. All tests should be a in a single tests directory. Anything other than ad-hoc testing should always be done in a separate build directory. 1.2. File Names Files should be named in all lowercase and should use a dash ( - ) to separate words. C source files should use the .c filename extension, and C++ source files should use the .cc filename extension. Header files should use the .h filename extension, and inline files should use the .inl filename extension. Data files that contain C/C++ code and are meant to be included using the C preprocessor should use the .dat filename extension. All test programs should end in -test.c . All evaluation programs should end in -eval.c . 1.3. Header and Inline Files All header files should be self-contained. A header should include all other headers it needs. The definitions for template and inline functions should be placed in a separate .inl file and included at the end of the header. Every header should use include guards where the name of the include guard preprocessor macro is derived directly from the filename. For example, a header file named foo-bar.h would use the following include guards: 1 2 3 4 #ifndef FOO_BAR_H #define FOO_BAR_H #endif // FOO_BAR_H 2. Formatting This section discusses general formatting that is common across all kinds of files. 2.1. Line Length Lines in all files should in general be less than 80 characters. Using less than 74 characters is ideal since this is a natural width that enables reasonable font sizes to be used when using side-by-side code development with two listings on modern laptops and side-by-side code development with three to four listings on 24\" to 27\" monitors. Lines longer than 80 characters should be avoided unless there is a compelling reason to use longer lines to increase code quality. 2.2. Indentation Absolutely no tabs are allowed. Only spaces are allowed for the purposes of indentation. The standard number of spaces per level of indentation is two. Here is an example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int gcd ( int x , int y ) { while ( y != 0 ) { if ( x y ) { int temp = x ; y = temp ; x = y ; } else { x = x - y ; } } return x ; } 2.3. Vertical Whitespace Vertical whitspace can and should be used to separate conceptually distinct portions of your code. A blank line within a block of code serves like a paragraph break in prose: visually separating two thoughts. Vertical whitespace should be limited to a single blank line. Do not use two or more blank lines in a row. Do not include a blank line at the beginning and end of the function body in a function definition. So this is incorrect: 1 2 3 4 5 6 7 int foo () { stmt1 ; return 0 ; } This is correct: 1 2 3 4 5 int foo () { stmt1 ; return 0 ; } 2.4. Horizontal Whitespace Absolutely no tabs are allowed. Only spaces are allowed for the purposes of indentation. The standard number of spaces per level of indentation is two. In general, horizontal whitespace should be used to separate distinct conceptual \"tokens\". Do not cram all of the characters in an expression together without any horizontal whitespace. There should be white space around binary operators. Here is an example: 1 2 int a = b * c ; // incorrect int a = b * c ; // correct Use explicit parenthesis to make operator precendence explicit: 1 2 int a = a 0 b != 0 ; // incorrect int a = ( ( a 0 ) ( b != 0 ) ); // correct 2.5. Variable Declarations There should be whitespace around the assignment operator. Here is an example: 1 2 int a = 3 ; // incorrect int a = 3 ; // correct If possible, consder vertically aligning the variable names and assignment operators for related variables: 1 2 unsigned int a = 32 ; int * a_ptr = a ; Never declare multiple variables in a single statement. Always use multiple statements. Here is an example: 1 2 3 int a , b ; // incorrect int a ; // correct int b ; // correct 2.6. Conditional Statements if conditional statements should look like this: 1 2 3 4 5 6 7 8 9 if ( conditional_expression0 ) { statement0 ; } else if ( conditional_expression1 ) { statement1 ; } else { statement2 ; } Notice the use of spaces inside the parentheses since the () tokens should be conceptually separated from the conditional expression. If you use curly braces for one part of an if/then/else statement you must use them for all parts of the statement. Avoid single line if statements: 1 2 3 if ( conditional_expression0 ) return 1 ; // incorrect if ( conditional_expression0 ) // correct return 0 ; // correct 2.7. Iteration Statements for loops should look like this: 1 2 3 for ( int i = 0 ; i size ; i ++ ) { loop_body ; } Notice the extra horizontal whitespace used to separate the parentheses from the initialization statement and the increment statement. The open curly brace should be on the same line as the for statement. 2.8. Function Definitions Function definitions should look like this: 1 2 3 4 int foo_bar ( int a , int b ) { function_body ; } Insert space inside the parenthesis. Notice that for functions the open curly brace goes on its own line. Do not insert a space between the function name and the open parenthesis. So this is incorrect: 1 2 3 4 5 // incorrect int foo_bar ( int a , int b ) { function_body ; } 2.9. Function Calls Function calls should usually use whitespace inside the parenthesis. For example: 1 int result = gcd ( 10 , 15 ); If there is a single parameter, sometimes it may be more appropriate to eliminate the whitespace inside the parenthesis. 3. Naming 3.1. Type Names For C programs, the names of user-defined types should usually be all lowercase, use underscores ( _ ) to separate words, and use a _t suffix. 1 typedef unsigned int uint_t ; For C++ programs, the names of user-defined types should usually use CamelCase. 1 2 3 4 class FooBar { ... }; When specifying pointer types, the * should be placed with the type without whitespace: 1 2 3 int * a_ptr ; // incorrect int * a_ptr ; // incorrect int * a_ptr ; // correct As a reminder, never declare multiple variables in a single statement. This is never allowed: 1 int *a_ptr, *b_ptr; // not allowed! 3.2. Variable Names The names of variables should always be all lowercase with underscores ( _ ) to separate words. Do not use CamelCase for variable names. For pointers, use a _ptr or _p suffix. For data member fields, use a m_ prefix. While single letter variable names are common in the lecture examples, single letter variable names should be very rare in real code. 3.3. Function/Method Names The names of free functions and methods should always be all lowercase with underscores ( _ ) to separate words. Do not use CamelCase for function or method names. 4. Comments Though a pain to write, comments are absolutely vital to keeping our code readable. The following rules describe what you should comment and where. But remember: while comments are very important, the best code is self-documenting. Giving sensible names to types and variables is much better than using obscure names that you must then explain through comments. When writing your comments, write for your audience: the next contributor who will need to understand your code. Be generous \u2014 the next one may be you! Do not state the obvious. In particular, don't literally describe what code does, unless the behavior is nonobvious to a reader who understands C/C++ well. Instead, provide higher level comments that describe why the code does what it does, or make the code self describing. 4.1. Comment Style Use // comments. These are perfectly acceptable now in C99. Do not use the older /* */ comments. Include a space after // before starting your comment: 1 2 //without space, incorrect formatting // with space, correct formatting 4.2. File Comments All files should include a \"title block\". This is a comment at the very beginning of the file which gives the name of the file and a brief description of the purpose and contents of the file. Title blocks should use the following format: 1 2 3 4 //========================================================================= // foo-bar.h //========================================================================= // Description of the purpose and contents of this file. The horizontal lines used in the title block should extend exactly 74 characters (i.e., two '/' characters and 72 = characters). You do not need to duplicate comments between the .h and .cc . Often the header will have a description of the interface, and the source file will discuss the broad implementation approach. 4.3. Function Comments Almost every function declaration in the header should have comments immediately preceding it that describe what the function does and how to use it. These comments may be omitted only if the function is simple and obvious. These comments should be descriptive (\"Opens the file\") rather than imperative (\"Open the file\"); the comment describes the function, it does not tell the function what to do. In general, these comments do not describe how the function performs its task. Instead, that should be left to comments in the function definition. Every function definition in the source file should have a comment like this: 1 2 3 4 //------------------------------------------------------------------------ // foo_bar() //------------------------------------------------------------------------ // optional high-level discussion of implementation approach 4.4. Old Comments Do not leave old comments in the source file. So you must remove comments that were provided by the instructors. 5. Scoping This section discusses use of local and global variables. 5.1. Local Variables Place a function's variables in the narrowest scope possible. C99 no longer requires all variables to be declared at the beginning of a function, so declare functions close to where they are initialized. 5.2. Static and Global Variables Do not use non-const static or global variables unless there is a very good reason to do so. Const global variables are allowed and should definitely be used instead of preprocessor defines. 6. C Pre-processor Using the C pre-processor should be avoided. Use of the C pre-processor should usually be limited to include guards and the UTST macros. When the C pre-processor must be used, pre-processor macro names should be in all capital letters and use an underscore ( _ ) to separate words. Do not use the C pre-processor to declare global constants. Use const global variables instead. 7. Examples Here is an example of an incorrectly formatted for loop: 1 2 3 for ( int i = 0 ; i n ; i ++ ){ a += c ; } There should be a space inside the parenthesis and no space between i and ++ . There should be a space after the closing parenthesis and the open curly brace. Here is the same code formatted correctly: 1 2 3 for ( int i = 0 ; i n ; i ++ ) { a += c ; } Here is an example of an incorrectly formatted if statement: 1 2 3 4 5 6 if ( a 0 b != 0 ){ c = 1 / c ; } else ( x % 2 == 0 ){ ... } There should be a space inside the parenthesis and we need extra parenthesis to make the operator precedence more explicit. We also need a space between the closing parenthesis and the open curly brace. 1 2 3 4 5 6 if ( ( a 0 ) ( b != 0 ) ) { c = 1 / c ; } else ( ( x % 2 ) == 0 ) { ... } Once we have multiple levels of nested parenthesis, it might be more readable to do something like this: 1 2 3 4 5 6 if ( ( a 0 ) ( b != 0 ) ) { c = 1 / c ; } else ( ( x % 2 ) == 0 ) { ... } Here is an example of a poorly formatted return statement: 1 2 3 4 5 6 void foo () { ... return bar ( x ) * bar ( y ); } Indentation should be used to make this more clear: 1 2 3 4 5 6 void foo () { ... return bar ( x ) * bar ( y ); } This code does not include spaces around the assignment operator, and isn't even consistent in its formatting: 1 2 3 double foo = b ; int c = bar ; double e = 1 ; This should look like this: 1 2 3 double foo = b ; int c = bar ; double e = 1 ; Notice how we lined up the variable names and the assignment operators vertically. Here is an example of incorrectly formatted code: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int gcd ( int x , int y ){ while ( y != 0 ) { if ( x y ){ int t = x ; x = temp ; x = y ; } else x = x - y ; } return x ; } Here is an example of correctly formatted code: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //------------------------------------------------------------------------ // gcd() //------------------------------------------------------------------------ int gcd ( int x , int y ) { // iterate until GCD is found while ( y != 0 ) { if ( x y ) { // swap x and y int temp = x ; y = temp ; x = y ; } else { x = x - y ; } } return x ; }","title":"Ece2400 coding conventions"},{"location":"ece2400-coding-conventions/#coding-conventions","text":"Any significant programming project will usually require developers to use a standardized set of coding conventions. These conventions might be set by a company, the leaders of an open-source project, or simply through historical precedent. Standardized coding conventions enable code written by multiple developers to be consistent and improves readability, maintainability, and extensibility. We have developed a simple set of coding conventions for ECE 2400 that we would like you to use in all programming assignments. Keep in mind that these are just guidelines, and there may be situations where it is appropriate to defy a convention if this ultimately improves the overall code quality. Note that some of these conventions have been adapted from the Google C++ Style Guide . In general, anything not covered by the guidelines in this document should assume the Google style guide.","title":"Coding Conventions"},{"location":"ece2400-coding-conventions/#1-directories-and-files","text":"This section discusses the physical structure of how files should be organized in a project.","title":"1. Directories and Files"},{"location":"ece2400-coding-conventions/#11-directories","text":"All header, inline, data, and source files should be in a single src directory. All tests should be a in a single tests directory. Anything other than ad-hoc testing should always be done in a separate build directory.","title":"1.1. Directories"},{"location":"ece2400-coding-conventions/#12-file-names","text":"Files should be named in all lowercase and should use a dash ( - ) to separate words. C source files should use the .c filename extension, and C++ source files should use the .cc filename extension. Header files should use the .h filename extension, and inline files should use the .inl filename extension. Data files that contain C/C++ code and are meant to be included using the C preprocessor should use the .dat filename extension. All test programs should end in -test.c . All evaluation programs should end in -eval.c .","title":"1.2. File Names"},{"location":"ece2400-coding-conventions/#13-header-and-inline-files","text":"All header files should be self-contained. A header should include all other headers it needs. The definitions for template and inline functions should be placed in a separate .inl file and included at the end of the header. Every header should use include guards where the name of the include guard preprocessor macro is derived directly from the filename. For example, a header file named foo-bar.h would use the following include guards: 1 2 3 4 #ifndef FOO_BAR_H #define FOO_BAR_H #endif // FOO_BAR_H","title":"1.3. Header and Inline Files"},{"location":"ece2400-coding-conventions/#2-formatting","text":"This section discusses general formatting that is common across all kinds of files.","title":"2. Formatting"},{"location":"ece2400-coding-conventions/#21-line-length","text":"Lines in all files should in general be less than 80 characters. Using less than 74 characters is ideal since this is a natural width that enables reasonable font sizes to be used when using side-by-side code development with two listings on modern laptops and side-by-side code development with three to four listings on 24\" to 27\" monitors. Lines longer than 80 characters should be avoided unless there is a compelling reason to use longer lines to increase code quality.","title":"2.1. Line Length"},{"location":"ece2400-coding-conventions/#22-indentation","text":"Absolutely no tabs are allowed. Only spaces are allowed for the purposes of indentation. The standard number of spaces per level of indentation is two. Here is an example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int gcd ( int x , int y ) { while ( y != 0 ) { if ( x y ) { int temp = x ; y = temp ; x = y ; } else { x = x - y ; } } return x ; }","title":"2.2. Indentation"},{"location":"ece2400-coding-conventions/#23-vertical-whitespace","text":"Vertical whitspace can and should be used to separate conceptually distinct portions of your code. A blank line within a block of code serves like a paragraph break in prose: visually separating two thoughts. Vertical whitespace should be limited to a single blank line. Do not use two or more blank lines in a row. Do not include a blank line at the beginning and end of the function body in a function definition. So this is incorrect: 1 2 3 4 5 6 7 int foo () { stmt1 ; return 0 ; } This is correct: 1 2 3 4 5 int foo () { stmt1 ; return 0 ; }","title":"2.3. Vertical Whitespace"},{"location":"ece2400-coding-conventions/#24-horizontal-whitespace","text":"Absolutely no tabs are allowed. Only spaces are allowed for the purposes of indentation. The standard number of spaces per level of indentation is two. In general, horizontal whitespace should be used to separate distinct conceptual \"tokens\". Do not cram all of the characters in an expression together without any horizontal whitespace. There should be white space around binary operators. Here is an example: 1 2 int a = b * c ; // incorrect int a = b * c ; // correct Use explicit parenthesis to make operator precendence explicit: 1 2 int a = a 0 b != 0 ; // incorrect int a = ( ( a 0 ) ( b != 0 ) ); // correct","title":"2.4. Horizontal Whitespace"},{"location":"ece2400-coding-conventions/#25-variable-declarations","text":"There should be whitespace around the assignment operator. Here is an example: 1 2 int a = 3 ; // incorrect int a = 3 ; // correct If possible, consder vertically aligning the variable names and assignment operators for related variables: 1 2 unsigned int a = 32 ; int * a_ptr = a ; Never declare multiple variables in a single statement. Always use multiple statements. Here is an example: 1 2 3 int a , b ; // incorrect int a ; // correct int b ; // correct","title":"2.5. Variable Declarations"},{"location":"ece2400-coding-conventions/#26-conditional-statements","text":"if conditional statements should look like this: 1 2 3 4 5 6 7 8 9 if ( conditional_expression0 ) { statement0 ; } else if ( conditional_expression1 ) { statement1 ; } else { statement2 ; } Notice the use of spaces inside the parentheses since the () tokens should be conceptually separated from the conditional expression. If you use curly braces for one part of an if/then/else statement you must use them for all parts of the statement. Avoid single line if statements: 1 2 3 if ( conditional_expression0 ) return 1 ; // incorrect if ( conditional_expression0 ) // correct return 0 ; // correct","title":"2.6. Conditional Statements"},{"location":"ece2400-coding-conventions/#27-iteration-statements","text":"for loops should look like this: 1 2 3 for ( int i = 0 ; i size ; i ++ ) { loop_body ; } Notice the extra horizontal whitespace used to separate the parentheses from the initialization statement and the increment statement. The open curly brace should be on the same line as the for statement.","title":"2.7. Iteration Statements"},{"location":"ece2400-coding-conventions/#28-function-definitions","text":"Function definitions should look like this: 1 2 3 4 int foo_bar ( int a , int b ) { function_body ; } Insert space inside the parenthesis. Notice that for functions the open curly brace goes on its own line. Do not insert a space between the function name and the open parenthesis. So this is incorrect: 1 2 3 4 5 // incorrect int foo_bar ( int a , int b ) { function_body ; }","title":"2.8. Function Definitions"},{"location":"ece2400-coding-conventions/#29-function-calls","text":"Function calls should usually use whitespace inside the parenthesis. For example: 1 int result = gcd ( 10 , 15 ); If there is a single parameter, sometimes it may be more appropriate to eliminate the whitespace inside the parenthesis.","title":"2.9. Function Calls"},{"location":"ece2400-coding-conventions/#3-naming","text":"","title":"3. Naming"},{"location":"ece2400-coding-conventions/#31-type-names","text":"For C programs, the names of user-defined types should usually be all lowercase, use underscores ( _ ) to separate words, and use a _t suffix. 1 typedef unsigned int uint_t ; For C++ programs, the names of user-defined types should usually use CamelCase. 1 2 3 4 class FooBar { ... }; When specifying pointer types, the * should be placed with the type without whitespace: 1 2 3 int * a_ptr ; // incorrect int * a_ptr ; // incorrect int * a_ptr ; // correct As a reminder, never declare multiple variables in a single statement. This is never allowed: 1 int *a_ptr, *b_ptr; // not allowed!","title":"3.1. Type Names"},{"location":"ece2400-coding-conventions/#32-variable-names","text":"The names of variables should always be all lowercase with underscores ( _ ) to separate words. Do not use CamelCase for variable names. For pointers, use a _ptr or _p suffix. For data member fields, use a m_ prefix. While single letter variable names are common in the lecture examples, single letter variable names should be very rare in real code.","title":"3.2. Variable Names"},{"location":"ece2400-coding-conventions/#33-functionmethod-names","text":"The names of free functions and methods should always be all lowercase with underscores ( _ ) to separate words. Do not use CamelCase for function or method names.","title":"3.3. Function/Method Names"},{"location":"ece2400-coding-conventions/#4-comments","text":"Though a pain to write, comments are absolutely vital to keeping our code readable. The following rules describe what you should comment and where. But remember: while comments are very important, the best code is self-documenting. Giving sensible names to types and variables is much better than using obscure names that you must then explain through comments. When writing your comments, write for your audience: the next contributor who will need to understand your code. Be generous \u2014 the next one may be you! Do not state the obvious. In particular, don't literally describe what code does, unless the behavior is nonobvious to a reader who understands C/C++ well. Instead, provide higher level comments that describe why the code does what it does, or make the code self describing.","title":"4. Comments"},{"location":"ece2400-coding-conventions/#41-comment-style","text":"Use // comments. These are perfectly acceptable now in C99. Do not use the older /* */ comments. Include a space after // before starting your comment: 1 2 //without space, incorrect formatting // with space, correct formatting","title":"4.1. Comment Style"},{"location":"ece2400-coding-conventions/#42-file-comments","text":"All files should include a \"title block\". This is a comment at the very beginning of the file which gives the name of the file and a brief description of the purpose and contents of the file. Title blocks should use the following format: 1 2 3 4 //========================================================================= // foo-bar.h //========================================================================= // Description of the purpose and contents of this file. The horizontal lines used in the title block should extend exactly 74 characters (i.e., two '/' characters and 72 = characters). You do not need to duplicate comments between the .h and .cc . Often the header will have a description of the interface, and the source file will discuss the broad implementation approach.","title":"4.2. File Comments"},{"location":"ece2400-coding-conventions/#43-function-comments","text":"Almost every function declaration in the header should have comments immediately preceding it that describe what the function does and how to use it. These comments may be omitted only if the function is simple and obvious. These comments should be descriptive (\"Opens the file\") rather than imperative (\"Open the file\"); the comment describes the function, it does not tell the function what to do. In general, these comments do not describe how the function performs its task. Instead, that should be left to comments in the function definition. Every function definition in the source file should have a comment like this: 1 2 3 4 //------------------------------------------------------------------------ // foo_bar() //------------------------------------------------------------------------ // optional high-level discussion of implementation approach","title":"4.3. Function Comments"},{"location":"ece2400-coding-conventions/#44-old-comments","text":"Do not leave old comments in the source file. So you must remove comments that were provided by the instructors.","title":"4.4. Old Comments"},{"location":"ece2400-coding-conventions/#5-scoping","text":"This section discusses use of local and global variables.","title":"5. Scoping"},{"location":"ece2400-coding-conventions/#51-local-variables","text":"Place a function's variables in the narrowest scope possible. C99 no longer requires all variables to be declared at the beginning of a function, so declare functions close to where they are initialized.","title":"5.1. Local Variables"},{"location":"ece2400-coding-conventions/#52-static-and-global-variables","text":"Do not use non-const static or global variables unless there is a very good reason to do so. Const global variables are allowed and should definitely be used instead of preprocessor defines.","title":"5.2. Static and Global Variables"},{"location":"ece2400-coding-conventions/#6-c-pre-processor","text":"Using the C pre-processor should be avoided. Use of the C pre-processor should usually be limited to include guards and the UTST macros. When the C pre-processor must be used, pre-processor macro names should be in all capital letters and use an underscore ( _ ) to separate words. Do not use the C pre-processor to declare global constants. Use const global variables instead.","title":"6. C Pre-processor"},{"location":"ece2400-coding-conventions/#7-examples","text":"Here is an example of an incorrectly formatted for loop: 1 2 3 for ( int i = 0 ; i n ; i ++ ){ a += c ; } There should be a space inside the parenthesis and no space between i and ++ . There should be a space after the closing parenthesis and the open curly brace. Here is the same code formatted correctly: 1 2 3 for ( int i = 0 ; i n ; i ++ ) { a += c ; } Here is an example of an incorrectly formatted if statement: 1 2 3 4 5 6 if ( a 0 b != 0 ){ c = 1 / c ; } else ( x % 2 == 0 ){ ... } There should be a space inside the parenthesis and we need extra parenthesis to make the operator precedence more explicit. We also need a space between the closing parenthesis and the open curly brace. 1 2 3 4 5 6 if ( ( a 0 ) ( b != 0 ) ) { c = 1 / c ; } else ( ( x % 2 ) == 0 ) { ... } Once we have multiple levels of nested parenthesis, it might be more readable to do something like this: 1 2 3 4 5 6 if ( ( a 0 ) ( b != 0 ) ) { c = 1 / c ; } else ( ( x % 2 ) == 0 ) { ... } Here is an example of a poorly formatted return statement: 1 2 3 4 5 6 void foo () { ... return bar ( x ) * bar ( y ); } Indentation should be used to make this more clear: 1 2 3 4 5 6 void foo () { ... return bar ( x ) * bar ( y ); } This code does not include spaces around the assignment operator, and isn't even consistent in its formatting: 1 2 3 double foo = b ; int c = bar ; double e = 1 ; This should look like this: 1 2 3 double foo = b ; int c = bar ; double e = 1 ; Notice how we lined up the variable names and the assignment operators vertically. Here is an example of incorrectly formatted code: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 int gcd ( int x , int y ){ while ( y != 0 ) { if ( x y ){ int t = x ; x = temp ; x = y ; } else x = x - y ; } return x ; } Here is an example of correctly formatted code: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //------------------------------------------------------------------------ // gcd() //------------------------------------------------------------------------ int gcd ( int x , int y ) { // iterate until GCD is found while ( y != 0 ) { if ( x y ) { // swap x and y int temp = x ; y = temp ; x = y ; } else { x = x - y ; } } return x ; }","title":"7. Examples"},{"location":"ece2400-faq-c-basics/","text":"========================================================================== This is a collection of commonly asked questions on C basics. Q: How do understand the include guard? I noticed this on the sec2 handout 1 2 3 4 5 6 #ifndef WARM_COLORS_TXT #define WARM_COLORS_TXT red orange yellow #endif If I have already defined a macro, then excute the #ifndef directive, then include the content again. How does this operation skip over the contents of the same file? A: How do understand the include guard? From my understanding, what the #ifindef conditional does is check to see if this macro has been defined already. If it has not then, the code below the #ifindef line is run and the macro us defined. On the other hand, if it already exists, meaning it has a value, these lines below #ifindef will not be processed. So, the preprocessor determines if the macro exists before including the leading code in the compilation process. In other words, if something has a value during the course of the program, it is stored and so not changed again during the rest of the compilation process. An example I saw online that might help: 1 2 3 4 5 6 7 8 9 10 11 12 13 #include stdio.h #define YEARS_OLD 12 #ifndef YEARS_OLD #define YEARS_OLD 10 #endif int main () { printf ( TechOnTheNet is over %d years old. \\n , YEARS_OLD ); return 0 ; } In this case, since YEARS_OLD is defined before ifndef, the code below it will be skipped over because the macro is already defined and so the compiler will skip over to #endif. If you run this code, you will see that YEARS_OLD has a value of 12. If we removed the first #define statement and just had this: 1 2 3 4 5 6 7 8 9 #ifndef YEARS_OLD #define YEARS_OLD 10 #endif int main () { printf ( TechOnTheNet is over %d years old. \\n , YEARS_OLD ); return 0 ; } Then the lines under #ifndef would be processed and YEARS_OLD would attain a value of 10. Hope this answers your question!","title":"Ece2400 faq c basics"},{"location":"ece2400-faq-c-basics/#q-how-do-understand-the-include-guard","text":"I noticed this on the sec2 handout 1 2 3 4 5 6 #ifndef WARM_COLORS_TXT #define WARM_COLORS_TXT red orange yellow #endif If I have already defined a macro, then excute the #ifndef directive, then include the content again. How does this operation skip over the contents of the same file?","title":"Q: How do understand the include guard?"},{"location":"ece2400-faq-c-basics/#a-how-do-understand-the-include-guard","text":"From my understanding, what the #ifindef conditional does is check to see if this macro has been defined already. If it has not then, the code below the #ifindef line is run and the macro us defined. On the other hand, if it already exists, meaning it has a value, these lines below #ifindef will not be processed. So, the preprocessor determines if the macro exists before including the leading code in the compilation process. In other words, if something has a value during the course of the program, it is stored and so not changed again during the rest of the compilation process. An example I saw online that might help: 1 2 3 4 5 6 7 8 9 10 11 12 13 #include stdio.h #define YEARS_OLD 12 #ifndef YEARS_OLD #define YEARS_OLD 10 #endif int main () { printf ( TechOnTheNet is over %d years old. \\n , YEARS_OLD ); return 0 ; } In this case, since YEARS_OLD is defined before ifndef, the code below it will be skipped over because the macro is already defined and so the compiler will skip over to #endif. If you run this code, you will see that YEARS_OLD has a value of 12. If we removed the first #define statement and just had this: 1 2 3 4 5 6 7 8 9 #ifndef YEARS_OLD #define YEARS_OLD 10 #endif int main () { printf ( TechOnTheNet is over %d years old. \\n , YEARS_OLD ); return 0 ; } Then the lines under #ifndef would be processed and YEARS_OLD would attain a value of 10. Hope this answers your question!","title":"A: How do understand the include guard?"},{"location":"ece2400-memory-debugging/","text":"How to debug memory problems? Author: Tuan Ta Date : Sep 26, 2018 While dynamic memory allocation gives us a lot of freedom in keeping some blocks of memory alive across function calls, misusing dynamically allocated memory is often the most common cause of memory corruptions (e.g., segmentation fault). In this tutorial, I'll walk you through some common mistakes in using dynamic memory allocation and pointer. For each mistake, I'll show you how to detect it using a powerful memory checking tool called valgrind . 1. Memory leak Let's consider this program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 1 # include stdlib . h 2 # include stdio . h 3 4 int main ( void ) { 5 6 // Allocate an int on the heap 7 int* mem_ptr = ( int* ) malloc( sizeof( int) ) ; 8 9 // Initialize that int variable 10 *mem_ptr = 10 ; 11 12 printf( Before : mem_ptr : address = % lx , value = % d \\ n , mem_ptr, *mem_ptr); 13 14 // Declare a new int variable on the stack 15 int a = 20; 16 17 // Reuse mem_ptr to point to a 18 mem_ptr = a; 19 20 printf( After : mem_ptr : address = % lx , value = % d \\ n , mem_ptr , * mem_ptr ); 21 22 // How do I get back my memory on the heap? 23 24 return 0 ; 25 } We first allocate a block of memory on the heap (in line 7). Then, we assign mem_ptr to point to a different block of memory on the stack (in line 18). By assigning \"mem_ptr\" to a different block of memory, we lose the only way to go back to our heap memory block. Therefore, in line 22, we cannot free that heap memory block. There're actually two problems here: First, since there is no pointer pointing to the block of memory on the heap, that block of memory becomes \"orphan\". Second, since we do not or cannot free the block of memory, we lose it in our program. This problem is called \"memory leak\". Now, let's compile and run the program: 1 2 3 4 ECE2400: ~/ece2400/tests % gcc -Wall -g -O3 -o mem-leak mem-leak.c ECE2400: ~/ece2400/tests % ./mem-leak Before: mem_ptr: address = 0x1a17010, value = 10 After: mem_ptr: address = 0x7fffabe3582c, value = 20 Notice that there is no compilation error! And our program runs \"completely fine\", or does it? Well, if your memory leak is small enough (e.g., in this program, we lose only 4 bytes of memory), then your program may not crash. Think about if your memory leak accumulates over time in a long program, then something nasty (e.g., segmentation fault) will happen! We don't want that. So how to detect memory leak. Luckily, we have a powerful tool called \"Valgrind\" to help us. Let's use the tool to run our buggy program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ECE2400: ~/ece2400/tests % valgrind --leak-check=full --error-exitcode=1 ./mem-leak ==14973== Memcheck, a memory error detector ==14973== Copyright (C) 2002-2015, and GNU GPL d, by Julian Seward et al. ==14973== Using Valgrind-3.12.0 and LibVEX; rerun with -h for copyright info ==14973== Command: ./mem-leak ==14973== Before: mem_ptr: address = 0x5202040, value = 10 After: mem_ptr: address = 0xffefff4dc, value = 20 ==14973== ==14973== HEAP SUMMARY: ==14973== in use at exit: 4 bytes in 1 blocks ==14973== total heap usage: 1 allocs, 0 frees, 4 bytes allocated ==14973== ==14973== 4 bytes in 1 blocks are definitely lost in loss record 1 of 1 ==14973== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==14973== by 0x40047D: main (mem-leak.c:7) ==14973== ==14973== LEAK SUMMARY: ==14973== definitely lost: 4 bytes in 1 blocks ==14973== indirectly lost: 0 bytes in 0 blocks ==14973== possibly lost: 0 bytes in 0 blocks ==14973== still reachable: 0 bytes in 0 blocks ==14973== suppressed: 0 bytes in 0 blocks ==14973== ==14973== For counts of detected and suppressed errors, rerun with: -v ==14973== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0) Here I run valgrind with two options --leak-check=full that tells valgrind to give details about any possible memory leak in our program and --error-exitcode=1 that tells valgrind to return an error code of 1 if any memory error is detected. Let's dive into what valgrind is telling us here. We thought our program ran fine, but Valgrind reported that we \"definitely lost\" 4 bytes of memory on the heap and that no memory block on the heap was \"still reachable\" at the end of the program. The report tells us exactly what we expect in the buggy program right? Our heap memory block has no pointer pointing to it at the end of the program, so it is not reachable. Since there is no way to reach to the block, we could not free that block. Therefore, that block of heap memory is definitely lost. When you compile your program with -g option, valgrind can tell you where the leak exactly is in our program. In this case, we lost 4 bytes that were allocated in line 7 of mem-leak.c . Let's try to fix the memory bug and re-run valgrind on your own to verify the leak is actually fixed. 2. Double free your memory Another common problem is that a block of memory on the heap can be freed twice. Let's look at this buggy program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1 # include stdlib . h 2 # include stdio . h 3 4 void foo ( int * mem_ptr ) { 5 printf( In foo(): mem_ptr : address = % p , value = % d \\ n , mem_ptr, *mem_ptr); 6 free( mem_ptr ); 7 } 8 9 int main( void ) { 10 11 // Allocate an int on the heap 12 int* mem_ptr = ( int* ) malloc( sizeof( int) ); 13 14 // Initialize that int variable 15 *mem_ptr = 10; 16 17 printf( In main () : mem_ptr : address = % p , value = % d \\ n , mem_ptr , * mem_ptr ); 18 19 // Call foo 20 foo( mem_ptr ) ; 21 22 // Did foo free mem_ptr? Maybe not, so let s just free it here just in case! 23 free( mem_ptr ) ; 24 25 return 0 ; 26 } In line 12, we allocate a block of memory on the heap. In line 20, we pass \"mem_ptr\" to foo() . In line 6, foo() after printing the value pointed by \"mem_ptr\" frees the block. In line 23, main() tries to re-free \"mem_ptr\". You may think that in this small program, it's easy to see that \"mem_ptr\" is freed twice, right? In reality, it may be really hard to see this problem especially when multiple pointers point to the same block of memory (i.e., this is called pointer aliasing). Let's run the program and see what will happen: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ECE2400: ~/ece2400/tests % gcc -Wall -g -O3 -o double-free double-free.c ECE2400: ~/ece2400/tests % ./double-free In main(): mem_ptr: address = 0xcec010, value = 10 In foo(): mem_ptr: address = 0xcec010, value = 10 *** Error in `./double-free : double free or corruption (fasttop): 0x0000000000cec010 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x81429)[0x7f5564d81429] ./double-free[0x4004f8] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f5564d223d5] ./double-free[0x400525] ======= Memory map: ======== 00400000-00401000 r-xp 00000000 00:28 190587185 /home/qtt2/ece2400/tests/double-free 00600000-00601000 r--p 00000000 00:28 190587185 /home/qtt2/ece2400/tests/double-free 00601000-00602000 rw-p 00001000 00:28 190587185 /home/qtt2/ece2400/tests/double-free 00cec000-00d0d000 rw-p 00000000 00:00 0 [heap] 7f5560000000-7f5560021000 rw-p 00000000 00:00 0 7f5560021000-7f5564000000 ---p 00000000 00:00 0 7f5564aea000-7f5564aff000 r-xp 00000000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564aff000-7f5564cfe000 ---p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564cfe000-7f5564cff000 r--p 00014000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564cff000-7f5564d00000 rw-p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564d00000-7f5564ec3000 r-xp 00000000 fd:00 148997 /usr/lib64/libc-2.17.so 7f5564ec3000-7f55650c2000 ---p 001c3000 fd:00 148997 /usr/lib64/libc-2.17.so 7f55650c2000-7f55650c6000 r--p 001c2000 fd:00 148997 /usr/lib64/libc-2.17.so 7f55650c6000-7f55650c8000 rw-p 001c6000 fd:00 148997 /usr/lib64/libc-2.17.so 7f55650c8000-7f55650cd000 rw-p 00000000 00:00 0 7f55650cd000-7f55650ef000 r-xp 00000000 fd:00 148990 /usr/lib64/ld-2.17.so 7f55652c6000-7f55652c9000 rw-p 00000000 00:00 0 7f55652eb000-7f55652ee000 rw-p 00000000 00:00 0 7f55652ee000-7f55652ef000 r--p 00021000 fd:00 148990 /usr/lib64/ld-2.17.so 7f55652ef000-7f55652f0000 rw-p 00022000 fd:00 148990 /usr/lib64/ld-2.17.so 7f55652f0000-7f55652f1000 rw-p 00000000 00:00 0 7ffeec44c000-7ffeec46e000 rw-p 00000000 00:00 0 [stack] 7ffeec485000-7ffeec487000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] Aborted (core dumped) Oopps, our program crashed! No worries. Our friend valgrind can help us detect what went wrong. Let's run valgrind and see what it reports. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ECE2400: ~/ece2400/tests % valgrind --leak-check=full --error-exitcode=1 ./double-free ==23220== Memcheck, a memory error detector ==23220== Copyright (C) 2002-2015, and GNU GPL d, by Julian Seward et al. ==23220== Using Valgrind-3.12.0 and LibVEX; rerun with -h for copyright info ==23220== Command: ./double-free ==23220== In main(): mem_ptr: address = 0x5202040, value = 10 In foo(): mem_ptr: address = 0x5202040, value = 10 ==23220== Invalid free() / delete / delete[] / realloc() ==23220== at 0x4C2AC7D: free (vg_replace_malloc.c:530) ==23220== by 0x4004F7: main (double-free.c:23) ==23220== Address 0x5202040 is 0 bytes inside a block of size 4 free d ==23220== at 0x4C2AC7D: free (vg_replace_malloc.c:530) ==23220== by 0x4004EF: main (double-free.c:20) ==23220== Block was alloc d at ==23220== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==23220== by 0x4004CA: main (double-free.c:12) ==23220== ==23220== ==23220== HEAP SUMMARY: ==23220== in use at exit: 0 bytes in 0 blocks ==23220== total heap usage: 1 allocs, 2 frees, 4 bytes allocated ==23220== ==23220== All heap blocks were freed -- no leaks are possible ==23220== ==23220== For counts of detected and suppressed errors, rerun with: -v ==23220== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0) Valgrind tells us that there was an \"invalid free()\" in line 23 of double-free.c . Thanks to Valgrind, now you know exactly what the problem is. Can you fix it on your own and re-run valgrind? 3. Invalid memory access Remember that C compiler does not check out-of-bounds array access. You may accidentally access some memory blocks that are not allocated. Let's consider this buggy program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1 #include stdlib.h 2 #include stdio.h 3 4 int main( void ) { 5 6 const int size = 10; 7 int* mem_ptr = ( int* ) malloc( sizeof( int ) * size ); 8 9 for ( int i = 0; i = size; i++ ) { 10 printf( Initializing mem_ptr[%d] ... \\n , i ); 11 mem_ptr[i] = i; 12 } 13 14 // Print out the array 15 for ( int i = 0; i = size; i++ ) { 16 printf( mem_ptr[%d] = %d\\n , i, mem_ptr[i] ); 17 } 18 19 // Free mem_ptr 20 free(mem_ptr); 21 22 return 0; 23 } Notice that the program allocates an array of 10 \"int\" elements on the heap (in line 7). It by mistake initializes the 11th element when i == size in line 9. Then in line 15, the program tries to read that unallocated element. When you compile and run the program, you will get something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 ECE2400: ~/ece2400/tests % gcc -Wall -g -O3 -o out-of-bound-access out-of-bound-access.c ECE2400: ~/ece2400/tests % ./out-of-bound-access Initializing mem_ptr[0] ... Initializing mem_ptr[1] ... Initializing mem_ptr[2] ... Initializing mem_ptr[3] ... Initializing mem_ptr[4] ... Initializing mem_ptr[5] ... Initializing mem_ptr[6] ... Initializing mem_ptr[7] ... Initializing mem_ptr[8] ... Initializing mem_ptr[9] ... Initializing mem_ptr[10] ... mem_ptr[0] = 0 mem_ptr[1] = 1 mem_ptr[2] = 2 mem_ptr[3] = 3 mem_ptr[4] = 4 mem_ptr[5] = 5 mem_ptr[6] = 6 mem_ptr[7] = 7 mem_ptr[8] = 8 mem_ptr[9] = 9 mem_ptr[10] = 10 *** Error in `./out-of-bound-access : free(): invalid next size (fast): 0x0000000001d1e010 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x81429)[0x7fdf3ec46429] ./out-of-bound-access[0x400524] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7fdf3ebe73d5] ./out-of-bound-access[0x400556] ======= Memory map: ======== 00400000-00401000 r-xp 00000000 00:28 190587184 /home/qtt2/ece2400/tests/out-of-bound-access 00600000-00601000 r--p 00000000 00:28 190587184 /home/qtt2/ece2400/tests/out-of-bound-access 00601000-00602000 rw-p 00001000 00:28 190587184 /home/qtt2/ece2400/tests/out-of-bound-access 01d1e000-01d3f000 rw-p 00000000 00:00 0 [heap] 7fdf38000000-7fdf38021000 rw-p 00000000 00:00 0 7fdf38021000-7fdf3c000000 ---p 00000000 00:00 0 7fdf3e9af000-7fdf3e9c4000 r-xp 00000000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3e9c4000-7fdf3ebc3000 ---p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3ebc3000-7fdf3ebc4000 r--p 00014000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3ebc4000-7fdf3ebc5000 rw-p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3ebc5000-7fdf3ed88000 r-xp 00000000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ed88000-7fdf3ef87000 ---p 001c3000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ef87000-7fdf3ef8b000 r--p 001c2000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ef8b000-7fdf3ef8d000 rw-p 001c6000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ef8d000-7fdf3ef92000 rw-p 00000000 00:00 0 7fdf3ef92000-7fdf3efb4000 r-xp 00000000 fd:00 148990 /usr/lib64/ld-2.17.so 7fdf3f18b000-7fdf3f18e000 rw-p 00000000 00:00 0 7fdf3f1b0000-7fdf3f1b3000 rw-p 00000000 00:00 0 7fdf3f1b3000-7fdf3f1b4000 r--p 00021000 fd:00 148990 /usr/lib64/ld-2.17.so 7fdf3f1b4000-7fdf3f1b5000 rw-p 00022000 fd:00 148990 /usr/lib64/ld-2.17.so 7fdf3f1b5000-7fdf3f1b6000 rw-p 00000000 00:00 0 7ffe872bd000-7ffe872df000 rw-p 00000000 00:00 0 [stack] 7ffe872e7000-7ffe872e9000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] Aborted (core dumped) The program crashed at the very end when it tried to free an unallocated memory block. Let's run it using valgrind: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 ECE2400: ~/ece2400/tests % valgrind --leak-check=full --error-exitcode=1 ./out-of-bound-access ==31457== Memcheck, a memory error detector ==31457== Copyright (C) 2002-2015, and GNU GPL d, by Julian Seward et al. ==31457== Using Valgrind-3.12.0 and LibVEX; rerun with -h for copyright info ==31457== Command: ./out-of-bound-access ==31457== Initializing mem_ptr[0] ... Initializing mem_ptr[1] ... Initializing mem_ptr[2] ... Initializing mem_ptr[3] ... Initializing mem_ptr[4] ... Initializing mem_ptr[5] ... Initializing mem_ptr[6] ... Initializing mem_ptr[7] ... Initializing mem_ptr[8] ... Initializing mem_ptr[9] ... Initializing mem_ptr[10] ... ==31457== Invalid write of size 4 ==31457== at 0x4004E6: main (out-of-bound-access.c:11) ==31457== Address 0x5202068 is 0 bytes after a block of size 40 alloc d ==31457== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==31457== by 0x4004D1: main (out-of-bound-access.c:7) ==31457== mem_ptr[0] = 0 mem_ptr[1] = 1 mem_ptr[2] = 2 mem_ptr[3] = 3 mem_ptr[4] = 4 mem_ptr[5] = 5 mem_ptr[6] = 6 mem_ptr[7] = 7 mem_ptr[8] = 8 mem_ptr[9] = 9 ==31457== Invalid read of size 4 ==31457== at 0x400500: main (out-of-bound-access.c:16) ==31457== Address 0x5202068 is 0 bytes after a block of size 40 alloc d ==31457== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==31457== by 0x4004D1: main (out-of-bound-access.c:7) ==31457== mem_ptr[10] = 10 ==31457== ==31457== HEAP SUMMARY: ==31457== in use at exit: 0 bytes in 0 blocks ==31457== total heap usage: 1 allocs, 1 frees, 40 bytes allocated ==31457== ==31457== All heap blocks were freed -- no leaks are possible ==31457== ==31457== For counts of detected and suppressed errors, rerun with: -v ==31457== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0) Valgrind reported an \"Invalid write of size 4\" in line 11 and an \"Invalid read of size 4\" in line 16. They're exactly where we by mistake accessed data blocks outside our allocated array. Now, you can hopefully clearly see the bug and fix it on your own. How to use valgrind in your PAs In PAs, we provide you a make target called \"make memcheck\" that you can use to do memory check on your tests. You can do like this 1 2 3 4 5 6 7 8 9 10 11 % # go to your PA directory % cd ${HOME}/ece2400/ netid /pa2-dstruct % mkdir -p build % cd build % # run memcheck on all tests % make memcheck % # run memcheck on a single test (e.g., dlist-basic-tests) % make memcheck-dlist-basic-tests % # see reports generated by Valgrind % cd memtest-logs % geany dlist-basic-tests.log","title":"Ece2400 memory debugging"},{"location":"ece2400-memory-debugging/#how-to-debug-memory-problems","text":"Author: Tuan Ta Date : Sep 26, 2018 While dynamic memory allocation gives us a lot of freedom in keeping some blocks of memory alive across function calls, misusing dynamically allocated memory is often the most common cause of memory corruptions (e.g., segmentation fault). In this tutorial, I'll walk you through some common mistakes in using dynamic memory allocation and pointer. For each mistake, I'll show you how to detect it using a powerful memory checking tool called valgrind .","title":"How to debug memory problems?"},{"location":"ece2400-memory-debugging/#1-memory-leak","text":"Let's consider this program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 1 # include stdlib . h 2 # include stdio . h 3 4 int main ( void ) { 5 6 // Allocate an int on the heap 7 int* mem_ptr = ( int* ) malloc( sizeof( int) ) ; 8 9 // Initialize that int variable 10 *mem_ptr = 10 ; 11 12 printf( Before : mem_ptr : address = % lx , value = % d \\ n , mem_ptr, *mem_ptr); 13 14 // Declare a new int variable on the stack 15 int a = 20; 16 17 // Reuse mem_ptr to point to a 18 mem_ptr = a; 19 20 printf( After : mem_ptr : address = % lx , value = % d \\ n , mem_ptr , * mem_ptr ); 21 22 // How do I get back my memory on the heap? 23 24 return 0 ; 25 } We first allocate a block of memory on the heap (in line 7). Then, we assign mem_ptr to point to a different block of memory on the stack (in line 18). By assigning \"mem_ptr\" to a different block of memory, we lose the only way to go back to our heap memory block. Therefore, in line 22, we cannot free that heap memory block. There're actually two problems here: First, since there is no pointer pointing to the block of memory on the heap, that block of memory becomes \"orphan\". Second, since we do not or cannot free the block of memory, we lose it in our program. This problem is called \"memory leak\". Now, let's compile and run the program: 1 2 3 4 ECE2400: ~/ece2400/tests % gcc -Wall -g -O3 -o mem-leak mem-leak.c ECE2400: ~/ece2400/tests % ./mem-leak Before: mem_ptr: address = 0x1a17010, value = 10 After: mem_ptr: address = 0x7fffabe3582c, value = 20 Notice that there is no compilation error! And our program runs \"completely fine\", or does it? Well, if your memory leak is small enough (e.g., in this program, we lose only 4 bytes of memory), then your program may not crash. Think about if your memory leak accumulates over time in a long program, then something nasty (e.g., segmentation fault) will happen! We don't want that. So how to detect memory leak. Luckily, we have a powerful tool called \"Valgrind\" to help us. Let's use the tool to run our buggy program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ECE2400: ~/ece2400/tests % valgrind --leak-check=full --error-exitcode=1 ./mem-leak ==14973== Memcheck, a memory error detector ==14973== Copyright (C) 2002-2015, and GNU GPL d, by Julian Seward et al. ==14973== Using Valgrind-3.12.0 and LibVEX; rerun with -h for copyright info ==14973== Command: ./mem-leak ==14973== Before: mem_ptr: address = 0x5202040, value = 10 After: mem_ptr: address = 0xffefff4dc, value = 20 ==14973== ==14973== HEAP SUMMARY: ==14973== in use at exit: 4 bytes in 1 blocks ==14973== total heap usage: 1 allocs, 0 frees, 4 bytes allocated ==14973== ==14973== 4 bytes in 1 blocks are definitely lost in loss record 1 of 1 ==14973== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==14973== by 0x40047D: main (mem-leak.c:7) ==14973== ==14973== LEAK SUMMARY: ==14973== definitely lost: 4 bytes in 1 blocks ==14973== indirectly lost: 0 bytes in 0 blocks ==14973== possibly lost: 0 bytes in 0 blocks ==14973== still reachable: 0 bytes in 0 blocks ==14973== suppressed: 0 bytes in 0 blocks ==14973== ==14973== For counts of detected and suppressed errors, rerun with: -v ==14973== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0) Here I run valgrind with two options --leak-check=full that tells valgrind to give details about any possible memory leak in our program and --error-exitcode=1 that tells valgrind to return an error code of 1 if any memory error is detected. Let's dive into what valgrind is telling us here. We thought our program ran fine, but Valgrind reported that we \"definitely lost\" 4 bytes of memory on the heap and that no memory block on the heap was \"still reachable\" at the end of the program. The report tells us exactly what we expect in the buggy program right? Our heap memory block has no pointer pointing to it at the end of the program, so it is not reachable. Since there is no way to reach to the block, we could not free that block. Therefore, that block of heap memory is definitely lost. When you compile your program with -g option, valgrind can tell you where the leak exactly is in our program. In this case, we lost 4 bytes that were allocated in line 7 of mem-leak.c . Let's try to fix the memory bug and re-run valgrind on your own to verify the leak is actually fixed.","title":"1. Memory leak"},{"location":"ece2400-memory-debugging/#2-double-free-your-memory","text":"Another common problem is that a block of memory on the heap can be freed twice. Let's look at this buggy program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1 # include stdlib . h 2 # include stdio . h 3 4 void foo ( int * mem_ptr ) { 5 printf( In foo(): mem_ptr : address = % p , value = % d \\ n , mem_ptr, *mem_ptr); 6 free( mem_ptr ); 7 } 8 9 int main( void ) { 10 11 // Allocate an int on the heap 12 int* mem_ptr = ( int* ) malloc( sizeof( int) ); 13 14 // Initialize that int variable 15 *mem_ptr = 10; 16 17 printf( In main () : mem_ptr : address = % p , value = % d \\ n , mem_ptr , * mem_ptr ); 18 19 // Call foo 20 foo( mem_ptr ) ; 21 22 // Did foo free mem_ptr? Maybe not, so let s just free it here just in case! 23 free( mem_ptr ) ; 24 25 return 0 ; 26 } In line 12, we allocate a block of memory on the heap. In line 20, we pass \"mem_ptr\" to foo() . In line 6, foo() after printing the value pointed by \"mem_ptr\" frees the block. In line 23, main() tries to re-free \"mem_ptr\". You may think that in this small program, it's easy to see that \"mem_ptr\" is freed twice, right? In reality, it may be really hard to see this problem especially when multiple pointers point to the same block of memory (i.e., this is called pointer aliasing). Let's run the program and see what will happen: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ECE2400: ~/ece2400/tests % gcc -Wall -g -O3 -o double-free double-free.c ECE2400: ~/ece2400/tests % ./double-free In main(): mem_ptr: address = 0xcec010, value = 10 In foo(): mem_ptr: address = 0xcec010, value = 10 *** Error in `./double-free : double free or corruption (fasttop): 0x0000000000cec010 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x81429)[0x7f5564d81429] ./double-free[0x4004f8] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f5564d223d5] ./double-free[0x400525] ======= Memory map: ======== 00400000-00401000 r-xp 00000000 00:28 190587185 /home/qtt2/ece2400/tests/double-free 00600000-00601000 r--p 00000000 00:28 190587185 /home/qtt2/ece2400/tests/double-free 00601000-00602000 rw-p 00001000 00:28 190587185 /home/qtt2/ece2400/tests/double-free 00cec000-00d0d000 rw-p 00000000 00:00 0 [heap] 7f5560000000-7f5560021000 rw-p 00000000 00:00 0 7f5560021000-7f5564000000 ---p 00000000 00:00 0 7f5564aea000-7f5564aff000 r-xp 00000000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564aff000-7f5564cfe000 ---p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564cfe000-7f5564cff000 r--p 00014000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564cff000-7f5564d00000 rw-p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f5564d00000-7f5564ec3000 r-xp 00000000 fd:00 148997 /usr/lib64/libc-2.17.so 7f5564ec3000-7f55650c2000 ---p 001c3000 fd:00 148997 /usr/lib64/libc-2.17.so 7f55650c2000-7f55650c6000 r--p 001c2000 fd:00 148997 /usr/lib64/libc-2.17.so 7f55650c6000-7f55650c8000 rw-p 001c6000 fd:00 148997 /usr/lib64/libc-2.17.so 7f55650c8000-7f55650cd000 rw-p 00000000 00:00 0 7f55650cd000-7f55650ef000 r-xp 00000000 fd:00 148990 /usr/lib64/ld-2.17.so 7f55652c6000-7f55652c9000 rw-p 00000000 00:00 0 7f55652eb000-7f55652ee000 rw-p 00000000 00:00 0 7f55652ee000-7f55652ef000 r--p 00021000 fd:00 148990 /usr/lib64/ld-2.17.so 7f55652ef000-7f55652f0000 rw-p 00022000 fd:00 148990 /usr/lib64/ld-2.17.so 7f55652f0000-7f55652f1000 rw-p 00000000 00:00 0 7ffeec44c000-7ffeec46e000 rw-p 00000000 00:00 0 [stack] 7ffeec485000-7ffeec487000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] Aborted (core dumped) Oopps, our program crashed! No worries. Our friend valgrind can help us detect what went wrong. Let's run valgrind and see what it reports. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ECE2400: ~/ece2400/tests % valgrind --leak-check=full --error-exitcode=1 ./double-free ==23220== Memcheck, a memory error detector ==23220== Copyright (C) 2002-2015, and GNU GPL d, by Julian Seward et al. ==23220== Using Valgrind-3.12.0 and LibVEX; rerun with -h for copyright info ==23220== Command: ./double-free ==23220== In main(): mem_ptr: address = 0x5202040, value = 10 In foo(): mem_ptr: address = 0x5202040, value = 10 ==23220== Invalid free() / delete / delete[] / realloc() ==23220== at 0x4C2AC7D: free (vg_replace_malloc.c:530) ==23220== by 0x4004F7: main (double-free.c:23) ==23220== Address 0x5202040 is 0 bytes inside a block of size 4 free d ==23220== at 0x4C2AC7D: free (vg_replace_malloc.c:530) ==23220== by 0x4004EF: main (double-free.c:20) ==23220== Block was alloc d at ==23220== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==23220== by 0x4004CA: main (double-free.c:12) ==23220== ==23220== ==23220== HEAP SUMMARY: ==23220== in use at exit: 0 bytes in 0 blocks ==23220== total heap usage: 1 allocs, 2 frees, 4 bytes allocated ==23220== ==23220== All heap blocks were freed -- no leaks are possible ==23220== ==23220== For counts of detected and suppressed errors, rerun with: -v ==23220== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0) Valgrind tells us that there was an \"invalid free()\" in line 23 of double-free.c . Thanks to Valgrind, now you know exactly what the problem is. Can you fix it on your own and re-run valgrind?","title":"2. Double free your memory"},{"location":"ece2400-memory-debugging/#3-invalid-memory-access","text":"Remember that C compiler does not check out-of-bounds array access. You may accidentally access some memory blocks that are not allocated. Let's consider this buggy program: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1 #include stdlib.h 2 #include stdio.h 3 4 int main( void ) { 5 6 const int size = 10; 7 int* mem_ptr = ( int* ) malloc( sizeof( int ) * size ); 8 9 for ( int i = 0; i = size; i++ ) { 10 printf( Initializing mem_ptr[%d] ... \\n , i ); 11 mem_ptr[i] = i; 12 } 13 14 // Print out the array 15 for ( int i = 0; i = size; i++ ) { 16 printf( mem_ptr[%d] = %d\\n , i, mem_ptr[i] ); 17 } 18 19 // Free mem_ptr 20 free(mem_ptr); 21 22 return 0; 23 } Notice that the program allocates an array of 10 \"int\" elements on the heap (in line 7). It by mistake initializes the 11th element when i == size in line 9. Then in line 15, the program tries to read that unallocated element. When you compile and run the program, you will get something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 ECE2400: ~/ece2400/tests % gcc -Wall -g -O3 -o out-of-bound-access out-of-bound-access.c ECE2400: ~/ece2400/tests % ./out-of-bound-access Initializing mem_ptr[0] ... Initializing mem_ptr[1] ... Initializing mem_ptr[2] ... Initializing mem_ptr[3] ... Initializing mem_ptr[4] ... Initializing mem_ptr[5] ... Initializing mem_ptr[6] ... Initializing mem_ptr[7] ... Initializing mem_ptr[8] ... Initializing mem_ptr[9] ... Initializing mem_ptr[10] ... mem_ptr[0] = 0 mem_ptr[1] = 1 mem_ptr[2] = 2 mem_ptr[3] = 3 mem_ptr[4] = 4 mem_ptr[5] = 5 mem_ptr[6] = 6 mem_ptr[7] = 7 mem_ptr[8] = 8 mem_ptr[9] = 9 mem_ptr[10] = 10 *** Error in `./out-of-bound-access : free(): invalid next size (fast): 0x0000000001d1e010 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x81429)[0x7fdf3ec46429] ./out-of-bound-access[0x400524] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7fdf3ebe73d5] ./out-of-bound-access[0x400556] ======= Memory map: ======== 00400000-00401000 r-xp 00000000 00:28 190587184 /home/qtt2/ece2400/tests/out-of-bound-access 00600000-00601000 r--p 00000000 00:28 190587184 /home/qtt2/ece2400/tests/out-of-bound-access 00601000-00602000 rw-p 00001000 00:28 190587184 /home/qtt2/ece2400/tests/out-of-bound-access 01d1e000-01d3f000 rw-p 00000000 00:00 0 [heap] 7fdf38000000-7fdf38021000 rw-p 00000000 00:00 0 7fdf38021000-7fdf3c000000 ---p 00000000 00:00 0 7fdf3e9af000-7fdf3e9c4000 r-xp 00000000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3e9c4000-7fdf3ebc3000 ---p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3ebc3000-7fdf3ebc4000 r--p 00014000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3ebc4000-7fdf3ebc5000 rw-p 00015000 fd:00 1188523 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7fdf3ebc5000-7fdf3ed88000 r-xp 00000000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ed88000-7fdf3ef87000 ---p 001c3000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ef87000-7fdf3ef8b000 r--p 001c2000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ef8b000-7fdf3ef8d000 rw-p 001c6000 fd:00 148997 /usr/lib64/libc-2.17.so 7fdf3ef8d000-7fdf3ef92000 rw-p 00000000 00:00 0 7fdf3ef92000-7fdf3efb4000 r-xp 00000000 fd:00 148990 /usr/lib64/ld-2.17.so 7fdf3f18b000-7fdf3f18e000 rw-p 00000000 00:00 0 7fdf3f1b0000-7fdf3f1b3000 rw-p 00000000 00:00 0 7fdf3f1b3000-7fdf3f1b4000 r--p 00021000 fd:00 148990 /usr/lib64/ld-2.17.so 7fdf3f1b4000-7fdf3f1b5000 rw-p 00022000 fd:00 148990 /usr/lib64/ld-2.17.so 7fdf3f1b5000-7fdf3f1b6000 rw-p 00000000 00:00 0 7ffe872bd000-7ffe872df000 rw-p 00000000 00:00 0 [stack] 7ffe872e7000-7ffe872e9000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] Aborted (core dumped) The program crashed at the very end when it tried to free an unallocated memory block. Let's run it using valgrind: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 ECE2400: ~/ece2400/tests % valgrind --leak-check=full --error-exitcode=1 ./out-of-bound-access ==31457== Memcheck, a memory error detector ==31457== Copyright (C) 2002-2015, and GNU GPL d, by Julian Seward et al. ==31457== Using Valgrind-3.12.0 and LibVEX; rerun with -h for copyright info ==31457== Command: ./out-of-bound-access ==31457== Initializing mem_ptr[0] ... Initializing mem_ptr[1] ... Initializing mem_ptr[2] ... Initializing mem_ptr[3] ... Initializing mem_ptr[4] ... Initializing mem_ptr[5] ... Initializing mem_ptr[6] ... Initializing mem_ptr[7] ... Initializing mem_ptr[8] ... Initializing mem_ptr[9] ... Initializing mem_ptr[10] ... ==31457== Invalid write of size 4 ==31457== at 0x4004E6: main (out-of-bound-access.c:11) ==31457== Address 0x5202068 is 0 bytes after a block of size 40 alloc d ==31457== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==31457== by 0x4004D1: main (out-of-bound-access.c:7) ==31457== mem_ptr[0] = 0 mem_ptr[1] = 1 mem_ptr[2] = 2 mem_ptr[3] = 3 mem_ptr[4] = 4 mem_ptr[5] = 5 mem_ptr[6] = 6 mem_ptr[7] = 7 mem_ptr[8] = 8 mem_ptr[9] = 9 ==31457== Invalid read of size 4 ==31457== at 0x400500: main (out-of-bound-access.c:16) ==31457== Address 0x5202068 is 0 bytes after a block of size 40 alloc d ==31457== at 0x4C29B83: malloc (vg_replace_malloc.c:299) ==31457== by 0x4004D1: main (out-of-bound-access.c:7) ==31457== mem_ptr[10] = 10 ==31457== ==31457== HEAP SUMMARY: ==31457== in use at exit: 0 bytes in 0 blocks ==31457== total heap usage: 1 allocs, 1 frees, 40 bytes allocated ==31457== ==31457== All heap blocks were freed -- no leaks are possible ==31457== ==31457== For counts of detected and suppressed errors, rerun with: -v ==31457== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0) Valgrind reported an \"Invalid write of size 4\" in line 11 and an \"Invalid read of size 4\" in line 16. They're exactly where we by mistake accessed data blocks outside our allocated array. Now, you can hopefully clearly see the bug and fix it on your own.","title":"3. Invalid memory access"},{"location":"ece2400-memory-debugging/#how-to-use-valgrind-in-your-pas","text":"In PAs, we provide you a make target called \"make memcheck\" that you can use to do memory check on your tests. You can do like this 1 2 3 4 5 6 7 8 9 10 11 % # go to your PA directory % cd ${HOME}/ece2400/ netid /pa2-dstruct % mkdir -p build % cd build % # run memcheck on all tests % make memcheck % # run memcheck on a single test (e.g., dlist-basic-tests) % make memcheck-dlist-basic-tests % # see reports generated by Valgrind % cd memtest-logs % geany dlist-basic-tests.log","title":"How to use valgrind in your PAs"},{"location":"ece2400-pa1-math/","text":"Programming Assignment 1: Math Functions","title":"Ece2400 pa1 math"},{"location":"ece2400-pa1-math/#programming-assignment-1-math-functions","text":"","title":"Programming Assignment 1: Math Functions"},{"location":"ece2400-sec1-linux-git/","text":"Section 1: Linux and Git This section serves as gentle introduction to the basics of using Linux and Git on the ecelinux machines. The corresponding tutorial provides significantly more detail and background. 1. The ecelinux Machines We will be using the ecelinux workstations and servers for all of the programming assignments. The ecelinux machines all run the Red Hat Enterprise Linux 7 operating system, and they all use an identical setup. Linux is the operating system of choice for both cloud and IoT systems, so becoming familiar with Linux will pay dividends beyond just this course. Options For Using ecelinux machines directly use workstations in 314 Phillips Linux Lab log in remotely from 318 Phillips Windows Lab log in remotely from your own laptop in this discussion section, we will be directly logging into the workstations in the 314 Phillips ECE Linux Lab Logging Into a Workstatation use your NetID and your standard NetID password if you cannot log in, then it may be because you added the course since Thursday morning, we will be updating the access list often Joining The Zoom Screenshare for the discussion section, we will be using screensharing via zoom start zoom, choose from menubar: Applications Internet Zoom click \"Join a Meeting\" enter \"ece2400\" in the text box check \"Don't connect to Audio\" check \"Turn off my video\" click \"Join\" click \"View Options\" at the top choose \"Exit Full Screen\"_ drag window over to the right-hand edge to make it take up the right half of the screen 2. Repl.it Online Development Environment We will be using Repl.it to enable quickly exploring small C/C++ code snippets. Repl.it is a free online service which supports writing, compiling, and executing C/C++ programs completely online in your browser. start Firefox, choose from menubar: Applications Internet Firefox drag window over to the left-hand edge to make it take up the left half of the screen go to Repl.it here: https://repl.it you can use Repl.it without an account, you can reate an account later in the \"Search for a language\" drop-down choose Python the left panel is for entering code the right panel displays the results of executing that code enter the following Python program inspired by today's lecture 1 2 3 4 5 6 7 8 def min ( a , b ): if a b : c = a else : c = b return c print ( min ( 13 , 42 )) remember, indentation is important in Python! click \"run\" again go back to Repl.it here: https://repl.it in the \"Search for a language\" drop-down choose C you will see a default program replace that program with this new program inspired by today's lecture 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include stdio.h int min ( int a , int b ) { int c ; if ( a b ) c = a ; else c = b ; return c ; } int main () { printf ( %d , min ( 13 , 42 )); return 0 ; } click \"run\" by the end of next week you will understand this program students are encouraged to use Repl.it through the semester! 3. Linux Development Environment While Repl.it is great for experimenting with small code snippets, it is not suitable for serious system-level programming. So we will instead be using the ecelinux workstations and servers which run the Red Hat Enterprise Linux 7 operating system. The heart of the Linux operating system is the Linux command line. This is a text-based console where you can enter commands to interact with the operating system. Starting the Terminal the terminal is where you can work at the Linux command line choose from menubar: Applications Favorites Terminal drag window over to the left-hand edge to make it take up the left half of the screen Hello World We begin with the ubiquitous \"Hello, World\" example. To display the message \"Hello, World\" we will use the echo command. The echo command simply \"echoes\" its input to the console. 1 % echo Hello, World The string we provide to the echo command is called a command line argument . We use command line arguments to tell commands what they should operate on. Note that you do not need to enter % character. In a tutorial like this, the % simply indicates what you should type at the command line. To-Do On Your Own Experiment with using the echo command to display different messages. Manual Pages You can learn more about any Linux command by using the man command. Try using this to learn more about the echo command. 1 % man echo You can use the up/down keys to scroll the manual one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the manual. Create, View, and List Files We can use the echo command and a feature called command output redirection to create simple text files. Command output redirection is discussed more in the full tutorial. Command output redirection uses the operator to take the output from one command and \"redirect\" it to a file. The following commands will create a new file named ece2400-tut1.txt that simply contains the text \"Computer Systems Programming\". 1 % echo Computer Systems Programming ece2400-tut1.txt We can use the cat command to quickly display the contents of a file. 1 % cat ece2400-tut1.txt For larger files, cat will output the entire file to the console so it may be hard to read the file as it streams past. We can use the less command to show one screen-full of text at a time. You can use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the file. 1 % less ece2400-tut1.txt You can use the ls command to list the filenames of the files you have created. 1 % ls We can provide command line options to the ls command to modify the command\u2019s behavior. For example, we can use the -1 (i.e., a dash followed by the number one) command line option to list one file per line, and we can we can use the -l (i.e., a dash followed by the letter l) command line option to provide a longer listing with more information about each file. To-Do On Your Own Create a new file named ece2400-tut1-layer3.txt which contains the third layer in the computing systems stack (i.e., programming language). Use cat and less to verify the file contents. Create, Change, and List Directories Obviously, having all files in a single location would be hard to manage effectively. We can use directories (also called folders) to logically organize our files, just like one can use physical folders to organize physical pieces of paper. The mechanism for organizing files and directories is called the file system. When you first login to an ecelinux machine, you will be in your home directory. This is your own private space on the server that you can use to work on the programming assignments and store your files. You can use the pwd command to print the directory in which you are currently working, which is known as the current working directory. 1 2 % pwd /home/ netid You should see output similar to what is shown above, but instead of netid it should show your actual NetID. The pwd command shows a directory path. A directory path is a list of nested directory names; it describes a \"path\" to get to a specific file or directory. So the above path indicates that there is a toplevel directory named home that contains a directory named netid . This is the directory path to your home directory. As an aside, notice that Linux uses a forward slash ( / ) to separate directories, while Windows uses a back slash ( \\ ) for the same purpose. We can use the mkdir command to make new directories. The following command will make a new directory named ece2400 within your home directory. 1 % mkdir ece2400 We can use the cd command to change our current working directory. The following command will change the current working directory to be the newly created ece2400 directory, before displaying the current working directory with the pwd command. 1 2 3 % cd ece2400 % pwd /home/ netid /ece2400 Use the mkdir , cd , and pwd commands to make another directory. 1 2 3 4 % mkdir tut1 % cd tut1 % pwd /home/ netid /ece2400/tut1 We sometimes say that tut1 is a subdirectory or a child directory of the ece2400 directory. We might also say that the ece2400 directory is the parent directory of the tut1 directory. Use the following command to create a new file in this child directory. 1 2 3 4 % cd /home/ netid /ece2400/tut1 % echo Computer Systems Programming ece2400-tut1.txt % mkdir dirA % ls You can use the tree command to visualize the directory layout and where files are located: 1 2 % cd ~/ece2400 % tree Note that the tilde character ( ~ ) is a shortcut which always refers to your home directory. There are a few other very useful shortcuts. You can use a single dot ( . ) to refer to the current working directory, and you can use a double dot ( .. ) to refer to the parent directory of the current working directory. 1 2 3 4 % cd ~/ece2400/tut1 % cd .. % cd .. % pwd To-Do On Your Own Experiment with creating additional directories and files within the ece2400/tut1 subdirectory. Try using the tree command to display your newly created directory hierarchy. Copy, Move, and Remove Files and Directories We can use the cp command to copy files. The first argument is the name of the file you want to copy, and the second argument is the new name to give to the copy. The following commands will make two copies of the files we created in the previous section. 1 2 3 4 % cd ~/ece2400/tut1 % cp ece2400-tut1.txt ece2400-tut1-a.txt % cp ece2400-tut1.txt ece2400-tut1-b.txt % ls Instead of copying we can also move a file with the mv command: 1 2 3 % cd ~/ece2400/tut1 % mv ece2400-tut1.txt ece2400-tut1-c.txt % ls Finally, we can use the rm command to remove files. 1 2 3 % cd ~/ece2400/tut1 % ls % rm ece2400-tut1-a.txt To-Do On Your Own Creating additional directories and files within the ece2400/tut1 subdirectory, and then use the cp , mv , and rm commands to copy, move, and remove the newly created directories and files. Use the ls and tree commands to display your file and directory organization. Course Setup Script Once you are logged into an ecelinux machine, you will need to setup the working environment with the following command in order to work on the course programming assignments. 1 % source setup-ece2400.sh Editors Students are free to use any text editor they want. We recommend geany . You can start geany like this: 1 % geany Try opening and editing the ece2400-tut1.txt file you created earlier. 4. Git Distributed Version Control System In this course, we will be using Git as our revision control and source code management system. We will be using GitHub for centralized online repository hosting, and TravisCI for online continuous integration testing. These tools will enable us to adopt an agile hardware development methodology so your group can rapidly collaborate and iterate on the design, verification, and evaluation of the assignments. You can check to see if you have a GitHub account on github.com using this link: https://github.com/githubid where githubid is your GitHub username on github.com . If the above link does not work, then you do not have an GitHub account on github.com . You will need to create one here: https://github.com/join Your NetID makes a great GitHub username on github.com. Be sure to use your Cornell University email address. Once your account is setup, please make sure you set your full name so we can know who you are on GitHub.","title":"Ece2400 sec1 linux git"},{"location":"ece2400-sec1-linux-git/#section-1-linux-and-git","text":"This section serves as gentle introduction to the basics of using Linux and Git on the ecelinux machines. The corresponding tutorial provides significantly more detail and background.","title":"Section 1: Linux and Git"},{"location":"ece2400-sec1-linux-git/#1-the-ecelinux-machines","text":"We will be using the ecelinux workstations and servers for all of the programming assignments. The ecelinux machines all run the Red Hat Enterprise Linux 7 operating system, and they all use an identical setup. Linux is the operating system of choice for both cloud and IoT systems, so becoming familiar with Linux will pay dividends beyond just this course.","title":"1. The ecelinux Machines"},{"location":"ece2400-sec1-linux-git/#options-for-using-ecelinux-machines","text":"directly use workstations in 314 Phillips Linux Lab log in remotely from 318 Phillips Windows Lab log in remotely from your own laptop in this discussion section, we will be directly logging into the workstations in the 314 Phillips ECE Linux Lab","title":"Options For Using ecelinux machines"},{"location":"ece2400-sec1-linux-git/#logging-into-a-workstatation","text":"use your NetID and your standard NetID password if you cannot log in, then it may be because you added the course since Thursday morning, we will be updating the access list often","title":"Logging Into a Workstatation"},{"location":"ece2400-sec1-linux-git/#joining-the-zoom-screenshare","text":"for the discussion section, we will be using screensharing via zoom start zoom, choose from menubar: Applications Internet Zoom click \"Join a Meeting\" enter \"ece2400\" in the text box check \"Don't connect to Audio\" check \"Turn off my video\" click \"Join\" click \"View Options\" at the top choose \"Exit Full Screen\"_ drag window over to the right-hand edge to make it take up the right half of the screen","title":"Joining The Zoom Screenshare"},{"location":"ece2400-sec1-linux-git/#2-replit-online-development-environment","text":"We will be using Repl.it to enable quickly exploring small C/C++ code snippets. Repl.it is a free online service which supports writing, compiling, and executing C/C++ programs completely online in your browser. start Firefox, choose from menubar: Applications Internet Firefox drag window over to the left-hand edge to make it take up the left half of the screen go to Repl.it here: https://repl.it you can use Repl.it without an account, you can reate an account later in the \"Search for a language\" drop-down choose Python the left panel is for entering code the right panel displays the results of executing that code enter the following Python program inspired by today's lecture 1 2 3 4 5 6 7 8 def min ( a , b ): if a b : c = a else : c = b return c print ( min ( 13 , 42 )) remember, indentation is important in Python! click \"run\" again go back to Repl.it here: https://repl.it in the \"Search for a language\" drop-down choose C you will see a default program replace that program with this new program inspired by today's lecture 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include stdio.h int min ( int a , int b ) { int c ; if ( a b ) c = a ; else c = b ; return c ; } int main () { printf ( %d , min ( 13 , 42 )); return 0 ; } click \"run\" by the end of next week you will understand this program students are encouraged to use Repl.it through the semester!","title":"2. Repl.it Online Development Environment"},{"location":"ece2400-sec1-linux-git/#3-linux-development-environment","text":"While Repl.it is great for experimenting with small code snippets, it is not suitable for serious system-level programming. So we will instead be using the ecelinux workstations and servers which run the Red Hat Enterprise Linux 7 operating system. The heart of the Linux operating system is the Linux command line. This is a text-based console where you can enter commands to interact with the operating system.","title":"3. Linux Development Environment"},{"location":"ece2400-sec1-linux-git/#starting-the-terminal","text":"the terminal is where you can work at the Linux command line choose from menubar: Applications Favorites Terminal drag window over to the left-hand edge to make it take up the left half of the screen","title":"Starting the Terminal"},{"location":"ece2400-sec1-linux-git/#hello-world","text":"We begin with the ubiquitous \"Hello, World\" example. To display the message \"Hello, World\" we will use the echo command. The echo command simply \"echoes\" its input to the console. 1 % echo Hello, World The string we provide to the echo command is called a command line argument . We use command line arguments to tell commands what they should operate on. Note that you do not need to enter % character. In a tutorial like this, the % simply indicates what you should type at the command line. To-Do On Your Own Experiment with using the echo command to display different messages.","title":"Hello World"},{"location":"ece2400-sec1-linux-git/#manual-pages","text":"You can learn more about any Linux command by using the man command. Try using this to learn more about the echo command. 1 % man echo You can use the up/down keys to scroll the manual one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the manual.","title":"Manual Pages"},{"location":"ece2400-sec1-linux-git/#create-view-and-list-files","text":"We can use the echo command and a feature called command output redirection to create simple text files. Command output redirection is discussed more in the full tutorial. Command output redirection uses the operator to take the output from one command and \"redirect\" it to a file. The following commands will create a new file named ece2400-tut1.txt that simply contains the text \"Computer Systems Programming\". 1 % echo Computer Systems Programming ece2400-tut1.txt We can use the cat command to quickly display the contents of a file. 1 % cat ece2400-tut1.txt For larger files, cat will output the entire file to the console so it may be hard to read the file as it streams past. We can use the less command to show one screen-full of text at a time. You can use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the file. 1 % less ece2400-tut1.txt You can use the ls command to list the filenames of the files you have created. 1 % ls We can provide command line options to the ls command to modify the command\u2019s behavior. For example, we can use the -1 (i.e., a dash followed by the number one) command line option to list one file per line, and we can we can use the -l (i.e., a dash followed by the letter l) command line option to provide a longer listing with more information about each file. To-Do On Your Own Create a new file named ece2400-tut1-layer3.txt which contains the third layer in the computing systems stack (i.e., programming language). Use cat and less to verify the file contents.","title":"Create, View, and List Files"},{"location":"ece2400-sec1-linux-git/#create-change-and-list-directories","text":"Obviously, having all files in a single location would be hard to manage effectively. We can use directories (also called folders) to logically organize our files, just like one can use physical folders to organize physical pieces of paper. The mechanism for organizing files and directories is called the file system. When you first login to an ecelinux machine, you will be in your home directory. This is your own private space on the server that you can use to work on the programming assignments and store your files. You can use the pwd command to print the directory in which you are currently working, which is known as the current working directory. 1 2 % pwd /home/ netid You should see output similar to what is shown above, but instead of netid it should show your actual NetID. The pwd command shows a directory path. A directory path is a list of nested directory names; it describes a \"path\" to get to a specific file or directory. So the above path indicates that there is a toplevel directory named home that contains a directory named netid . This is the directory path to your home directory. As an aside, notice that Linux uses a forward slash ( / ) to separate directories, while Windows uses a back slash ( \\ ) for the same purpose. We can use the mkdir command to make new directories. The following command will make a new directory named ece2400 within your home directory. 1 % mkdir ece2400 We can use the cd command to change our current working directory. The following command will change the current working directory to be the newly created ece2400 directory, before displaying the current working directory with the pwd command. 1 2 3 % cd ece2400 % pwd /home/ netid /ece2400 Use the mkdir , cd , and pwd commands to make another directory. 1 2 3 4 % mkdir tut1 % cd tut1 % pwd /home/ netid /ece2400/tut1 We sometimes say that tut1 is a subdirectory or a child directory of the ece2400 directory. We might also say that the ece2400 directory is the parent directory of the tut1 directory. Use the following command to create a new file in this child directory. 1 2 3 4 % cd /home/ netid /ece2400/tut1 % echo Computer Systems Programming ece2400-tut1.txt % mkdir dirA % ls You can use the tree command to visualize the directory layout and where files are located: 1 2 % cd ~/ece2400 % tree Note that the tilde character ( ~ ) is a shortcut which always refers to your home directory. There are a few other very useful shortcuts. You can use a single dot ( . ) to refer to the current working directory, and you can use a double dot ( .. ) to refer to the parent directory of the current working directory. 1 2 3 4 % cd ~/ece2400/tut1 % cd .. % cd .. % pwd To-Do On Your Own Experiment with creating additional directories and files within the ece2400/tut1 subdirectory. Try using the tree command to display your newly created directory hierarchy.","title":"Create, Change, and List Directories"},{"location":"ece2400-sec1-linux-git/#copy-move-and-remove-files-and-directories","text":"We can use the cp command to copy files. The first argument is the name of the file you want to copy, and the second argument is the new name to give to the copy. The following commands will make two copies of the files we created in the previous section. 1 2 3 4 % cd ~/ece2400/tut1 % cp ece2400-tut1.txt ece2400-tut1-a.txt % cp ece2400-tut1.txt ece2400-tut1-b.txt % ls Instead of copying we can also move a file with the mv command: 1 2 3 % cd ~/ece2400/tut1 % mv ece2400-tut1.txt ece2400-tut1-c.txt % ls Finally, we can use the rm command to remove files. 1 2 3 % cd ~/ece2400/tut1 % ls % rm ece2400-tut1-a.txt To-Do On Your Own Creating additional directories and files within the ece2400/tut1 subdirectory, and then use the cp , mv , and rm commands to copy, move, and remove the newly created directories and files. Use the ls and tree commands to display your file and directory organization.","title":"Copy, Move, and Remove Files and Directories"},{"location":"ece2400-sec1-linux-git/#course-setup-script","text":"Once you are logged into an ecelinux machine, you will need to setup the working environment with the following command in order to work on the course programming assignments. 1 % source setup-ece2400.sh","title":"Course Setup Script"},{"location":"ece2400-sec1-linux-git/#editors","text":"Students are free to use any text editor they want. We recommend geany . You can start geany like this: 1 % geany Try opening and editing the ece2400-tut1.txt file you created earlier.","title":"Editors"},{"location":"ece2400-sec1-linux-git/#4-git-distributed-version-control-system","text":"In this course, we will be using Git as our revision control and source code management system. We will be using GitHub for centralized online repository hosting, and TravisCI for online continuous integration testing. These tools will enable us to adopt an agile hardware development methodology so your group can rapidly collaborate and iterate on the design, verification, and evaluation of the assignments. You can check to see if you have a GitHub account on github.com using this link: https://github.com/githubid where githubid is your GitHub username on github.com . If the above link does not work, then you do not have an GitHub account on github.com . You will need to create one here: https://github.com/join Your NetID makes a great GitHub username on github.com. Be sure to use your Cornell University email address. Once your account is setup, please make sure you set your full name so we can know who you are on GitHub.","title":"4. Git Distributed Version Control System"},{"location":"ece2400-sec1-linux/","text":"Section 1: Linux Development Environment This section serves as gentle introduction to the basics of using the Linux development environment on the ecelinux machines including how to log into the machines, how to work at the Linux command line, and how to use Git version control. 1. The ecelinux Machines We will be using the ecelinux workstations and servers for all of the programming assignments. The ecelinux machines all run the Red Hat Enterprise Linux 7 operating system, and they all use an identical setup. Linux is the operating system of choice for both cloud and IoT systems, so becoming familiar with Linux will pay dividends beyond just this course. Options For Using ecelinux Machines directly use workstations in 314 Phillips Linux Lab log in remotely from workstations in 318 Phillips Windows Lab log in remotely from your own laptop in this discussion section, we will be logging in remotely from the workstations in the 318 Phillips Windows Lab Using MobaXterm to Log Into the ecelinux Servers The first step is to log into the Windows workstation using your NetID and your standard NetID password. The second step is to start MobaXterm. From the Start menu, choose MobaXterm Educational Edition MobaXterm Educational Edition . Then double click on ecelinux.ece.cornell.edu under Saved sessions in MobaXterm. Log in using your NetID and password. Click Yes when asked if you want to save your password. This will make it easier to open multiple terminals if you need to. All of your credentials will be deleted when you restart the workstation so there is no security concern. If you cannot log in into ecelinux , then it may be because you are either not enrolled in the course or you added the course this morning. We will be updating the access list often. Using Multiple Terminals in MobaXterm It is often very useful to have multiple terminals open at the same time. From the menu, choose Sessions ecelinux.ece.cornell.edu to create a new tab with a second terminal. Enter your NetID and you should be logged into the ecelinux servers. Now you can move back and forth between the two terminals. You can also detach a tab so you can have two terminals side-by-side. From the menu, choose Terminal Detach . Then drag the new window all the way to the left so it fills up the left-hand side of your screen. Drag the original MobaXterm all the way to the left so it fills up the right-hand size of your screen. Now you have two terminals side-by-side, enabling you to be doing multiple things on the server at the same time. 2. ecelinux Account Setup The very first thing you need to do after logging into a ecelinux machine is source the course setup script. This will ensure your environment is setup with everything you need for working on the programming assignments. Enter the following command on the command line: 1 % source setup-ece2400.sh Note that you do not need to enter % character. In a tutorial like this, the % simply indicates what you should type at the command line. You should now see ECE 2400 in your prompt which means your environment is setup for the course. It can be tedious to always remember to source the course setup script. You can also use auto setup which will automatically source the course setup for you when you log in. Note that if the environment for ECE 2400 conflicts with the environment required by a different course then you will need to manually source the setup script when you are working on this course. Enter the following command on the command line to use auto setup: 1 % source setup-ece2400.sh --enable-auto-setup Now quit MobaXterm, restart MobaXterm, and log back into the ecelinux server. You should see ECE 2400 in the prompt meaning your environment is automatically setup for the course. If at anytime you need to disable auto setup you can use the following command: 1 % source setup-ece2400.sh --disable-auto-setup Now that we have source the course setup script we can start to explore the Linux command line. 3. Linux Command Line We will using the ecelinux workstations and servers which run the Red Hat Enterprise Linux 7 operating system for all of the programming assignments. The heart of the Linux operating system is the Linux command line. This is a text-based console where you can enter commands to interact with the operating system. Hello World We begin with the ubiquitous \"Hello, World\" example. To display the message \"Hello, World\" we will use the echo command. The echo command simply \"echoes\" its input to the console. 1 % echo Hello, World The string we provide to the echo command is called a command line argument . We use command line arguments to tell commands what they should operate on. Again, note that you do not need to enter % character. To-Do On Your Own Experiment with using the echo command to display different messages. Manual Pages You can learn more about any Linux command by using the man command. Try using this to learn more about the echo command. 1 % man echo You can use the up/down keys to scroll the manual one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the manual. Create, View, and List Files We can use the echo command and a feature called command output redirection to create simple text files. Command output redirection is discussed more in the full tutorial. Command output redirection uses the operator to take the output from one command and \"redirect\" it to a file. The following commands will create a new file named ece2400-sec1.txt that simply contains the text \"Computer Systems Programming\". 1 % echo Computer Systems Programming ece2400-sec1.txt We can use the cat command to quickly display the contents of a file. 1 % cat ece2400-sec1.txt For larger files, cat will output the entire file to the console so it may be hard to read the file as it streams past. We can use the less command to show one screen-full of text at a time. You can use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the file. 1 % less ece2400-sec1.txt You can use the ls command to list the filenames of the files you have created. 1 % ls We can provide command line options to the ls command to modify the command\u2019s behavior. For example, we can use the -1 (i.e., a dash followed by the number one) command line option to list one file per line, and we can we can use the -l (i.e., a dash followed by the letter l) command line option to provide a longer listing with more information about each file. To-Do On Your Own Create a new file named ece2400-sec1-layer3.txt which contains the third layer in the computing systems stack (i.e., programming language). Use cat and less to verify the file contents. Create, Change, and List Directories Obviously, having all files in a single location would be hard to manage effectively. We can use directories (also called folders) to logically organize our files, just like one can use physical folders to organize physical pieces of paper. The mechanism for organizing files and directories is called the file system. When you first login to an ecelinux machine, you will be in your home directory. This is your own private space on the server that you can use to work on the programming assignments and store your files. You can use the pwd command to print the directory in which you are currently working, which is known as the current working directory. 1 2 % pwd /home/netid You should see output similar to what is shown above, but instead of netid it should show your actual NetID. The pwd command shows a directory path. A directory path is a list of nested directory names; it describes a \"path\" to get to a specific file or directory. So the above path indicates that there is a toplevel directory named home that contains a directory named netid . This is the directory path to your home directory. As an aside, notice that Linux uses a forward slash ( / ) to separate directories, while Windows uses a back slash ( \\ ) for the same purpose. We can use the mkdir command to make new directories. The following command will make a new directory named ece2400 within your home directory. 1 % mkdir ece2400 We can use the cd command to change our current working directory. The following command will change the current working directory to be the newly created ece2400 directory, before displaying the current working directory with the pwd command. 1 2 3 % cd ece2400 % pwd /home/netid/ece2400 Use the mkdir , cd , and pwd commands to make another directory. 1 2 3 4 % mkdir sec1 % cd sec1 % pwd /home/netid/ece2400/sec1 We sometimes say that sec1 is a subdirectory or a child directory of the ece2400 directory. We might also say that the ece2400 directory is the parent directory of the sec1 directory. Use the following command to create a new file in this child directory. 1 2 3 4 % cd /home/netid/ece2400/sec1 % echo Computer Systems Programming ece2400-sec1.txt % mkdir dirA % ls You can use the tree command to visualize the directory layout and where files are located: 1 2 % cd ~/ece2400 % tree Note that the tilde character ( ~ ) is a shortcut which always refers to your home directory. There are a few other very useful shortcuts. You can use a single dot ( . ) to refer to the current working directory, and you can use a double dot ( .. ) to refer to the parent directory of the current working directory. 1 2 3 4 % cd ~/ece2400/sec1 % cd .. % cd .. % pwd To-Do On Your Own Experiment with creating additional directories and files within the ece2400/sec1 subdirectory. Try using the tree command to display your newly created directory hierarchy. Copy, Move, and Remove Files and Directories We can use the cp command to copy files. The first argument is the name of the file you want to copy, and the second argument is the new name to give to the copy. The following commands will make two copies of the files we created in the previous section. 1 2 3 4 % cd ~/ece2400/sec1 % cp ece2400-sec1.txt ece2400-sec1-a.txt % cp ece2400-sec1.txt ece2400-sec1-b.txt % ls Instead of copying we can also move a file with the mv command: 1 2 3 % cd ~/ece2400/sec1 % mv ece2400-sec1.txt ece2400-sec1-c.txt % ls Finally, we can use the rm command to remove files. 1 2 3 % cd ~/ece2400/sec1 % ls % rm ece2400-sec1-a.txt To-Do On Your Own Creating additional directories and files within the ece2400/sec1 subdirectory, and then use the cp , mv , and rm commands to copy, move, and remove the newly created directories and files. Use the ls and tree commands to display your file and directory organization. Text Editors Students are free to use any text editor they want. We recommend using either Micro or Geany. You can start Micro like this: 1 % micro ece2400-sec1-b.txt Micro is a lightweight text-based text editor. Use Ctrl-G to learn more about the keyboard shortcuts you can use to in Micro. You can start Geany like this: 1 % geany ece2400-sec1-b.txt Geany is a graphical-based text editor. Notice the character at the end of the command line. This indicates that Linux should run Geany in the background meaning you can still work at the command line while Geany is running in a different window. To-Do On Your Own Try editing the ece2400-sec1.txt file you created earlier using either Micro or Geany. Save the file and then view your changes from the command line using cat . When you are finished go ahead and delete the sec1 directory to keep things tidy. 1 % rm -rf ~/ece2400/sec1 4. GitHub Account Setup We will be using GitHub for centralized repository hosting. You can check to see if you have a GitHub account on github.com using this link: https://github.com/githubid where githubid is your GitHub username on github.com . If the above link does not work, then you do not have an GitHub account on github.com . NOTE: We are using github.com not the Cornell hosted GitHub! You will need to create one here: https://github.com/join Your NetID makes a great GitHub username on github.com . Be sure to use your Cornell University email address. Once your account is setup, please make sure you set your full name so we can know who you are on GitHub. Please also consider uploading a profile photo to GitHub; it makes it more fun to interact on GitHub if we all know what each other look like. Go to the following page and enter your first and last name in the Name field, and then consider uploading a profile photo. https://github.com/settings/profile Once you have a GitHub ID, please fill out the following online so the instructors know the mapping from NetID to GitHub ID: http://www.csl.cornell.edu/courses/ece2400/signup Before you can begin using GitHub, you need to create an SSH key pair on an ecelinux machine and upload the corresponding SSH public key to GitHub. GitHub uses these keys for authentication. The course setup script takes care of creating an SSH key pair which you can use. View the contents of your public key using the following commands: 1 % cat ~/.ssh/ece2400-github.pub Use the following page to upload the public key to GitHub: https://github.com/settings/ssh Click on New SSH Key , and then cut-and-paste the public key you displayed using cat into the key textbox. Give the key the title ece2400-github . Then click Add SSH key . To test things out try the following command: 1 % ssh -T git@github.com You may see a warning about the authenticity of the host. Don\u2019t worry, this is supposed to happen the first time you access GitHub using your new key. Just enter yes . The GitHub server should output some text including your GitHub ID. Verify that the GitHub ID is correct, and then you should be all set. 5. Git Version Control System In this course, we will be using Git as our revision control and source code management system. Git will enable us to adopt an agile hardware development methodology so you (and your group) can rapidly collaborate and iterate on the design, verification, and evaluation of the assignments. Fork and Clone a Repo from GitHub Fork'ing a repo means making a copy of that repo for your own local use. We won't actually be forking repos for the programming assignments, but it is an easy way for you to grab some example code for the discussion section. Go to the example repo here: https://github.com/cornell-ece2400/ece2400-sec1 Click on the \"Fork\" button. Wait a few seconds and then visit the new copy of this repo in your own person GitHub workspace: https://github.com/githubid/ece2400-sec1 Where githubid is your GitHubID. Now let's clone your new repo to the ecelinux machine. 1 2 3 4 % cd ${ HOME } /ece2400 % git clone git@github.com:githubid/ece2400-sec1 sec1 % cd sec1 % cat README.md Where githubid is your GitHubID. Adding and Committing Files to Local Repository Now let's add some new files to the repository. Use your favorite text editor (e.g., Micro, Geany) to create a file named warm-colors.txt with three warm colors: 1 2 3 red orange yellow Now use your favorite text editor again to create a file named cool-colors.txt with three cool colors. 1 2 3 blue green purple Now let's add these files to our repository. First use the git status command to check on the status of the repository. 1 2 % cd ${ HOME } /ece2400/sec1 % git status You should see that git has noticed two \"untracked files\" which are in the working directory but are not currently being tracked by git. Let's \"add\" these two files to git's \"staging\" area so it now knows it should keep track of them: 1 2 3 4 % cd ${ HOME } /ece2400/sec1 % git add warm-colors.txt % git add cool-colors.txt % git status The status of these two files have changed. Git reports that both of the new files are ready to be committed. Let's go ahead and commit these changes into your local repository. 1 2 % cd ${ HOME } /ece2400/sec1 % git commit -m add some colors To-Do On Your Own Try adding cyan to the cool-colors.txt file you created earlier using either Micro or Geany. Save the file and then view your changes from the command line using cat . Then use git status , git add , and git commit to add these changes to local repository. Pushing Files to GitHub Note that nothing has happened on GitHub yet. GitHub does not know anything about these local changes. We need to explicitly \"push\" our new commits up to GitHub like this: 1 2 % cd ${ HOME } /ece2400/sec1 % git push Now go to the repository page using the GitHub web interface and verify that there are two new files. https://github.com/githubid/ece2400-sec1 To-Do On Your Own Try adding mustard to the warm-colors.txt file you created earlier using either Micro or Geany. Save the file and then view your changes from the command line using cat . Then use git status , git add , and git commit to add these changes to local repository, and then use git push to push these changes up to GitHub. View the changes using the GitHub web interface. Pulling Files from GitHub Let's try making a change to this repository through the GitHub web interface. https://github.com/githubid/ece2400-sec1 Click on Create new file . Name the file languages.txt and add a list of programming languages: 1 2 3 4 5 C C++ Python MATLAB Java Now click Commit new file . Verify that there is a new file in the repo using the GitHub web interface. Now let's \"pull\" these new changes from GitHub to your local repo on ecelinux : 1 2 3 % cd ${ HOME } /ece2400/sec1 % git pull % cat languages.txt This will be the basic GitHub workflow were students pull and push code between GitHub and the ecelinux machines. To-Do On Your Own Try editing a file using the GitHub web interface. Click on the warm-colors.txt file and then click on the pencil in the right-hand corner to edit this text file. Add another warm color. Click Commit changes . Then pull these changes to the local repository on the ecelinux server and verify that your new warm color is included.","title":"Section 1: Linux Development Environment"},{"location":"ece2400-sec1-linux/#section-1-linux-development-environment","text":"This section serves as gentle introduction to the basics of using the Linux development environment on the ecelinux machines including how to log into the machines, how to work at the Linux command line, and how to use Git version control.","title":"Section 1: Linux Development Environment"},{"location":"ece2400-sec1-linux/#1-the-ecelinux-machines","text":"We will be using the ecelinux workstations and servers for all of the programming assignments. The ecelinux machines all run the Red Hat Enterprise Linux 7 operating system, and they all use an identical setup. Linux is the operating system of choice for both cloud and IoT systems, so becoming familiar with Linux will pay dividends beyond just this course.","title":"1. The ecelinux Machines"},{"location":"ece2400-sec1-linux/#options-for-using-ecelinux-machines","text":"directly use workstations in 314 Phillips Linux Lab log in remotely from workstations in 318 Phillips Windows Lab log in remotely from your own laptop in this discussion section, we will be logging in remotely from the workstations in the 318 Phillips Windows Lab","title":"Options For Using ecelinux Machines"},{"location":"ece2400-sec1-linux/#using-mobaxterm-to-log-into-the-ecelinux-servers","text":"The first step is to log into the Windows workstation using your NetID and your standard NetID password. The second step is to start MobaXterm. From the Start menu, choose MobaXterm Educational Edition MobaXterm Educational Edition . Then double click on ecelinux.ece.cornell.edu under Saved sessions in MobaXterm. Log in using your NetID and password. Click Yes when asked if you want to save your password. This will make it easier to open multiple terminals if you need to. All of your credentials will be deleted when you restart the workstation so there is no security concern. If you cannot log in into ecelinux , then it may be because you are either not enrolled in the course or you added the course this morning. We will be updating the access list often.","title":"Using MobaXterm to Log Into the ecelinux Servers"},{"location":"ece2400-sec1-linux/#using-multiple-terminals-in-mobaxterm","text":"It is often very useful to have multiple terminals open at the same time. From the menu, choose Sessions ecelinux.ece.cornell.edu to create a new tab with a second terminal. Enter your NetID and you should be logged into the ecelinux servers. Now you can move back and forth between the two terminals. You can also detach a tab so you can have two terminals side-by-side. From the menu, choose Terminal Detach . Then drag the new window all the way to the left so it fills up the left-hand side of your screen. Drag the original MobaXterm all the way to the left so it fills up the right-hand size of your screen. Now you have two terminals side-by-side, enabling you to be doing multiple things on the server at the same time.","title":"Using Multiple Terminals in MobaXterm"},{"location":"ece2400-sec1-linux/#2-ecelinux-account-setup","text":"The very first thing you need to do after logging into a ecelinux machine is source the course setup script. This will ensure your environment is setup with everything you need for working on the programming assignments. Enter the following command on the command line: 1 % source setup-ece2400.sh Note that you do not need to enter % character. In a tutorial like this, the % simply indicates what you should type at the command line. You should now see ECE 2400 in your prompt which means your environment is setup for the course. It can be tedious to always remember to source the course setup script. You can also use auto setup which will automatically source the course setup for you when you log in. Note that if the environment for ECE 2400 conflicts with the environment required by a different course then you will need to manually source the setup script when you are working on this course. Enter the following command on the command line to use auto setup: 1 % source setup-ece2400.sh --enable-auto-setup Now quit MobaXterm, restart MobaXterm, and log back into the ecelinux server. You should see ECE 2400 in the prompt meaning your environment is automatically setup for the course. If at anytime you need to disable auto setup you can use the following command: 1 % source setup-ece2400.sh --disable-auto-setup Now that we have source the course setup script we can start to explore the Linux command line.","title":"2. ecelinux Account Setup"},{"location":"ece2400-sec1-linux/#3-linux-command-line","text":"We will using the ecelinux workstations and servers which run the Red Hat Enterprise Linux 7 operating system for all of the programming assignments. The heart of the Linux operating system is the Linux command line. This is a text-based console where you can enter commands to interact with the operating system.","title":"3. Linux Command Line"},{"location":"ece2400-sec1-linux/#hello-world","text":"We begin with the ubiquitous \"Hello, World\" example. To display the message \"Hello, World\" we will use the echo command. The echo command simply \"echoes\" its input to the console. 1 % echo Hello, World The string we provide to the echo command is called a command line argument . We use command line arguments to tell commands what they should operate on. Again, note that you do not need to enter % character. To-Do On Your Own Experiment with using the echo command to display different messages.","title":"Hello World"},{"location":"ece2400-sec1-linux/#manual-pages","text":"You can learn more about any Linux command by using the man command. Try using this to learn more about the echo command. 1 % man echo You can use the up/down keys to scroll the manual one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the manual.","title":"Manual Pages"},{"location":"ece2400-sec1-linux/#create-view-and-list-files","text":"We can use the echo command and a feature called command output redirection to create simple text files. Command output redirection is discussed more in the full tutorial. Command output redirection uses the operator to take the output from one command and \"redirect\" it to a file. The following commands will create a new file named ece2400-sec1.txt that simply contains the text \"Computer Systems Programming\". 1 % echo Computer Systems Programming ece2400-sec1.txt We can use the cat command to quickly display the contents of a file. 1 % cat ece2400-sec1.txt For larger files, cat will output the entire file to the console so it may be hard to read the file as it streams past. We can use the less command to show one screen-full of text at a time. You can use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the q key to quit viewing the file. 1 % less ece2400-sec1.txt You can use the ls command to list the filenames of the files you have created. 1 % ls We can provide command line options to the ls command to modify the command\u2019s behavior. For example, we can use the -1 (i.e., a dash followed by the number one) command line option to list one file per line, and we can we can use the -l (i.e., a dash followed by the letter l) command line option to provide a longer listing with more information about each file. To-Do On Your Own Create a new file named ece2400-sec1-layer3.txt which contains the third layer in the computing systems stack (i.e., programming language). Use cat and less to verify the file contents.","title":"Create, View, and List Files"},{"location":"ece2400-sec1-linux/#create-change-and-list-directories","text":"Obviously, having all files in a single location would be hard to manage effectively. We can use directories (also called folders) to logically organize our files, just like one can use physical folders to organize physical pieces of paper. The mechanism for organizing files and directories is called the file system. When you first login to an ecelinux machine, you will be in your home directory. This is your own private space on the server that you can use to work on the programming assignments and store your files. You can use the pwd command to print the directory in which you are currently working, which is known as the current working directory. 1 2 % pwd /home/netid You should see output similar to what is shown above, but instead of netid it should show your actual NetID. The pwd command shows a directory path. A directory path is a list of nested directory names; it describes a \"path\" to get to a specific file or directory. So the above path indicates that there is a toplevel directory named home that contains a directory named netid . This is the directory path to your home directory. As an aside, notice that Linux uses a forward slash ( / ) to separate directories, while Windows uses a back slash ( \\ ) for the same purpose. We can use the mkdir command to make new directories. The following command will make a new directory named ece2400 within your home directory. 1 % mkdir ece2400 We can use the cd command to change our current working directory. The following command will change the current working directory to be the newly created ece2400 directory, before displaying the current working directory with the pwd command. 1 2 3 % cd ece2400 % pwd /home/netid/ece2400 Use the mkdir , cd , and pwd commands to make another directory. 1 2 3 4 % mkdir sec1 % cd sec1 % pwd /home/netid/ece2400/sec1 We sometimes say that sec1 is a subdirectory or a child directory of the ece2400 directory. We might also say that the ece2400 directory is the parent directory of the sec1 directory. Use the following command to create a new file in this child directory. 1 2 3 4 % cd /home/netid/ece2400/sec1 % echo Computer Systems Programming ece2400-sec1.txt % mkdir dirA % ls You can use the tree command to visualize the directory layout and where files are located: 1 2 % cd ~/ece2400 % tree Note that the tilde character ( ~ ) is a shortcut which always refers to your home directory. There are a few other very useful shortcuts. You can use a single dot ( . ) to refer to the current working directory, and you can use a double dot ( .. ) to refer to the parent directory of the current working directory. 1 2 3 4 % cd ~/ece2400/sec1 % cd .. % cd .. % pwd To-Do On Your Own Experiment with creating additional directories and files within the ece2400/sec1 subdirectory. Try using the tree command to display your newly created directory hierarchy.","title":"Create, Change, and List Directories"},{"location":"ece2400-sec1-linux/#copy-move-and-remove-files-and-directories","text":"We can use the cp command to copy files. The first argument is the name of the file you want to copy, and the second argument is the new name to give to the copy. The following commands will make two copies of the files we created in the previous section. 1 2 3 4 % cd ~/ece2400/sec1 % cp ece2400-sec1.txt ece2400-sec1-a.txt % cp ece2400-sec1.txt ece2400-sec1-b.txt % ls Instead of copying we can also move a file with the mv command: 1 2 3 % cd ~/ece2400/sec1 % mv ece2400-sec1.txt ece2400-sec1-c.txt % ls Finally, we can use the rm command to remove files. 1 2 3 % cd ~/ece2400/sec1 % ls % rm ece2400-sec1-a.txt To-Do On Your Own Creating additional directories and files within the ece2400/sec1 subdirectory, and then use the cp , mv , and rm commands to copy, move, and remove the newly created directories and files. Use the ls and tree commands to display your file and directory organization.","title":"Copy, Move, and Remove Files and Directories"},{"location":"ece2400-sec1-linux/#text-editors","text":"Students are free to use any text editor they want. We recommend using either Micro or Geany. You can start Micro like this: 1 % micro ece2400-sec1-b.txt Micro is a lightweight text-based text editor. Use Ctrl-G to learn more about the keyboard shortcuts you can use to in Micro. You can start Geany like this: 1 % geany ece2400-sec1-b.txt Geany is a graphical-based text editor. Notice the character at the end of the command line. This indicates that Linux should run Geany in the background meaning you can still work at the command line while Geany is running in a different window. To-Do On Your Own Try editing the ece2400-sec1.txt file you created earlier using either Micro or Geany. Save the file and then view your changes from the command line using cat . When you are finished go ahead and delete the sec1 directory to keep things tidy. 1 % rm -rf ~/ece2400/sec1","title":"Text Editors"},{"location":"ece2400-sec1-linux/#4-github-account-setup","text":"We will be using GitHub for centralized repository hosting. You can check to see if you have a GitHub account on github.com using this link: https://github.com/githubid where githubid is your GitHub username on github.com . If the above link does not work, then you do not have an GitHub account on github.com . NOTE: We are using github.com not the Cornell hosted GitHub! You will need to create one here: https://github.com/join Your NetID makes a great GitHub username on github.com . Be sure to use your Cornell University email address. Once your account is setup, please make sure you set your full name so we can know who you are on GitHub. Please also consider uploading a profile photo to GitHub; it makes it more fun to interact on GitHub if we all know what each other look like. Go to the following page and enter your first and last name in the Name field, and then consider uploading a profile photo. https://github.com/settings/profile Once you have a GitHub ID, please fill out the following online so the instructors know the mapping from NetID to GitHub ID: http://www.csl.cornell.edu/courses/ece2400/signup Before you can begin using GitHub, you need to create an SSH key pair on an ecelinux machine and upload the corresponding SSH public key to GitHub. GitHub uses these keys for authentication. The course setup script takes care of creating an SSH key pair which you can use. View the contents of your public key using the following commands: 1 % cat ~/.ssh/ece2400-github.pub Use the following page to upload the public key to GitHub: https://github.com/settings/ssh Click on New SSH Key , and then cut-and-paste the public key you displayed using cat into the key textbox. Give the key the title ece2400-github . Then click Add SSH key . To test things out try the following command: 1 % ssh -T git@github.com You may see a warning about the authenticity of the host. Don\u2019t worry, this is supposed to happen the first time you access GitHub using your new key. Just enter yes . The GitHub server should output some text including your GitHub ID. Verify that the GitHub ID is correct, and then you should be all set.","title":"4. GitHub Account Setup"},{"location":"ece2400-sec1-linux/#5-git-version-control-system","text":"In this course, we will be using Git as our revision control and source code management system. Git will enable us to adopt an agile hardware development methodology so you (and your group) can rapidly collaborate and iterate on the design, verification, and evaluation of the assignments.","title":"5. Git Version Control System"},{"location":"ece2400-sec1-linux/#fork-and-clone-a-repo-from-github","text":"Fork'ing a repo means making a copy of that repo for your own local use. We won't actually be forking repos for the programming assignments, but it is an easy way for you to grab some example code for the discussion section. Go to the example repo here: https://github.com/cornell-ece2400/ece2400-sec1 Click on the \"Fork\" button. Wait a few seconds and then visit the new copy of this repo in your own person GitHub workspace: https://github.com/githubid/ece2400-sec1 Where githubid is your GitHubID. Now let's clone your new repo to the ecelinux machine. 1 2 3 4 % cd ${ HOME } /ece2400 % git clone git@github.com:githubid/ece2400-sec1 sec1 % cd sec1 % cat README.md Where githubid is your GitHubID.","title":"Fork and Clone a Repo from GitHub"},{"location":"ece2400-sec1-linux/#adding-and-committing-files-to-local-repository","text":"Now let's add some new files to the repository. Use your favorite text editor (e.g., Micro, Geany) to create a file named warm-colors.txt with three warm colors: 1 2 3 red orange yellow Now use your favorite text editor again to create a file named cool-colors.txt with three cool colors. 1 2 3 blue green purple Now let's add these files to our repository. First use the git status command to check on the status of the repository. 1 2 % cd ${ HOME } /ece2400/sec1 % git status You should see that git has noticed two \"untracked files\" which are in the working directory but are not currently being tracked by git. Let's \"add\" these two files to git's \"staging\" area so it now knows it should keep track of them: 1 2 3 4 % cd ${ HOME } /ece2400/sec1 % git add warm-colors.txt % git add cool-colors.txt % git status The status of these two files have changed. Git reports that both of the new files are ready to be committed. Let's go ahead and commit these changes into your local repository. 1 2 % cd ${ HOME } /ece2400/sec1 % git commit -m add some colors To-Do On Your Own Try adding cyan to the cool-colors.txt file you created earlier using either Micro or Geany. Save the file and then view your changes from the command line using cat . Then use git status , git add , and git commit to add these changes to local repository.","title":"Adding and Committing Files to Local Repository"},{"location":"ece2400-sec1-linux/#pushing-files-to-github","text":"Note that nothing has happened on GitHub yet. GitHub does not know anything about these local changes. We need to explicitly \"push\" our new commits up to GitHub like this: 1 2 % cd ${ HOME } /ece2400/sec1 % git push Now go to the repository page using the GitHub web interface and verify that there are two new files. https://github.com/githubid/ece2400-sec1 To-Do On Your Own Try adding mustard to the warm-colors.txt file you created earlier using either Micro or Geany. Save the file and then view your changes from the command line using cat . Then use git status , git add , and git commit to add these changes to local repository, and then use git push to push these changes up to GitHub. View the changes using the GitHub web interface.","title":"Pushing Files to GitHub"},{"location":"ece2400-sec1-linux/#pulling-files-from-github","text":"Let's try making a change to this repository through the GitHub web interface. https://github.com/githubid/ece2400-sec1 Click on Create new file . Name the file languages.txt and add a list of programming languages: 1 2 3 4 5 C C++ Python MATLAB Java Now click Commit new file . Verify that there is a new file in the repo using the GitHub web interface. Now let's \"pull\" these new changes from GitHub to your local repo on ecelinux : 1 2 3 % cd ${ HOME } /ece2400/sec1 % git pull % cat languages.txt This will be the basic GitHub workflow were students pull and push code between GitHub and the ecelinux machines. To-Do On Your Own Try editing a file using the GitHub web interface. Click on the warm-colors.txt file and then click on the pencil in the right-hand corner to edit this text file. Add another warm color. Click Commit changes . Then pull these changes to the local repository on the ecelinux server and verify that your new warm color is included.","title":"Pulling Files from GitHub"},{"location":"ece2400-sec2-c-basics/","text":"Section 2: Compiling and Running C Programs This section serves as gentle introduction to the basics of compiling and running C programs on the ecelinux machines. The corresponding tutorial provides significantly more detail and background. 1. The ecelinux Machines Follow the same process as in the last section. login to a workstation with your NetID and password for the discussion section, we will be using screensharing via zoom start zoom, choose from menubar: Applications Internet Zoom click \"Join a Meeting\" enter \"ece2400\" in the text box check \"Don't connect to Audio\" check \"Turn off my video\" click \"Join\" click \"View Options\" at the top choose \"Exit Full Screen\"_ drag window over to the right-hand edge to make it take up the right half of the screen 2. Basic Git Usage In this course, we will be using Git as our revision control and source code management system. We will be using GitHub for centralized online repository hosting, and TravisCI for online continuous integration testing. These tools will enable us to adopt an agile hardware development methodology so your group can rapidly collaborate and iterate on the design, verification, and evaluation of the assignments. You should have already setup your GitHub account on github.com during the previous section. Please also make sure you have setup your ssh keys correctly (see Section 2 of the ECE 2400 Tutorial 2). Fork'ing a repo means making a copy of that repo for your own local use. We won't actually be forking repos for the programming assignments, but it is an easy way for you to grab some example code for the discussion section. Go to the example repo here: https://github.com/cornell-ece2400/ece2400-sec2 Click on the \"Fork\" button. Wait a few seconds and then visit the new copy of this repo in your own person GitHub workspace: https://github.com/ githubid /ece2400-sec2 Where githubid is your GitHubID. Now let's clone your new repo to the ecelinux machine. 1 2 3 4 5 % source setup-ece2400.sh % cd ${ HOME } /ece2400 % git clone git@github.com: githubid /ece2400-sec2 sec2 % cd sec2 % cat README.md Where githubid is your GitHubID. Now let's add some new files to the repository. Use your favorite text editor (e.g., Geany) to create a file named warm-colors.txt with three warm colors: 1 2 3 red orange yellow Now use your favorite text editor again to create a file named cool-colors.txt with three cool colors. 1 2 3 blue green purple Now let's add these files to our repository. First use the git status command to check on the status of the repository. 1 2 % cd ${ HOME } /ece2400/sec2 % git status You should see that git has noticed two \"untracked files\" which are in the working directory but are not currently being tracked by git. Let's \"add\" these two files to git's \"staging\" area so it now knows it should keep track of them: 1 2 3 4 % cd ${ HOME } /ece2400/sec2 % git add warm-colors.txt % git add cool-colors.txt % git status The status of these two files have changed. Git reports that both of the new files are ready to be committed. Let's go ahead and commit these changes into your local repository. 1 2 % cd ${ HOME } /ece2400/sec2 % git commit -m add some colors Note that nothing has happened on GitHub yet. GitHub does not know anything about these local changes. We need to explicitly \"push\" our new commits up to GitHub like this: 1 2 % cd ${ HOME } /ece2400/sec2 % git push Now go to the repository page on GitHub and verify that there are two new files. Let's try making a change to this repository through the GitHub web interface. Click on \"Create new file\". Name the file languages.txt and add a list of programming languages: 1 2 3 4 5 C C++ Python MATLAB Java Now click \"Commit new file\". Verify that there is a new file in the repo using the GitHub web interface. Now let's \"pull\" these new changes from GitHub to your local repo on ecelinux : 1 2 3 % cd ${ HOME } /ece2400/sec2 % git pull % cat languages.txt 3. C Preprocessor Before we can understand how to write and compile C programs, we need to understand the C preprocessor. The preprocessor takes an input C source file, preprocesses it, and generates the preprocessed version of the C source file. It is important to realize that the C preprocesor is not really part of the C programming language. The C preprocessor simply manipulates the text in the C source files and knows nothing about the C programming language's syntax or semantics. The C preprocessor is powerful but also very easy to abuse. Using the C preprocessor can cause subtle bugs and is usually not necessary. Unfortunately, there are a few cases where we have no choice but to use the C preprocessor, so we must learn at least the basics. The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we wish to create a text file which includes both warm and cool colors. We could simply copy-and-paste our lists from warm-colors.txt and cool-colors.txt , but this would be redundant and difficult to maintain if we wanted to add a new warm or cool color. We can instead use the C preprocessor to include the contents of one text file in another text file. Use your favorite text editor to create a new file named colors-in.txt with the following content: 1 2 #include warm-colors.txt #include cool-colors.txt The C preprocessor copies the input source file to the output source file, while also looking for C preprocessor directives . All C preprocessor directives begin with the special # character. The #include directive specifies the file name of a different text file to include. The file name should be be specified using double quotes ( \"\" ). Now we can use the C preprocessor ( cpp ) to preprocess the -in.txt files into a final text file that contains both the warm and cool colors. 1 2 3 % cd ${ HOME } /ece2400/sec2 % cpp -o colors.txt colors-in.txt % cat colors.txt The -o command line option is used to specify the name of the output file. The content of the colors.txt should look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1 colors-in.txt # 1 built-in # 1 command-line # 31 command-line # 1 /usr/include/stdc-predef.h 1 3 4 # 32 command-line 2 # 1 colors-in.txt # 1 warm-colors.txt 1 red orange yellow # 2 colors-in.txt 2 # 1 cool-colors.txt 1 blue green purple # 2 colors-in.txt 2 The C preprocessor has included all of the colors in a single output file, but it has also included some additional lines beginning with the # character to specify information about where all of the pieces of text originally came from. We can tell cpp to not include this extra metadata with the -P command line option. 1 2 3 % cd ${ HOME } /ece2400/sec2 % cpp -P -o colors.txt colors-in.txt % cat colors.txt This example illustrates the first way we will use the C preprocessor. We will use the #include directive to include common C source files in several of our own C source files. This approach avoids redundancy and makes our programs much easier to maintain since we can make changes in a single C source file, and those changes can be immediately reflected in any program which includes that C source file. We have actually already seen this use of the C preprocessor in the previous section when we included the stdio.h header file which includes the declaration of the printf function. We will also use the C preprocessor to create include guards . An include guard is a way to ensure that the contents of a given file is only inserted into the output file once, even if we include it multiple times. For example, modify warm-colors.txt as follows: 1 2 3 4 5 6 #ifndef WARM_COLORS_TXT #define WARM_COLORS_TXT red orange yellow #endif The #ifndef directive is a conditional which will only include the content after the directive if the given preprocessor macro is defined. The #define directive \"defines\" the given preprocessor macro. So these directives essentially check to see if WARM_COLORS_TXT is defined and if not it will include the text in the file ... and also define WARM_COLORS_TXT . If we try and include this same file again then WARM_COLORS_TXT will already be defined and we will skip over the contents of the file. Modify cool-colors.txt as follows: 1 2 3 4 5 6 #ifndef COOL_COLORS_TXT #define COOL_COLORS_TXT blue green purple #endif And now modify colors-in.txt to include each file three times: 1 2 3 4 5 6 #include warm-colors.txt #include warm-colors.txt #include warm-colors.txt #include cool-colors.txt #include cool-colors.txt #include cool-colors.txt If you run the C preprocessor you will see that the colors are only included once because of the include guards. 1 2 3 % cd ${ HOME } /ece2400/sec2 % cpp -P -o colors.txt colors-in.txt % cat colors.txt 4. Compiling and Running a Single-File C Program Now that we have explored how to use the C preprocessor for file inclusion and include guards, we will can turn out attention to writing C programs. We will begin by writing a single-file C program to calculate the average of two integers. Our goal is to reproduce what we did earlier by using various command line tools on the ecelinux machines instead of using Compiler Explorer and Repl.it. Edit the avg-sfile.c code to include an appropriate implementation of the avg function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include stdio.h int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } int main () { int a = 10 ; int b = 20 ; int c = avg ( a , b ); printf ( average of %d and %d is %d \\n , a , b , c ); return 0 ; } We use a compiler to compiler the C source code into an executable binary (i.e., the actual bits) that the machine can understand. In this course we will be using the GNU C compiler ( gcc ). Let's go ahead and give this a try: 1 2 3 4 % cd ${ HOME } /ece2400/sec2 % gcc -o avg-sfile avg-sfile.c % objdump -dC avg-sfile | less % ./avg-sfile The objdump command takes an executable binary and shows you the machine instructions in a human readable format. We are piping it through less so we can scroll through the output. Try and find the machine instructions that go along with the avg function. Then we actually execute the binary by simply calling it as any other Linux command. Recall that a single dot ( . ) always refers to the current working directory. Essentially we are telling Linux that we want to run the executable named avg-sfile which is located in the current working directory. 5. Compiling and Running a Multi-File C Program Real C programs are almost never contained in a single file. They require many files which must be individually compiled and then linked together. To illustrate this process we will break our avg-sfile.c source file into two files: avg.c will contain the avg function, and avg-mfile.c will contain the main function. Go ahead and use your favorite text editor to create the avg.c file: 1 2 3 4 5 6 7 #include avg.h int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } And now create the avg-mfile.c file: 1 2 3 4 5 6 7 8 9 10 11 #include stdio.h #include avg.h int main () { int a = 10 ; int b = 20 ; int c = avg ( a , b ); printf ( average of %d and %d is %d \\n , a , b , c ); return 0 ; } We will use gcc compile the avg.c source file into the avg.o object file, and we will also use gcc to compile the avg-mfile.c source file into the avg-mfile.o object file. Finally, we can use gcc to link both object files along with the pre-compiled C standard library and any startup code to produce an executable binary. We will also need a header file named avg.h . Header files are the key to multi-file C programs. The avg-mfile.c source file needs to call the avg function, but the avg function is in a different source file. When we compile the avg-mfile.c source file, how will the compiler know that the avg function exists to ensure the programmer is not accidentally calling an undefined function? How will the compiler know what parameters the avg function takes, so it can perform type checking? The avg-mfile.c source file cannot directly include avg.c since that would result in the same function being compiled twice into two different object files (which would cause a linker error). What we need to do is have a way to tell avg-mfile.c the avg function prototype (i.e., the interface of the function including its name, parameter list, and return type) but not the avg function implementation . We do this with a function declaration . A function definition specifies both the function prototype (interface) and the implementation at the same time, while a function declaration just specifies the function prototype without the implementation. A header file contains all of the function declarations but no function definitions. All of the function definitions are placed in a source file that goes along with the header file. If we want to call a function that is defined in a different source file, then we simply use the #include directive to include the appropriate header file. The linker will take care of making sure the machine instructions corresponding to every function definition is linked together into the executable binary. Create a header file for avg.c named avg.h with the following contents. 1 2 3 4 5 6 #ifndef TUT3_C_AVG_H #define TUT3_C_AVG_H int avg ( int x , int y ); #endif Notice the include guards implemented using the C preprocessor. Let's go ahead and compile avg.c and avg-mfile.c into their corresponding object files: 1 2 3 % cd ${ HOME } /ece2400/sec2 % gcc -c -o avg.o avg.c % gcc -c -o avg-mfile.o avg-mfile.c And now we can link these two object files together to create an executable binary that we can run: 1 2 3 % cd ${ HOME } /ece2400/sec2 % gcc -o avg-mfile avg.o avg-mfile.o % ./avg-mfile We can actually simplify this process and do the compilation and linking in a single step like this: 1 2 3 % cd ${ HOME } /ece2400/sec2 % gcc -o avg-mfile avg.c avg-mfile.c % ./avg-mfile","title":"Ece2400 sec2 c basics"},{"location":"ece2400-sec2-c-basics/#section-2-compiling-and-running-c-programs","text":"This section serves as gentle introduction to the basics of compiling and running C programs on the ecelinux machines. The corresponding tutorial provides significantly more detail and background.","title":"Section 2: Compiling and Running C Programs"},{"location":"ece2400-sec2-c-basics/#1-the-ecelinux-machines","text":"Follow the same process as in the last section. login to a workstation with your NetID and password for the discussion section, we will be using screensharing via zoom start zoom, choose from menubar: Applications Internet Zoom click \"Join a Meeting\" enter \"ece2400\" in the text box check \"Don't connect to Audio\" check \"Turn off my video\" click \"Join\" click \"View Options\" at the top choose \"Exit Full Screen\"_ drag window over to the right-hand edge to make it take up the right half of the screen","title":"1. The ecelinux Machines"},{"location":"ece2400-sec2-c-basics/#2-basic-git-usage","text":"In this course, we will be using Git as our revision control and source code management system. We will be using GitHub for centralized online repository hosting, and TravisCI for online continuous integration testing. These tools will enable us to adopt an agile hardware development methodology so your group can rapidly collaborate and iterate on the design, verification, and evaluation of the assignments. You should have already setup your GitHub account on github.com during the previous section. Please also make sure you have setup your ssh keys correctly (see Section 2 of the ECE 2400 Tutorial 2). Fork'ing a repo means making a copy of that repo for your own local use. We won't actually be forking repos for the programming assignments, but it is an easy way for you to grab some example code for the discussion section. Go to the example repo here: https://github.com/cornell-ece2400/ece2400-sec2 Click on the \"Fork\" button. Wait a few seconds and then visit the new copy of this repo in your own person GitHub workspace: https://github.com/ githubid /ece2400-sec2 Where githubid is your GitHubID. Now let's clone your new repo to the ecelinux machine. 1 2 3 4 5 % source setup-ece2400.sh % cd ${ HOME } /ece2400 % git clone git@github.com: githubid /ece2400-sec2 sec2 % cd sec2 % cat README.md Where githubid is your GitHubID. Now let's add some new files to the repository. Use your favorite text editor (e.g., Geany) to create a file named warm-colors.txt with three warm colors: 1 2 3 red orange yellow Now use your favorite text editor again to create a file named cool-colors.txt with three cool colors. 1 2 3 blue green purple Now let's add these files to our repository. First use the git status command to check on the status of the repository. 1 2 % cd ${ HOME } /ece2400/sec2 % git status You should see that git has noticed two \"untracked files\" which are in the working directory but are not currently being tracked by git. Let's \"add\" these two files to git's \"staging\" area so it now knows it should keep track of them: 1 2 3 4 % cd ${ HOME } /ece2400/sec2 % git add warm-colors.txt % git add cool-colors.txt % git status The status of these two files have changed. Git reports that both of the new files are ready to be committed. Let's go ahead and commit these changes into your local repository. 1 2 % cd ${ HOME } /ece2400/sec2 % git commit -m add some colors Note that nothing has happened on GitHub yet. GitHub does not know anything about these local changes. We need to explicitly \"push\" our new commits up to GitHub like this: 1 2 % cd ${ HOME } /ece2400/sec2 % git push Now go to the repository page on GitHub and verify that there are two new files. Let's try making a change to this repository through the GitHub web interface. Click on \"Create new file\". Name the file languages.txt and add a list of programming languages: 1 2 3 4 5 C C++ Python MATLAB Java Now click \"Commit new file\". Verify that there is a new file in the repo using the GitHub web interface. Now let's \"pull\" these new changes from GitHub to your local repo on ecelinux : 1 2 3 % cd ${ HOME } /ece2400/sec2 % git pull % cat languages.txt","title":"2. Basic Git Usage"},{"location":"ece2400-sec2-c-basics/#3-c-preprocessor","text":"Before we can understand how to write and compile C programs, we need to understand the C preprocessor. The preprocessor takes an input C source file, preprocesses it, and generates the preprocessed version of the C source file. It is important to realize that the C preprocesor is not really part of the C programming language. The C preprocessor simply manipulates the text in the C source files and knows nothing about the C programming language's syntax or semantics. The C preprocessor is powerful but also very easy to abuse. Using the C preprocessor can cause subtle bugs and is usually not necessary. Unfortunately, there are a few cases where we have no choice but to use the C preprocessor, so we must learn at least the basics. The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we wish to create a text file which includes both warm and cool colors. We could simply copy-and-paste our lists from warm-colors.txt and cool-colors.txt , but this would be redundant and difficult to maintain if we wanted to add a new warm or cool color. We can instead use the C preprocessor to include the contents of one text file in another text file. Use your favorite text editor to create a new file named colors-in.txt with the following content: 1 2 #include warm-colors.txt #include cool-colors.txt The C preprocessor copies the input source file to the output source file, while also looking for C preprocessor directives . All C preprocessor directives begin with the special # character. The #include directive specifies the file name of a different text file to include. The file name should be be specified using double quotes ( \"\" ). Now we can use the C preprocessor ( cpp ) to preprocess the -in.txt files into a final text file that contains both the warm and cool colors. 1 2 3 % cd ${ HOME } /ece2400/sec2 % cpp -o colors.txt colors-in.txt % cat colors.txt The -o command line option is used to specify the name of the output file. The content of the colors.txt should look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1 colors-in.txt # 1 built-in # 1 command-line # 31 command-line # 1 /usr/include/stdc-predef.h 1 3 4 # 32 command-line 2 # 1 colors-in.txt # 1 warm-colors.txt 1 red orange yellow # 2 colors-in.txt 2 # 1 cool-colors.txt 1 blue green purple # 2 colors-in.txt 2 The C preprocessor has included all of the colors in a single output file, but it has also included some additional lines beginning with the # character to specify information about where all of the pieces of text originally came from. We can tell cpp to not include this extra metadata with the -P command line option. 1 2 3 % cd ${ HOME } /ece2400/sec2 % cpp -P -o colors.txt colors-in.txt % cat colors.txt This example illustrates the first way we will use the C preprocessor. We will use the #include directive to include common C source files in several of our own C source files. This approach avoids redundancy and makes our programs much easier to maintain since we can make changes in a single C source file, and those changes can be immediately reflected in any program which includes that C source file. We have actually already seen this use of the C preprocessor in the previous section when we included the stdio.h header file which includes the declaration of the printf function. We will also use the C preprocessor to create include guards . An include guard is a way to ensure that the contents of a given file is only inserted into the output file once, even if we include it multiple times. For example, modify warm-colors.txt as follows: 1 2 3 4 5 6 #ifndef WARM_COLORS_TXT #define WARM_COLORS_TXT red orange yellow #endif The #ifndef directive is a conditional which will only include the content after the directive if the given preprocessor macro is defined. The #define directive \"defines\" the given preprocessor macro. So these directives essentially check to see if WARM_COLORS_TXT is defined and if not it will include the text in the file ... and also define WARM_COLORS_TXT . If we try and include this same file again then WARM_COLORS_TXT will already be defined and we will skip over the contents of the file. Modify cool-colors.txt as follows: 1 2 3 4 5 6 #ifndef COOL_COLORS_TXT #define COOL_COLORS_TXT blue green purple #endif And now modify colors-in.txt to include each file three times: 1 2 3 4 5 6 #include warm-colors.txt #include warm-colors.txt #include warm-colors.txt #include cool-colors.txt #include cool-colors.txt #include cool-colors.txt If you run the C preprocessor you will see that the colors are only included once because of the include guards. 1 2 3 % cd ${ HOME } /ece2400/sec2 % cpp -P -o colors.txt colors-in.txt % cat colors.txt","title":"3. C Preprocessor"},{"location":"ece2400-sec2-c-basics/#4-compiling-and-running-a-single-file-c-program","text":"Now that we have explored how to use the C preprocessor for file inclusion and include guards, we will can turn out attention to writing C programs. We will begin by writing a single-file C program to calculate the average of two integers. Our goal is to reproduce what we did earlier by using various command line tools on the ecelinux machines instead of using Compiler Explorer and Repl.it. Edit the avg-sfile.c code to include an appropriate implementation of the avg function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include stdio.h int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } int main () { int a = 10 ; int b = 20 ; int c = avg ( a , b ); printf ( average of %d and %d is %d \\n , a , b , c ); return 0 ; } We use a compiler to compiler the C source code into an executable binary (i.e., the actual bits) that the machine can understand. In this course we will be using the GNU C compiler ( gcc ). Let's go ahead and give this a try: 1 2 3 4 % cd ${ HOME } /ece2400/sec2 % gcc -o avg-sfile avg-sfile.c % objdump -dC avg-sfile | less % ./avg-sfile The objdump command takes an executable binary and shows you the machine instructions in a human readable format. We are piping it through less so we can scroll through the output. Try and find the machine instructions that go along with the avg function. Then we actually execute the binary by simply calling it as any other Linux command. Recall that a single dot ( . ) always refers to the current working directory. Essentially we are telling Linux that we want to run the executable named avg-sfile which is located in the current working directory.","title":"4. Compiling and Running a Single-File C Program"},{"location":"ece2400-sec2-c-basics/#5-compiling-and-running-a-multi-file-c-program","text":"Real C programs are almost never contained in a single file. They require many files which must be individually compiled and then linked together. To illustrate this process we will break our avg-sfile.c source file into two files: avg.c will contain the avg function, and avg-mfile.c will contain the main function. Go ahead and use your favorite text editor to create the avg.c file: 1 2 3 4 5 6 7 #include avg.h int avg ( int x , int y ) { int sum = x + y ; return sum / 2 ; } And now create the avg-mfile.c file: 1 2 3 4 5 6 7 8 9 10 11 #include stdio.h #include avg.h int main () { int a = 10 ; int b = 20 ; int c = avg ( a , b ); printf ( average of %d and %d is %d \\n , a , b , c ); return 0 ; } We will use gcc compile the avg.c source file into the avg.o object file, and we will also use gcc to compile the avg-mfile.c source file into the avg-mfile.o object file. Finally, we can use gcc to link both object files along with the pre-compiled C standard library and any startup code to produce an executable binary. We will also need a header file named avg.h . Header files are the key to multi-file C programs. The avg-mfile.c source file needs to call the avg function, but the avg function is in a different source file. When we compile the avg-mfile.c source file, how will the compiler know that the avg function exists to ensure the programmer is not accidentally calling an undefined function? How will the compiler know what parameters the avg function takes, so it can perform type checking? The avg-mfile.c source file cannot directly include avg.c since that would result in the same function being compiled twice into two different object files (which would cause a linker error). What we need to do is have a way to tell avg-mfile.c the avg function prototype (i.e., the interface of the function including its name, parameter list, and return type) but not the avg function implementation . We do this with a function declaration . A function definition specifies both the function prototype (interface) and the implementation at the same time, while a function declaration just specifies the function prototype without the implementation. A header file contains all of the function declarations but no function definitions. All of the function definitions are placed in a source file that goes along with the header file. If we want to call a function that is defined in a different source file, then we simply use the #include directive to include the appropriate header file. The linker will take care of making sure the machine instructions corresponding to every function definition is linked together into the executable binary. Create a header file for avg.c named avg.h with the following contents. 1 2 3 4 5 6 #ifndef TUT3_C_AVG_H #define TUT3_C_AVG_H int avg ( int x , int y ); #endif Notice the include guards implemented using the C preprocessor. Let's go ahead and compile avg.c and avg-mfile.c into their corresponding object files: 1 2 3 % cd ${ HOME } /ece2400/sec2 % gcc -c -o avg.o avg.c % gcc -c -o avg-mfile.o avg-mfile.c And now we can link these two object files together to create an executable binary that we can run: 1 2 3 % cd ${ HOME } /ece2400/sec2 % gcc -o avg-mfile avg.o avg-mfile.o % ./avg-mfile We can actually simplify this process and do the compilation and linking in a single step like this: 1 2 3 % cd ${ HOME } /ece2400/sec2 % gcc -o avg-mfile avg.c avg-mfile.c % ./avg-mfile","title":"5. Compiling and Running a Multi-File C Program"},{"location":"ece2400-sec3-c-build-test/","text":"Section 3: C Build and Test Frameworks In the previous discussion section, you learned how to explicitly compile and run C programs from the command line. You learned how to use the GNU C Compiler ( gcc ) to compile both a single-file and multi-file program that calculated the average of two integers. You probably noticed that it can be tedious to have to carefully enter the correct commands on the command line. We also need to carefully track which steps need to be redone whenever we change a C source file. In this discussion section, we will explore using a build framework based on CMake to automate this process. In the previous discussion section, you also learned how to do ad-hoc testing by executing a function and then simply printing out the result to the terminal. In this discussion section, we will explore using a test framework to automate this process. Using a build and test framework is critical to productive system-level programming in C and C++. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. 1 2 3 4 5 % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec3-c-build-test sec3 % cd sec3/src % ls The given src directory includes the following files: avg-sfile.c : source and main for single-file avg program avg.h : header file for the avg function avg.c : source file for the avg function avg-mfile.c : main for multi-file avg program avg-mfile-basic-tests.h : most basic smoke test utst.h : simple C preprocessor macros for unit testing 1. Basic Makefile for Compiling C Programs Let's remind ourselves how to explicitly compile and run a single-file C program on the command line: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % gcc -Wall -o avg-sfile avg-sfile.c % ./avg-sfile Let's now remove the binary so we are back to a clean directory: 1 2 % cd ${ HOME } /ece2400/sec3/src % rm -rf avg-sfile We will start by using a new tool called make which was specifically designed to help automate the process of building C programs. The key to using make is developing a Makefile . A Makefile is a plain text file which contains a list of rules which together specify how to execute commands to accomplish some task. Each rule has the following syntax: 1 2 target : prerequisite0 prerequisite1 prerequisite2 TAB command A rule specifies how to generate the target file using the list of prerequisite files and the given Linux command. make is smart enough to know it should rerun the command if any of the prerequisites change, and it also knows that if one of the prerequisites does not exist then it needs to look for some other rule to generate that prerequisite first. It is very important to note that make requires commands in a rule to start with a real TAB character. So you should not type the letters TAB , but you should instead press the TAB key and verify that it has inserted a real TAB character (i.e., if you move the left/right arrows the cursor should jump back and forth across the TAB). This is the only time in the course where you should use a real TAB character as opposed to spaces. Let's create a simple Makefile to compile a single-file C program. Use your favorite text editor to create a file named Makefile in the src directory with the following content: 1 2 3 4 5 avg-sfile : avg - sfile . c TAB gcc -Wall -o avg-sfile avg-sfile.c clean : TAB rm -rf avg-sfile We can use the newly created Makefile like this: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile make will by default use the Makefile in the current directory. make takes a command line argument specifying what you want \"make\". In this case, we want to make the avg-sfile executable. make will look at all of the rules in the Makefile to find a rule that specifies how to make the avg-sfile executable. It will then check to make sure the prerequisites exist and that they are up-to-date, and then it will run the command specified in the rule for avg-sfile . In this case, that command is gcc . make will output to the terminal every command it runs, so you should see it output the command line which uses gcc to generate the avg-sfile executable. Try running make again: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile make detects that the prerequisite (i.e., avg-sfile.c ) has not changed and so it does not recompile the executable. Now let's try making a change in the avg-sfile.c source file. Modify the printf statement as follows: 1 printf ( avg( %d, %d ) == %d \\n , a , b , c ); You can recompile and re-execute the program like this: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile make will automatically detect that the prerequisite has changed and recompile the executable appropriately. This ability to automatically track dependencies and recompile just what is necessary is a key benefit of using a tool like make . Makefiles can also include targets which are not actually files. Our example Makefile includes a clean target which will delete any generated executables. Let's clean up our directory like this: 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % ls % make clean % ls To-Do On Your Own Add two rules to your Makefile to compile avg.o and avg-mfile.o . Add a rule that links these two object files together and produces avg-mfile . Update the rule for the clean target appropriately. Carefully consider what command and prerequisites to use for each target. Test out your Makefile . Try changing avg.c and rerunning make . Does your program recompile correctly? Try changing avg.h and rerunning make . Does your program recompile correctly? 2. Using CMake to Generate Makefiles for Compiling C Programs While using make can help automate the build process, the corresponding Makefiles can quickly grow to be incredibly complicated. Creating and maintaining these Makefiles can involve significant effort. It can be particularly challenging to ensure all of the dependencies between the various source and header files are always correctly captured in the Makefile . It can also be complicated to add support for code coverage, memory checking, and debug vs.~evaluation builds. New tools have been developed to help automate the process of managing Makefiles (which in turn automate the build process). Automation is the key to effective software development methodologies. In this course, we will be using CMake as a key step in our build framework. CMake takes as input a simple CMakeLists.txt file and generates a sophisticated Makefile for us to use. A CMakeLists.txt is a plain text file with a list of commands that specify what tasks we would like the generated Makefile to perform. Before getting started let's remove any files we have generated and also remove the Makefile we developed in the previous section. 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make clean % trash Makefile Let's create a simple CMakeLists.txt that can be used to generate a Makefile which will in turn be used to compile a single-file C program. User your favorite text editor to create a file named CMakeLists.txt in the src directory with the following content: 1 2 3 cmake_minimum_required ( VERSION 2.8 ) enable_language ( C ) add_executable ( avg-sfile avg-sfile.c ) Line 1 specifies the CMake version we are assuming, and line 2 specifies that we will be using CMake with a C project. Line 3 specifies that we want to generate a Makefile that can compile an executable named avg-sfile form the avg-sfile.c source file. Now let's run the cmake command to generate a Makefile we can use to compile avg-sfile : 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % cmake . % ls % less Makefile The cmake command will by default use the CMakeLists.txt in the directory given as a command line argument. CMake takes care of figuring out what C compilers are available and then generating the Makefile appropriately. You can see that CMake has automatically generated a pretty sophisticated Makefile . Let's go ahead and use this Makefile to build avg-sfile . 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile CMake will automatically create some useful targets like clean . 1 2 % cd ${ HOME } /ece2400/sec3/src % make clean Writing a CMakeLists.txt is simpler than writing a Makefile , especially when we start working with many files. To-Do On Your Own Add another line to your CMakeLists.txt file to specify that we want to generate a Makefile that can be used to compile avg-mfile from avg-mfile.c and avg.c . Use CMake to generate the corresponding Makefile and then use make to compile avg-mfile . Try changing avg.c and rerunning make . Does your program recompile correctly? Try changing avg.h and rerunning make . Does your program recompile correctly? 3. Using CTest for Systematic Unit Testing So far we have been using \"ad-hoc testing\". For example, the main function in avg-sfile.c will execute the avg function with one set of inputs and then print the result to the terminal. If it is not what we expected, we can debug our program until it meets our expectations. Unfortunately, ad-hoc testing is error prone and not easily reproducible. If you later make a change to your implementation, you would have to take another look at the output to ensure your implementation still works. If another developer wants to understand your implementation and verify that it is working, he or she would also need to take a look at the output and think hard about what is the expected result. Ad-hoc testing is usually verbose, which makes it error prone, and does not use any kind of standard test output. While ad-hoc testing might be feasible for very simple implementations, it is obviously not a scalable approach when developing the more complicated implementations we will tackle in this course. New tools have been developed to help automate the process of testing implementations. These tools provide a systematic way to do automated unit testing including standardized naming conventions, test output, and test drivers. In this course, we will be using CTest as a key step in our test framework. CTest elegantly integrates with CMake to create a unified built and test framework. Each unit test will be a stand-alone test program where the test code is contained within the main function. The following is an example of a unit test program for our avg function: 1 2 3 4 5 6 7 8 9 10 11 12 13 #include stdio.h #include avg.h #include utst.h int main () { UTST_BEGIN (); UTST_ASSERT_INT_EQ ( avg ( 10 , 20 ), 15 ); UTST_END (); return 0 ; } We provide a simple library of test macros in utst.h which can be used to write various testing assertions. You should always insert UTST_BEGIN() at the beginning of main and UTST_END() at the end of main immediately before the final return statement. The UTST_ASSERT_INT_EQ macro asserts that the two given integer parameters are equal. If they are indeed equal, then the macro prints out the values, and we move on to the next test assertion. If they are not equal, the the macro prints out an error message and returns from main with the value 1. Recall that when main returns 0 it means success, and when main returns 1 it means failure. The return value enables our test program to inform CTest of whether or not our test passed of failed. We have provided the above test program in the repository for this discussion section. To use CTest, we need to tell it about this new test program. We can do this by simply adding a new line to our CMakeLists.txt file. Here is an example CMakeLists.txt file: 1 2 3 4 5 6 7 8 9 cmake_minimum_required ( VERSION 2.8 ) enable_language ( C ) enable_testing () add_executable ( avg-sfile avg-sfile.c ) add_executable ( avg-mfile avg-mfile.c avg.c ) add_executable ( avg-mfile-basic-tests avg-mfile-basic-tests.c avg.c ) add_test ( avg-mfile-basic-tests avg-mfile-basic-tests ) Line 3 tells CMake to turn on support for testing with CTest. Line 6 specifies how to build avg-mfile . Line 8 specifies how to build the avg-mfile-basic-tests test program. Line 9 tells CMake that avg-mfile-basic-tests is a test that should be managed by CTest. Modify your CMakeLists.txt file to look like what is given above, rerun cmake, build the test, and run it. 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % cmake . % make avg-mfile-basic-tests % ./avg-mfile-basic-tests You should see some output which indicates the passing test assertion. CMake provides a test target which can run all of the tests and provides a summary. 1 2 % cd ${ HOME } /ece2400/sec3/src % make test It is always a good idea to occasionally force a test to fail to ensure your test framework is behaving correctly. Change the test assertion in avg-mfile-basic-tests.c to look like this: 1 UTST_ASSERT_INT_EQ ( avg ( 10 , 20 ), 16 ); Then rebuild and rerun the test like this: 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % make avg-mfile-basic-tests % make test % ./avg-mfile-basic-tests You should see the test failing in the test summary, and then see additional information about the failing test assertion when you explicitly run the test program. avg-mfile-basic-tests is a kind of \"smoke\" test which is used to test the absolute most basic functionality of an implementation. We will also be doing extensive directed testing and random testing . In directed testing, you explicitly use test assertions to test as many corner cases as possible. In random testing, you use random input values and compare the output to some golden \"reference\" implementation to hopefully catch bugs missed in your directed testing. To-Do On Your Own Create another unit test program named avg-mfile-directed-tests.c for directed testing. Use the macros in utst.h to begin/end your test program and for test assertions. Try to test several different corner cases. Modify your CMakeLists.txt file to include this new unit test program. Use CMake to regenerate the corresponding Makefile , use make to build your test program, and then run it. Ensure that make test runs both the basic and directed tests. 4. Using a Build Directory Take a look at the source directory. It likely contains a mess of generated directories, object files, executables, etc. It is usually very bad practice to build C programs directly in the source directory. It is much better to build C programs in a completely separate build directory. Adding support for these build directories in a Makefile is complex, but CMake makes it easy. Let's start by deleting all generated content in your source directory: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make clean % trash CMakeCache.txt CMakeFiles *.cmake Now let's first create a separate build directory, use CMake to create a new Makefile , and finally build and run all of our tests. 1 2 3 4 5 6 % cd ${ HOME } /ece2400/sec3 % mkdir build % cd build % cmake ../src % make % make test A separate build directory makes it easy to do a \"clean build\" where you start your build from scratch. Simply remove the build directory and start again like this: 1 2 3 4 5 6 7 % cd ${ HOME } /ece2400/sec3 % trash build % mkdir build % cd build % cmake ../src % make % make test You should never check in your build directory or any generated content into Git. Only source files are checked into Git! To-Do On Your Own Add a new test assertion to your directed tests. Rebuild and rerun the test program in the separate build directory. 5. Try Steps for Programming Assignments For each programming assignment, we will provide you a skeleton for your project including a complete CMakeLists.txt . In the common case, you should not need to modify the CMakeLists.txt unless you want to incorporate additional source and/or test files. The programming assignments are setup to use a separate build directory. The programming assignments also group all of the tests into their own separate directory. You can use the following steps to clone and build the first programming assignment. 1 2 3 4 5 6 7 8 9 10 % mkdir -p ${ HOME } /ece2400 % cd ece2400 % git clone git@github.com:cornell-ece2400/netid % cd ece2400-pa-release/pa1-math % tree % mkdir build % cd build % cmake .. % make % make test Where netid is your NetID. We provide you convenient check targets which should be the primary way you build and run your tests. These targets take care of making sure your test programs are always up-to-date before running them. The following will run all of the tests for the first programming assignment: 1 2 % cd ${ HOME } /ece2400/netid/pa1-math/build % make check If there is a test failure, we can \"zoom in\" and run just the tests for the corresponding implementation like this: 1 2 % cd ${ HOME } /ece2400/netid/pa1-math/build % make check-pow-iter Then we can \"zoom in\" further, and run a single test program so we can see exactly which test assertion is failing. We should always start by debugging the simplest test program first (i.e., basic tests) before moving on to directed or random tests. 1 2 % cd ${ HOME } /ece2400/netid/pa1-math/build % make check-pow-iter-basic-tests Once we fix the bug, then we can \"zoom out\" and move on to the next failing test program, or to the next implementation. To-Do On Your Own Force one of your directed test assertions to fail. Use the check targets to \"zoom in\", fix the bug, and then \"zoom out\".","title":"Ece2400 sec3 c build test"},{"location":"ece2400-sec3-c-build-test/#section-3-c-build-and-test-frameworks","text":"In the previous discussion section, you learned how to explicitly compile and run C programs from the command line. You learned how to use the GNU C Compiler ( gcc ) to compile both a single-file and multi-file program that calculated the average of two integers. You probably noticed that it can be tedious to have to carefully enter the correct commands on the command line. We also need to carefully track which steps need to be redone whenever we change a C source file. In this discussion section, we will explore using a build framework based on CMake to automate this process. In the previous discussion section, you also learned how to do ad-hoc testing by executing a function and then simply printing out the result to the terminal. In this discussion section, we will explore using a test framework to automate this process. Using a build and test framework is critical to productive system-level programming in C and C++. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. 1 2 3 4 5 % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec3-c-build-test sec3 % cd sec3/src % ls The given src directory includes the following files: avg-sfile.c : source and main for single-file avg program avg.h : header file for the avg function avg.c : source file for the avg function avg-mfile.c : main for multi-file avg program avg-mfile-basic-tests.h : most basic smoke test utst.h : simple C preprocessor macros for unit testing","title":"Section 3: C Build and Test Frameworks"},{"location":"ece2400-sec3-c-build-test/#1-basic-makefile-for-compiling-c-programs","text":"Let's remind ourselves how to explicitly compile and run a single-file C program on the command line: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % gcc -Wall -o avg-sfile avg-sfile.c % ./avg-sfile Let's now remove the binary so we are back to a clean directory: 1 2 % cd ${ HOME } /ece2400/sec3/src % rm -rf avg-sfile We will start by using a new tool called make which was specifically designed to help automate the process of building C programs. The key to using make is developing a Makefile . A Makefile is a plain text file which contains a list of rules which together specify how to execute commands to accomplish some task. Each rule has the following syntax: 1 2 target : prerequisite0 prerequisite1 prerequisite2 TAB command A rule specifies how to generate the target file using the list of prerequisite files and the given Linux command. make is smart enough to know it should rerun the command if any of the prerequisites change, and it also knows that if one of the prerequisites does not exist then it needs to look for some other rule to generate that prerequisite first. It is very important to note that make requires commands in a rule to start with a real TAB character. So you should not type the letters TAB , but you should instead press the TAB key and verify that it has inserted a real TAB character (i.e., if you move the left/right arrows the cursor should jump back and forth across the TAB). This is the only time in the course where you should use a real TAB character as opposed to spaces. Let's create a simple Makefile to compile a single-file C program. Use your favorite text editor to create a file named Makefile in the src directory with the following content: 1 2 3 4 5 avg-sfile : avg - sfile . c TAB gcc -Wall -o avg-sfile avg-sfile.c clean : TAB rm -rf avg-sfile We can use the newly created Makefile like this: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile make will by default use the Makefile in the current directory. make takes a command line argument specifying what you want \"make\". In this case, we want to make the avg-sfile executable. make will look at all of the rules in the Makefile to find a rule that specifies how to make the avg-sfile executable. It will then check to make sure the prerequisites exist and that they are up-to-date, and then it will run the command specified in the rule for avg-sfile . In this case, that command is gcc . make will output to the terminal every command it runs, so you should see it output the command line which uses gcc to generate the avg-sfile executable. Try running make again: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile make detects that the prerequisite (i.e., avg-sfile.c ) has not changed and so it does not recompile the executable. Now let's try making a change in the avg-sfile.c source file. Modify the printf statement as follows: 1 printf ( avg( %d, %d ) == %d \\n , a , b , c ); You can recompile and re-execute the program like this: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile make will automatically detect that the prerequisite has changed and recompile the executable appropriately. This ability to automatically track dependencies and recompile just what is necessary is a key benefit of using a tool like make . Makefiles can also include targets which are not actually files. Our example Makefile includes a clean target which will delete any generated executables. Let's clean up our directory like this: 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % ls % make clean % ls To-Do On Your Own Add two rules to your Makefile to compile avg.o and avg-mfile.o . Add a rule that links these two object files together and produces avg-mfile . Update the rule for the clean target appropriately. Carefully consider what command and prerequisites to use for each target. Test out your Makefile . Try changing avg.c and rerunning make . Does your program recompile correctly? Try changing avg.h and rerunning make . Does your program recompile correctly?","title":"1. Basic Makefile for Compiling C Programs"},{"location":"ece2400-sec3-c-build-test/#2-using-cmake-to-generate-makefiles-for-compiling-c-programs","text":"While using make can help automate the build process, the corresponding Makefiles can quickly grow to be incredibly complicated. Creating and maintaining these Makefiles can involve significant effort. It can be particularly challenging to ensure all of the dependencies between the various source and header files are always correctly captured in the Makefile . It can also be complicated to add support for code coverage, memory checking, and debug vs.~evaluation builds. New tools have been developed to help automate the process of managing Makefiles (which in turn automate the build process). Automation is the key to effective software development methodologies. In this course, we will be using CMake as a key step in our build framework. CMake takes as input a simple CMakeLists.txt file and generates a sophisticated Makefile for us to use. A CMakeLists.txt is a plain text file with a list of commands that specify what tasks we would like the generated Makefile to perform. Before getting started let's remove any files we have generated and also remove the Makefile we developed in the previous section. 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make clean % trash Makefile Let's create a simple CMakeLists.txt that can be used to generate a Makefile which will in turn be used to compile a single-file C program. User your favorite text editor to create a file named CMakeLists.txt in the src directory with the following content: 1 2 3 cmake_minimum_required ( VERSION 2.8 ) enable_language ( C ) add_executable ( avg-sfile avg-sfile.c ) Line 1 specifies the CMake version we are assuming, and line 2 specifies that we will be using CMake with a C project. Line 3 specifies that we want to generate a Makefile that can compile an executable named avg-sfile form the avg-sfile.c source file. Now let's run the cmake command to generate a Makefile we can use to compile avg-sfile : 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % cmake . % ls % less Makefile The cmake command will by default use the CMakeLists.txt in the directory given as a command line argument. CMake takes care of figuring out what C compilers are available and then generating the Makefile appropriately. You can see that CMake has automatically generated a pretty sophisticated Makefile . Let's go ahead and use this Makefile to build avg-sfile . 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make avg-sfile % ./avg-sfile CMake will automatically create some useful targets like clean . 1 2 % cd ${ HOME } /ece2400/sec3/src % make clean Writing a CMakeLists.txt is simpler than writing a Makefile , especially when we start working with many files. To-Do On Your Own Add another line to your CMakeLists.txt file to specify that we want to generate a Makefile that can be used to compile avg-mfile from avg-mfile.c and avg.c . Use CMake to generate the corresponding Makefile and then use make to compile avg-mfile . Try changing avg.c and rerunning make . Does your program recompile correctly? Try changing avg.h and rerunning make . Does your program recompile correctly?","title":"2. Using CMake to Generate Makefiles for Compiling C Programs"},{"location":"ece2400-sec3-c-build-test/#3-using-ctest-for-systematic-unit-testing","text":"So far we have been using \"ad-hoc testing\". For example, the main function in avg-sfile.c will execute the avg function with one set of inputs and then print the result to the terminal. If it is not what we expected, we can debug our program until it meets our expectations. Unfortunately, ad-hoc testing is error prone and not easily reproducible. If you later make a change to your implementation, you would have to take another look at the output to ensure your implementation still works. If another developer wants to understand your implementation and verify that it is working, he or she would also need to take a look at the output and think hard about what is the expected result. Ad-hoc testing is usually verbose, which makes it error prone, and does not use any kind of standard test output. While ad-hoc testing might be feasible for very simple implementations, it is obviously not a scalable approach when developing the more complicated implementations we will tackle in this course. New tools have been developed to help automate the process of testing implementations. These tools provide a systematic way to do automated unit testing including standardized naming conventions, test output, and test drivers. In this course, we will be using CTest as a key step in our test framework. CTest elegantly integrates with CMake to create a unified built and test framework. Each unit test will be a stand-alone test program where the test code is contained within the main function. The following is an example of a unit test program for our avg function: 1 2 3 4 5 6 7 8 9 10 11 12 13 #include stdio.h #include avg.h #include utst.h int main () { UTST_BEGIN (); UTST_ASSERT_INT_EQ ( avg ( 10 , 20 ), 15 ); UTST_END (); return 0 ; } We provide a simple library of test macros in utst.h which can be used to write various testing assertions. You should always insert UTST_BEGIN() at the beginning of main and UTST_END() at the end of main immediately before the final return statement. The UTST_ASSERT_INT_EQ macro asserts that the two given integer parameters are equal. If they are indeed equal, then the macro prints out the values, and we move on to the next test assertion. If they are not equal, the the macro prints out an error message and returns from main with the value 1. Recall that when main returns 0 it means success, and when main returns 1 it means failure. The return value enables our test program to inform CTest of whether or not our test passed of failed. We have provided the above test program in the repository for this discussion section. To use CTest, we need to tell it about this new test program. We can do this by simply adding a new line to our CMakeLists.txt file. Here is an example CMakeLists.txt file: 1 2 3 4 5 6 7 8 9 cmake_minimum_required ( VERSION 2.8 ) enable_language ( C ) enable_testing () add_executable ( avg-sfile avg-sfile.c ) add_executable ( avg-mfile avg-mfile.c avg.c ) add_executable ( avg-mfile-basic-tests avg-mfile-basic-tests.c avg.c ) add_test ( avg-mfile-basic-tests avg-mfile-basic-tests ) Line 3 tells CMake to turn on support for testing with CTest. Line 6 specifies how to build avg-mfile . Line 8 specifies how to build the avg-mfile-basic-tests test program. Line 9 tells CMake that avg-mfile-basic-tests is a test that should be managed by CTest. Modify your CMakeLists.txt file to look like what is given above, rerun cmake, build the test, and run it. 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % cmake . % make avg-mfile-basic-tests % ./avg-mfile-basic-tests You should see some output which indicates the passing test assertion. CMake provides a test target which can run all of the tests and provides a summary. 1 2 % cd ${ HOME } /ece2400/sec3/src % make test It is always a good idea to occasionally force a test to fail to ensure your test framework is behaving correctly. Change the test assertion in avg-mfile-basic-tests.c to look like this: 1 UTST_ASSERT_INT_EQ ( avg ( 10 , 20 ), 16 ); Then rebuild and rerun the test like this: 1 2 3 4 % cd ${ HOME } /ece2400/sec3/src % make avg-mfile-basic-tests % make test % ./avg-mfile-basic-tests You should see the test failing in the test summary, and then see additional information about the failing test assertion when you explicitly run the test program. avg-mfile-basic-tests is a kind of \"smoke\" test which is used to test the absolute most basic functionality of an implementation. We will also be doing extensive directed testing and random testing . In directed testing, you explicitly use test assertions to test as many corner cases as possible. In random testing, you use random input values and compare the output to some golden \"reference\" implementation to hopefully catch bugs missed in your directed testing. To-Do On Your Own Create another unit test program named avg-mfile-directed-tests.c for directed testing. Use the macros in utst.h to begin/end your test program and for test assertions. Try to test several different corner cases. Modify your CMakeLists.txt file to include this new unit test program. Use CMake to regenerate the corresponding Makefile , use make to build your test program, and then run it. Ensure that make test runs both the basic and directed tests.","title":"3. Using CTest for Systematic Unit Testing"},{"location":"ece2400-sec3-c-build-test/#4-using-a-build-directory","text":"Take a look at the source directory. It likely contains a mess of generated directories, object files, executables, etc. It is usually very bad practice to build C programs directly in the source directory. It is much better to build C programs in a completely separate build directory. Adding support for these build directories in a Makefile is complex, but CMake makes it easy. Let's start by deleting all generated content in your source directory: 1 2 3 % cd ${ HOME } /ece2400/sec3/src % make clean % trash CMakeCache.txt CMakeFiles *.cmake Now let's first create a separate build directory, use CMake to create a new Makefile , and finally build and run all of our tests. 1 2 3 4 5 6 % cd ${ HOME } /ece2400/sec3 % mkdir build % cd build % cmake ../src % make % make test A separate build directory makes it easy to do a \"clean build\" where you start your build from scratch. Simply remove the build directory and start again like this: 1 2 3 4 5 6 7 % cd ${ HOME } /ece2400/sec3 % trash build % mkdir build % cd build % cmake ../src % make % make test You should never check in your build directory or any generated content into Git. Only source files are checked into Git! To-Do On Your Own Add a new test assertion to your directed tests. Rebuild and rerun the test program in the separate build directory.","title":"4. Using a Build Directory"},{"location":"ece2400-sec3-c-build-test/#5-try-steps-for-programming-assignments","text":"For each programming assignment, we will provide you a skeleton for your project including a complete CMakeLists.txt . In the common case, you should not need to modify the CMakeLists.txt unless you want to incorporate additional source and/or test files. The programming assignments are setup to use a separate build directory. The programming assignments also group all of the tests into their own separate directory. You can use the following steps to clone and build the first programming assignment. 1 2 3 4 5 6 7 8 9 10 % mkdir -p ${ HOME } /ece2400 % cd ece2400 % git clone git@github.com:cornell-ece2400/netid % cd ece2400-pa-release/pa1-math % tree % mkdir build % cd build % cmake .. % make % make test Where netid is your NetID. We provide you convenient check targets which should be the primary way you build and run your tests. These targets take care of making sure your test programs are always up-to-date before running them. The following will run all of the tests for the first programming assignment: 1 2 % cd ${ HOME } /ece2400/netid/pa1-math/build % make check If there is a test failure, we can \"zoom in\" and run just the tests for the corresponding implementation like this: 1 2 % cd ${ HOME } /ece2400/netid/pa1-math/build % make check-pow-iter Then we can \"zoom in\" further, and run a single test program so we can see exactly which test assertion is failing. We should always start by debugging the simplest test program first (i.e., basic tests) before moving on to directed or random tests. 1 2 % cd ${ HOME } /ece2400/netid/pa1-math/build % make check-pow-iter-basic-tests Once we fix the bug, then we can \"zoom out\" and move on to the next failing test program, or to the next implementation. To-Do On Your Own Force one of your directed test assertions to fail. Use the check targets to \"zoom in\", fix the bug, and then \"zoom out\".","title":"5. Try Steps for Programming Assignments"},{"location":"ece2400-sec4-c-debug-coverage/","text":"Section 4: C Debug and Code Coverage In the previous discussion section, you learned how to use C build and test frameworks to help automate the process of compiling and verifying your programs In this discussion, we will continue to learn about new tools that can help us better debug and verify our programs. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now fork the github repo for this discussion section so you have your own personal copy. Go to the example repo here: https://github.com/cornell-ece2400/ece2400-sec4-c-debug-coverage Click on the \"Fork\" button. Wait a few seconds and then visit the new copy of this repo in your own person GitHub workspace: https://github.com/githubid/ece2400-sec2 Where githubid is your GitHubID. Now clone the github repo for this discussion section. 1 2 3 4 5 % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone git@github.com:githubid/ece2400-sec4-c-debug-coverage sec4 % cd sec4 % ls Where again, the githubid is your GitHubID. The given src directory includes the following files: avg-test.c : source and test for avg function gcd-test.c : source and test for gcd function utst.h : simple C preprocessor macros for unit testing .travis.yml : TravisCI configuration script 1. Using GDB for Debugging There are two kinds of C/C++ programmers in the world: printf debuggers and GDB debuggers. Prof. Batten used to be a printf debuggers but teaching this course has converted him to be a GDB advocate. He will share his perspectives on this in the discussion section. Let's start by compiling a single-file program that uses the UTST macros to test our ubiquitous avg function. 1 2 3 % cd ${ HOME } /ece2400/sec4 % gcc -Wall -g -o avg-test avg-test.c % ./avg-test Notice how we include the -g option to turn on support for debugging. This code has a bug and should fail the test. Let's start by using printf debugging. Add some extra printfs to observe the state of the program as it executes. 1 2 3 4 5 6 7 int avg ( int x , int y ) { printf ( x = %d, y = %d \\n , x , y ); int sum = x + x ; printf ( sum = %d \\n , sum ); return sum / 2 ; } You should be able to see that the value for the sum variable is incorrect, but the value for the x and y variables are correct. This means we can narrow our focus to line~4 in the above code snippet. Hopefully, you should be able to spot the bug. Fix the bug, recompile, and rerun the program. Let's now try tracing the execution of this program using GDB. Then you can start GDB like this 1 2 % cd ${ HOME } /ece2400/sec4 % gdb -tui avg-test GDB will drop you into a GDB \"prompt\" which you can use to interactively execute your program. Your source code will show up at the top, and the GDB prompt is at the bottom. Here are some useful GDB commands: break location : set a breakpoint run : start running the program record : start recording the execution for reverse debugging step : execute the next C statement, step into a function call next : execute the next C statement, do not step into a function call rs : reserve step, undo the execution of current C statement print var : print a C variable continue : continue on to the next breakpoint quit : exit GDB refresh : refresh the source code display GDB is very sophisticated so of course there are many more commands you can use, but these are enough to get started. Let's start by just running the program in GDB: 1 (gdb) run Now let's try again, but first let's set a breakpoint to tell GDB to stop at a certain function or line in the program. The following will set a breakpoint at the beginning of the main function. 1 (gdb) break main You can see a little B marker in the margin next to the first statement in the main function indicating the location of the breakpoint. We can now use run to start the program running. The execution should stop at the beginning of the function main . You should see the first line of the function highlighted. 1 (gdb) run We can use record to turn on recording to enable reverse debugging and then we can step through the execution of each C statement using the step command. 1 2 (gdb) record (gdb) step Keep using step until you get into the avg function You can print out the value of any variable using the print command: 1 2 3 (gdb) print x (gdb) print y (gdb) print sum You can also step backwards using the rs command: 1 (gdb) rs Try stepping forward and backward through the avg function and print out various variables to see how they change during the execution. You can use quit to exit. 1 (gdb) quit To-Do On Your Own Try compiling gcd-test.c and executing the resulting binary. The test should fail. Use GDB debugging to find the bug and fix it. 2. Using GCOV for Code Coverage One you have developed your implementation and the corresponding basic, directed, and random tests, you can then move on to understanding the quality of your current set of tests. One way to do this is to use code coverage tools. The idea here is to use a tool which will count how many times each line of code in your program is executed when running all of your tests. If there are lines of code which have never executed, then this is a good indicator that you need more tests to verify that part of your code. Let's start by recompiling our avg-test.c and turning on code coverage support. 1 2 3 % cd ${ HOME } /ece2400/sec4 % gcc -Wall -g --coverage -o avg-test avg-test.c % ./avg-test This will generate additional data in avg-test.gcda . To make this data easy to read and understand we need to run two more tools: lcov and genhtml like this: 1 2 3 % cd ${ HOME } /ece2400/sec4 % lcov --capture --directory . --output-file coverage.info % genhtml coverage.info --output-directory coverage-html These tools will produce easy to read HTML reports. While you can use a browser like firefox , it is faster (especially when working on the server) to use a terminal based browser like elinks : 1 % elinks coverage-html/index.html You should be able to use your mouse to browse to the report for the avg-test.c source file and verify that you are achieving 100% code coverage. Note that 100% code coverage is not the same as 100% path coverage; ask the instructors for more on this. Also note that 100% code coverage does not mean your program is guaranteed to be correct! To-Do On Your Own Try compiling gcd-test.c and executing the resulting binary with support for code coverage. Use the code coverage reports to verify that the test has less than 100% code coverage. Add more tests to improve the code coverage to 100%. 3. Using TravisCI and Codecov.io for Continuous Integration Continuous integration is the process of continually integrating, testing, and evaluating your code. We will be using two tools to facilitate continuous integration. The first is TravisCI, an online service which is tightly coupled to GitHub. TravisCI will automatically run all tests for a project every time code is pushed to GitHub. The second is Codecov.io, an online service for visualizing code coverage. To start, you need to enable TravisCI for the remote repository on GitHub. Log into TravisCI using your GitHub ID and password: https://travis-ci.org/profile Once you have signed in, you should go to your TravisCI profile and find the list of your public GitHub repositories. You may need to click Sync to ensure that TravisCI has the most recent view of your public repositories on GitHub. Turn on TravisCI with the little \"switch\" next to the repository we have been using in this tutorial ( githubid/ece2400-sec4-c-debug-coverage ). After enabling TravisCI for the githubid/ece2400-sec4-c-debug-coverage repository, you should be able to go to the TravisCI page for this repository: https://travis-ci.org/githubid/ece2400-sec4-c-debug-coverage TravisCI will report that there are no builds for this repository yet. TravisCI looks for a special file named .travis.yml in the top of your repository to determine how to build and test your project. We have already created one of those files for you, and you can see it here: 1 2 % cd ${ HOME } /ece2400/sec4 % cat .travis.yml Go ahead and commit all of the work you have done in this tutorial, then push your local commits to the remote repository on GitHub. If you revisit the TravisCI page for this repository, you should see TravisCI starting to build and run all of your tests. Just like we can use TravisCI to automatically run tests, we can use Codecov.io to automatically prepare code coverage reports on every commit. You can see your code coverage reports here: https://codecov.io/gh/githubid/ece2400-sec4-c-debug-coverage 4. Try Steps for Programming Assignments Spend some time looking at the .travis.yml file for PA1. Look at the TravisCI results for the PA1 milestone and also look at the Codecov.io results. You can find these results but clicking on the appropriate badges in your PA1 README.","title":"Ece2400 sec4 c debug coverage"},{"location":"ece2400-sec4-c-debug-coverage/#section-4-c-debug-and-code-coverage","text":"In the previous discussion section, you learned how to use C build and test frameworks to help automate the process of compiling and verifying your programs In this discussion, we will continue to learn about new tools that can help us better debug and verify our programs. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now fork the github repo for this discussion section so you have your own personal copy. Go to the example repo here: https://github.com/cornell-ece2400/ece2400-sec4-c-debug-coverage Click on the \"Fork\" button. Wait a few seconds and then visit the new copy of this repo in your own person GitHub workspace: https://github.com/githubid/ece2400-sec2 Where githubid is your GitHubID. Now clone the github repo for this discussion section. 1 2 3 4 5 % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone git@github.com:githubid/ece2400-sec4-c-debug-coverage sec4 % cd sec4 % ls Where again, the githubid is your GitHubID. The given src directory includes the following files: avg-test.c : source and test for avg function gcd-test.c : source and test for gcd function utst.h : simple C preprocessor macros for unit testing .travis.yml : TravisCI configuration script","title":"Section 4: C Debug and Code Coverage"},{"location":"ece2400-sec4-c-debug-coverage/#1-using-gdb-for-debugging","text":"There are two kinds of C/C++ programmers in the world: printf debuggers and GDB debuggers. Prof. Batten used to be a printf debuggers but teaching this course has converted him to be a GDB advocate. He will share his perspectives on this in the discussion section. Let's start by compiling a single-file program that uses the UTST macros to test our ubiquitous avg function. 1 2 3 % cd ${ HOME } /ece2400/sec4 % gcc -Wall -g -o avg-test avg-test.c % ./avg-test Notice how we include the -g option to turn on support for debugging. This code has a bug and should fail the test. Let's start by using printf debugging. Add some extra printfs to observe the state of the program as it executes. 1 2 3 4 5 6 7 int avg ( int x , int y ) { printf ( x = %d, y = %d \\n , x , y ); int sum = x + x ; printf ( sum = %d \\n , sum ); return sum / 2 ; } You should be able to see that the value for the sum variable is incorrect, but the value for the x and y variables are correct. This means we can narrow our focus to line~4 in the above code snippet. Hopefully, you should be able to spot the bug. Fix the bug, recompile, and rerun the program. Let's now try tracing the execution of this program using GDB. Then you can start GDB like this 1 2 % cd ${ HOME } /ece2400/sec4 % gdb -tui avg-test GDB will drop you into a GDB \"prompt\" which you can use to interactively execute your program. Your source code will show up at the top, and the GDB prompt is at the bottom. Here are some useful GDB commands: break location : set a breakpoint run : start running the program record : start recording the execution for reverse debugging step : execute the next C statement, step into a function call next : execute the next C statement, do not step into a function call rs : reserve step, undo the execution of current C statement print var : print a C variable continue : continue on to the next breakpoint quit : exit GDB refresh : refresh the source code display GDB is very sophisticated so of course there are many more commands you can use, but these are enough to get started. Let's start by just running the program in GDB: 1 (gdb) run Now let's try again, but first let's set a breakpoint to tell GDB to stop at a certain function or line in the program. The following will set a breakpoint at the beginning of the main function. 1 (gdb) break main You can see a little B marker in the margin next to the first statement in the main function indicating the location of the breakpoint. We can now use run to start the program running. The execution should stop at the beginning of the function main . You should see the first line of the function highlighted. 1 (gdb) run We can use record to turn on recording to enable reverse debugging and then we can step through the execution of each C statement using the step command. 1 2 (gdb) record (gdb) step Keep using step until you get into the avg function You can print out the value of any variable using the print command: 1 2 3 (gdb) print x (gdb) print y (gdb) print sum You can also step backwards using the rs command: 1 (gdb) rs Try stepping forward and backward through the avg function and print out various variables to see how they change during the execution. You can use quit to exit. 1 (gdb) quit To-Do On Your Own Try compiling gcd-test.c and executing the resulting binary. The test should fail. Use GDB debugging to find the bug and fix it.","title":"1. Using GDB for Debugging"},{"location":"ece2400-sec4-c-debug-coverage/#2-using-gcov-for-code-coverage","text":"One you have developed your implementation and the corresponding basic, directed, and random tests, you can then move on to understanding the quality of your current set of tests. One way to do this is to use code coverage tools. The idea here is to use a tool which will count how many times each line of code in your program is executed when running all of your tests. If there are lines of code which have never executed, then this is a good indicator that you need more tests to verify that part of your code. Let's start by recompiling our avg-test.c and turning on code coverage support. 1 2 3 % cd ${ HOME } /ece2400/sec4 % gcc -Wall -g --coverage -o avg-test avg-test.c % ./avg-test This will generate additional data in avg-test.gcda . To make this data easy to read and understand we need to run two more tools: lcov and genhtml like this: 1 2 3 % cd ${ HOME } /ece2400/sec4 % lcov --capture --directory . --output-file coverage.info % genhtml coverage.info --output-directory coverage-html These tools will produce easy to read HTML reports. While you can use a browser like firefox , it is faster (especially when working on the server) to use a terminal based browser like elinks : 1 % elinks coverage-html/index.html You should be able to use your mouse to browse to the report for the avg-test.c source file and verify that you are achieving 100% code coverage. Note that 100% code coverage is not the same as 100% path coverage; ask the instructors for more on this. Also note that 100% code coverage does not mean your program is guaranteed to be correct! To-Do On Your Own Try compiling gcd-test.c and executing the resulting binary with support for code coverage. Use the code coverage reports to verify that the test has less than 100% code coverage. Add more tests to improve the code coverage to 100%.","title":"2. Using GCOV for Code Coverage"},{"location":"ece2400-sec4-c-debug-coverage/#3-using-travisci-and-codecovio-for-continuous-integration","text":"Continuous integration is the process of continually integrating, testing, and evaluating your code. We will be using two tools to facilitate continuous integration. The first is TravisCI, an online service which is tightly coupled to GitHub. TravisCI will automatically run all tests for a project every time code is pushed to GitHub. The second is Codecov.io, an online service for visualizing code coverage. To start, you need to enable TravisCI for the remote repository on GitHub. Log into TravisCI using your GitHub ID and password: https://travis-ci.org/profile Once you have signed in, you should go to your TravisCI profile and find the list of your public GitHub repositories. You may need to click Sync to ensure that TravisCI has the most recent view of your public repositories on GitHub. Turn on TravisCI with the little \"switch\" next to the repository we have been using in this tutorial ( githubid/ece2400-sec4-c-debug-coverage ). After enabling TravisCI for the githubid/ece2400-sec4-c-debug-coverage repository, you should be able to go to the TravisCI page for this repository: https://travis-ci.org/githubid/ece2400-sec4-c-debug-coverage TravisCI will report that there are no builds for this repository yet. TravisCI looks for a special file named .travis.yml in the top of your repository to determine how to build and test your project. We have already created one of those files for you, and you can see it here: 1 2 % cd ${ HOME } /ece2400/sec4 % cat .travis.yml Go ahead and commit all of the work you have done in this tutorial, then push your local commits to the remote repository on GitHub. If you revisit the TravisCI page for this repository, you should see TravisCI starting to build and run all of your tests. Just like we can use TravisCI to automatically run tests, we can use Codecov.io to automatically prepare code coverage reports on every commit. You can see your code coverage reports here: https://codecov.io/gh/githubid/ece2400-sec4-c-debug-coverage","title":"3. Using TravisCI and Codecov.io for Continuous Integration"},{"location":"ece2400-sec4-c-debug-coverage/#4-try-steps-for-programming-assignments","text":"Spend some time looking at the .travis.yml file for PA1. Look at the TravisCI results for the PA1 milestone and also look at the Codecov.io results. You can find these results but clicking on the appropriate badges in your PA1 README.","title":"4. Try Steps for Programming Assignments"},{"location":"ece2400-sec5-c-profiling/","text":"Section 5: C Profiling In this discussion, we will explore how to measure the performance of a C evaluation program. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec5-c-profiling sec5 % cd sec5 % ls 1. Warmup: Implement Array Average Functions Take a look at the array-eval.c source file. You will see four functions: init_array : initialize an array of integers with random values avg_array : find average of an array of integers init_parray : initialize an array of pointers to integers avg_parray : find average of an array of pointers to integers The first two functions operate on an array of integers, while the second two functions operate on an array of pointers to integers. Start by sketching a state diagram for the given main program assuming size is set to 3. Work through the state diagram and stop when you get to the call to the avg_array function. Use this state diagram to understand the difference between the array of integers vs. the array of pointers to integers. Now implement the avg_array function which should find the average of the integers stored in the given array. Then implement the avg_parray function which should find the average of the integers pointed to by the given array. Compile and execute your program a couple of times, changing the seed passed into srand each time. Verify that the value returned by avg_array always equals the value returned by avg_parray and that the average is always around 500. 2. Measuring Execution Time Now assume we want to quantitatively measure how long it takes to initialize both arrays and then calculate the averages. To do this, we can use the time functions provided by the C standard library in the sys/time.h header file. Go ahead and add the following header to your evaluation program: 1 #include sys/time.h We can use the gettimeofday function to get the current time: http://man7.org/linux/man-pages/man2/gettimeofday.2.html This function takes as a parameter a pointer to a struct of type struct timeval . It uses call-by-pointer semantics to update this struct with the current time with a precision of 10s of microseconds. The struct has two fields: tv_sec is the number of seconds and tv_usec is the number of microseconds since January 1, 1970. We can use gettimeofday like this to quantitatively measure how long it takes to run an experiment. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // Track time using timers struct timeval start ; struct timeval end ; // Start tracking time gettimeofday ( start , NULL ); // Run the experiment // ... // Stop tracking time gettimeofday ( end , NULL ); // Calculate elapsed time double elapsed = ( end . tv_sec - start . tv_sec ) + ( ( end . tv_usec - start . tv_usec ) / 1000000.0 ); printf ( Elapsed time for trial is %f \\n , elapsed ); Modify the evaluation program to measure how long one experiment takes. You will notice that the execution time is very short ... so short that it is too fast for the resolution of the timer. We need to run a subtrial in a loop many times to make sure we have a long enough experiment that we can get a reasonable accurate time measurement. Put the subtrial in a loop like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int x ; int y ; for ( int j = 0 ; j 100000 ; j ++ ) { int array [ size ]; init_array ( array , size ); int * parray [ size ]; init_parray ( parray , array , size ); x = avg_array ( array , size ); y = avg_parray ( parray , size ); } Your program should now run for a couple of seconds and this should enable a much more precise time measurement. Try running the program at least five times and write down the results for each trial. Is the execution time always the same? If not, why not? We need to do several trials and then take the average execution time to ensure we can get a good estimate of the execution time. Restructure your evaluation program to look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 int main( void) { int ntrials = 5; int nsubtrials = 1e5; double elapsed_avg = 0.0; for ( int i = 0; i ntrials; i++ ) { // Track time using timers struct timeval start; struct timeval end; // Start tracking time gettimeofday( start, NULL ); // Run the experiment for ( int j = 0; j nsubtrials; j++ ) { // ... run one trial ... } // Stop tracking time gettimeofday( end, NULL ); // Calculate elapsed time double elapsed = ( end.tv_sec - start.tv_sec ) + ( ( end.tv_usec - start.tv_usec ) / 1000000.0 ); elapsed_avg += elapsed; printf( Elapsed time for trial %d is %f\\n , i, elapsed ); } // Calculate average elapsed time per trial elapsed_avg = elapsed_avg / ntrials; printf( Elapsed time (averaged) is %f\\n , elapsed_avg ); } Now use your evaluation program to quantitatively measure the execution time of this experiment. 3. Profiling Execution Time The previous section enables us to measure the overall execution time, but we might also be interested to know which functions are taking the most time. This can help us focus on the important hotspots for optimization. We can use profiling to do this kind of performance analysis. We will look at two profiling tools: gprof and perf . Let's start by recompiling our program with support for profiling: 1 2 % cd ${ HOME } /ece2400/sec5 % gcc -Wall -pg -o array-eval array-eval.c Notice the -pg command line option. This tells GCC to enable support for profiling. Now we run the program and use the gprof tool to analyze the execution time: 1 2 3 % cd ${ HOME } /ece2400/sec5 % ./array-eval % gprof ./array-eval The output will have two parts: a flat profile and a call graph profile. The flat profile specifies how many times each function was called and how much time was spent in each function. The call graph profile additionally indicates what exact sequence of function calls led let to a specific function call, and how much time was spent in that specific function call. Why do you think more time is spent in init_array ? Let's now use a different tool called perf : 1 2 3 % cd ${ HOME } /ece2400/sec5 % perf record ./array-eval % perf report --stdio The output will show a flat profile, but it also includes how much time was spent in various functions contained in the standard C library. Does this information help explain why more time is spent in init_array ? We can use these profiling tools to help identify hotspots in our code for optimization. Hotspots might be due to a small function which is called many, many times, or a function which is only called a few times but takes a very long time to execute.","title":"Ece2400 sec5 c profiling"},{"location":"ece2400-sec5-c-profiling/#section-5-c-profiling","text":"In this discussion, we will explore how to measure the performance of a C evaluation program. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec5-c-profiling sec5 % cd sec5 % ls","title":"Section 5: C Profiling"},{"location":"ece2400-sec5-c-profiling/#1-warmup-implement-array-average-functions","text":"Take a look at the array-eval.c source file. You will see four functions: init_array : initialize an array of integers with random values avg_array : find average of an array of integers init_parray : initialize an array of pointers to integers avg_parray : find average of an array of pointers to integers The first two functions operate on an array of integers, while the second two functions operate on an array of pointers to integers. Start by sketching a state diagram for the given main program assuming size is set to 3. Work through the state diagram and stop when you get to the call to the avg_array function. Use this state diagram to understand the difference between the array of integers vs. the array of pointers to integers. Now implement the avg_array function which should find the average of the integers stored in the given array. Then implement the avg_parray function which should find the average of the integers pointed to by the given array. Compile and execute your program a couple of times, changing the seed passed into srand each time. Verify that the value returned by avg_array always equals the value returned by avg_parray and that the average is always around 500.","title":"1. Warmup: Implement Array Average Functions"},{"location":"ece2400-sec5-c-profiling/#2-measuring-execution-time","text":"Now assume we want to quantitatively measure how long it takes to initialize both arrays and then calculate the averages. To do this, we can use the time functions provided by the C standard library in the sys/time.h header file. Go ahead and add the following header to your evaluation program: 1 #include sys/time.h We can use the gettimeofday function to get the current time: http://man7.org/linux/man-pages/man2/gettimeofday.2.html This function takes as a parameter a pointer to a struct of type struct timeval . It uses call-by-pointer semantics to update this struct with the current time with a precision of 10s of microseconds. The struct has two fields: tv_sec is the number of seconds and tv_usec is the number of microseconds since January 1, 1970. We can use gettimeofday like this to quantitatively measure how long it takes to run an experiment. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // Track time using timers struct timeval start ; struct timeval end ; // Start tracking time gettimeofday ( start , NULL ); // Run the experiment // ... // Stop tracking time gettimeofday ( end , NULL ); // Calculate elapsed time double elapsed = ( end . tv_sec - start . tv_sec ) + ( ( end . tv_usec - start . tv_usec ) / 1000000.0 ); printf ( Elapsed time for trial is %f \\n , elapsed ); Modify the evaluation program to measure how long one experiment takes. You will notice that the execution time is very short ... so short that it is too fast for the resolution of the timer. We need to run a subtrial in a loop many times to make sure we have a long enough experiment that we can get a reasonable accurate time measurement. Put the subtrial in a loop like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int x ; int y ; for ( int j = 0 ; j 100000 ; j ++ ) { int array [ size ]; init_array ( array , size ); int * parray [ size ]; init_parray ( parray , array , size ); x = avg_array ( array , size ); y = avg_parray ( parray , size ); } Your program should now run for a couple of seconds and this should enable a much more precise time measurement. Try running the program at least five times and write down the results for each trial. Is the execution time always the same? If not, why not? We need to do several trials and then take the average execution time to ensure we can get a good estimate of the execution time. Restructure your evaluation program to look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 int main( void) { int ntrials = 5; int nsubtrials = 1e5; double elapsed_avg = 0.0; for ( int i = 0; i ntrials; i++ ) { // Track time using timers struct timeval start; struct timeval end; // Start tracking time gettimeofday( start, NULL ); // Run the experiment for ( int j = 0; j nsubtrials; j++ ) { // ... run one trial ... } // Stop tracking time gettimeofday( end, NULL ); // Calculate elapsed time double elapsed = ( end.tv_sec - start.tv_sec ) + ( ( end.tv_usec - start.tv_usec ) / 1000000.0 ); elapsed_avg += elapsed; printf( Elapsed time for trial %d is %f\\n , i, elapsed ); } // Calculate average elapsed time per trial elapsed_avg = elapsed_avg / ntrials; printf( Elapsed time (averaged) is %f\\n , elapsed_avg ); } Now use your evaluation program to quantitatively measure the execution time of this experiment.","title":"2. Measuring Execution Time"},{"location":"ece2400-sec5-c-profiling/#3-profiling-execution-time","text":"The previous section enables us to measure the overall execution time, but we might also be interested to know which functions are taking the most time. This can help us focus on the important hotspots for optimization. We can use profiling to do this kind of performance analysis. We will look at two profiling tools: gprof and perf . Let's start by recompiling our program with support for profiling: 1 2 % cd ${ HOME } /ece2400/sec5 % gcc -Wall -pg -o array-eval array-eval.c Notice the -pg command line option. This tells GCC to enable support for profiling. Now we run the program and use the gprof tool to analyze the execution time: 1 2 3 % cd ${ HOME } /ece2400/sec5 % ./array-eval % gprof ./array-eval The output will have two parts: a flat profile and a call graph profile. The flat profile specifies how many times each function was called and how much time was spent in each function. The call graph profile additionally indicates what exact sequence of function calls led let to a specific function call, and how much time was spent in that specific function call. Why do you think more time is spent in init_array ? Let's now use a different tool called perf : 1 2 3 % cd ${ HOME } /ece2400/sec5 % perf record ./array-eval % perf report --stdio The output will show a flat profile, but it also includes how much time was spent in various functions contained in the standard C library. Does this information help explain why more time is spent in init_array ? We can use these profiling tools to help identify hotspots in our code for optimization. Hotspots might be due to a small function which is called many, many times, or a function which is only called a few times but takes a very long time to execute.","title":"3. Profiling Execution Time"},{"location":"ece2400-sec6-pa3-walkthrough/","text":"Section 6: ECE 2400 PA 3 Walkthrough In this discussion, we will explore two different implementations of a simple sorting algorithm called insertion sort . We will use similar build, test, and evaluation infrastructure as you will use in PA 3. Hopefully, after this section, you can start working on your PA 3. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-pa3-walkthrough.git sec6 % cd sec6 % ls The repo includes the following files: CMake configuration script: CMakeLists.txt Header file, source file, and ad-hoc test for out-of-place insertion sort implementation: src/oop-insertion-sort.h src/oop-insertion-sort.c src/oop-insertion-sort-main.c Header file, source file, and ad-hoc test for in-place insertion sort implementation: src/ip-insertion-sort.h src/ip-insertion-sort.c src/ip-insertion-sort-main.c Test files for both implementations tests/oop-insertion-sort-basic-tests.c tests/oop-insertion-sort-directed-tests.c tests/oop-insertion-sort-random-tests.c tests/ip-insertion-sort-basic-tests.c tests/ip-insertion-sort-directed-tests.c tests/ip-insertion-sort-random-tests.c Files containing utility functions: src/utils.h src/utils.c tests/utst.h Performance evaluation files: src/sort-eval.c src/sort.dat You will implement two versions of the insertion sort algorithm. The first version is called out-of-place insertion sort (oop-insertion-sort) that uses extra temporary space. The second version is called in-place insertion sort (ip-insertion-sort) that does NOT use extra temporary space to sort a given array. Here are the two functions you are about to implement: 1 2 void oop_insertion_sort( int arr[], size_t size ); void ip_insertion_sort ( int arr[], size_t size ); Both functions take as input an integer array arr with length size and sort the array in an ascending order. Sorted insertion Before we talk about insertion sort algorithm, let's consider the following problem. Let's say we have an array of numbers sorted in an ascending order. We want to insert a new number to the array such that the array remains sorted after the insertion. For example, my array is array = { 1, 4, 6, 10, 15 } , and the number to be inserted is value = 5 . After the sorted insertion, my array will be array = { 1, 4, 5, 6, 10, 15 } . How can we do that? One way to do the insertion is that we look for the correct position of value in array , which is in between 4 and 6 , insert 5 in that position, and shift the rest of the array to the right by one position. We can do that using the following algorithm. 1 2 3 4 5 6 7 8 9 10 11 12 13 // Inputs // - arr : a sorted array // - begin : beginning index of the array // - end : index of the element after the last element in the array // - value : new value to be inserted // Outputs // - arr : a sorted array with 1 extra value sorted_insert_fwd( arr, begin, end, value ): for i in begin to end (excluding end) if value arr[i] swap value and arr[i] arr[end] = value The above algorithm is called forward sorted insertion. It iterates from the begin to the end of the array, and inserts the value into a correct position. Your tasks - Implement the above algorithm inside function sorted_insert_fwd in src/utils.c - Write a couple of ad-hoc tests to verify the function in src/sorted-insert-main.c - Can you do the insertion more efficiently? Out-of-place insertion sort (oop-insertion-sort) We can leverage the sorted insertion algorithm in our insertion sort by taking each element out of the input array and insert it into a sorted output array such that the output array remains sorted. Here is the pseudocode: 1 2 3 4 5 oop_insertion_sort( arr, size ): make an empty array called tmp_arr of size size for i in 0 to size (excluding size) sorted_insert_fwd( tmp_arr, 0, i, arr[i] ) copy tmp_arr to arr This algorithm is out-of-place since we need an extra array of the same size to temporarily store sorted elements. Your tasks Implement the above algorithm in oop_insertion_sort() function in src/oop_insertion_sort.c Add directed and random tests to test your implementation Analyze the time and space complexity of your implementation In-place insertion sort (ip-insertion-sort) We can do better than out-of-place insertion sort in terms of space complexity by not using the temporary array. Instead, we can sort all elements by swapping them directly in the original array (i.e., in place). Here is the pseudocode: 1 2 3 ip_insertion_sort( arr, size ) for i in 0 to size (excluding size) sorted_insert_fwd( arr, 0, i, arr[i] ) This algorithm is in-place since we do NOT need an extra array of the same size to temporarily store sorted elements. Your tasks Implement the above algorithm in ip_insertion_sort() function in src/ip_insertion_sort.c Add directed and random tests to test your implementation Analyze the time and space complexity of your implementation Evaluate both implementations Your tasks - Run the evaluation program to evaluate the performance of both implementations 1 2 3 4 % cd ${HOME}/ece2400/sec6 % mkdir -p build-eval % cmake .. -DCMAKE_BUILD_TYPE=RELEASE % make eval","title":"Ece2400 sec6 pa3 walkthrough"},{"location":"ece2400-sec6-pa3-walkthrough/#section-6-ece-2400-pa-3-walkthrough","text":"In this discussion, we will explore two different implementations of a simple sorting algorithm called insertion sort . We will use similar build, test, and evaluation infrastructure as you will use in PA 3. Hopefully, after this section, you can start working on your PA 3. Follow the same process as in the previous discussion section. You need to login to a workstation with your NetID and password. Start a terminal and then don't forget to source the setup script! 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-pa3-walkthrough.git sec6 % cd sec6 % ls The repo includes the following files: CMake configuration script: CMakeLists.txt Header file, source file, and ad-hoc test for out-of-place insertion sort implementation: src/oop-insertion-sort.h src/oop-insertion-sort.c src/oop-insertion-sort-main.c Header file, source file, and ad-hoc test for in-place insertion sort implementation: src/ip-insertion-sort.h src/ip-insertion-sort.c src/ip-insertion-sort-main.c Test files for both implementations tests/oop-insertion-sort-basic-tests.c tests/oop-insertion-sort-directed-tests.c tests/oop-insertion-sort-random-tests.c tests/ip-insertion-sort-basic-tests.c tests/ip-insertion-sort-directed-tests.c tests/ip-insertion-sort-random-tests.c Files containing utility functions: src/utils.h src/utils.c tests/utst.h Performance evaluation files: src/sort-eval.c src/sort.dat You will implement two versions of the insertion sort algorithm. The first version is called out-of-place insertion sort (oop-insertion-sort) that uses extra temporary space. The second version is called in-place insertion sort (ip-insertion-sort) that does NOT use extra temporary space to sort a given array. Here are the two functions you are about to implement: 1 2 void oop_insertion_sort( int arr[], size_t size ); void ip_insertion_sort ( int arr[], size_t size ); Both functions take as input an integer array arr with length size and sort the array in an ascending order. Sorted insertion Before we talk about insertion sort algorithm, let's consider the following problem. Let's say we have an array of numbers sorted in an ascending order. We want to insert a new number to the array such that the array remains sorted after the insertion. For example, my array is array = { 1, 4, 6, 10, 15 } , and the number to be inserted is value = 5 . After the sorted insertion, my array will be array = { 1, 4, 5, 6, 10, 15 } . How can we do that? One way to do the insertion is that we look for the correct position of value in array , which is in between 4 and 6 , insert 5 in that position, and shift the rest of the array to the right by one position. We can do that using the following algorithm. 1 2 3 4 5 6 7 8 9 10 11 12 13 // Inputs // - arr : a sorted array // - begin : beginning index of the array // - end : index of the element after the last element in the array // - value : new value to be inserted // Outputs // - arr : a sorted array with 1 extra value sorted_insert_fwd( arr, begin, end, value ): for i in begin to end (excluding end) if value arr[i] swap value and arr[i] arr[end] = value The above algorithm is called forward sorted insertion. It iterates from the begin to the end of the array, and inserts the value into a correct position. Your tasks - Implement the above algorithm inside function sorted_insert_fwd in src/utils.c - Write a couple of ad-hoc tests to verify the function in src/sorted-insert-main.c - Can you do the insertion more efficiently? Out-of-place insertion sort (oop-insertion-sort) We can leverage the sorted insertion algorithm in our insertion sort by taking each element out of the input array and insert it into a sorted output array such that the output array remains sorted. Here is the pseudocode: 1 2 3 4 5 oop_insertion_sort( arr, size ): make an empty array called tmp_arr of size size for i in 0 to size (excluding size) sorted_insert_fwd( tmp_arr, 0, i, arr[i] ) copy tmp_arr to arr This algorithm is out-of-place since we need an extra array of the same size to temporarily store sorted elements. Your tasks Implement the above algorithm in oop_insertion_sort() function in src/oop_insertion_sort.c Add directed and random tests to test your implementation Analyze the time and space complexity of your implementation In-place insertion sort (ip-insertion-sort) We can do better than out-of-place insertion sort in terms of space complexity by not using the temporary array. Instead, we can sort all elements by swapping them directly in the original array (i.e., in place). Here is the pseudocode: 1 2 3 ip_insertion_sort( arr, size ) for i in 0 to size (excluding size) sorted_insert_fwd( arr, 0, i, arr[i] ) This algorithm is in-place since we do NOT need an extra array of the same size to temporarily store sorted elements. Your tasks Implement the above algorithm in ip_insertion_sort() function in src/ip_insertion_sort.c Add directed and random tests to test your implementation Analyze the time and space complexity of your implementation Evaluate both implementations Your tasks - Run the evaluation program to evaluate the performance of both implementations 1 2 3 4 % cd ${HOME}/ece2400/sec6 % mkdir -p build-eval % cmake .. -DCMAKE_BUILD_TYPE=RELEASE % make eval","title":"Section 6: ECE 2400 PA 3 Walkthrough"},{"location":"ece2400-sec7-cxx-intro/","text":"Section 7: Introduction to C++ In this discussion, we will transition from C to C++ by incrementally moving a simple C structure into C++. We will work on the following concepts in this section: C++ Structure and Class Static member functions in C++ structure Non-static member functions in C++ structure/class Before you start, let's source our setup script like this: 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec7-cxx-intro.git sec7 % cd sec7 % ls The repo includes the following files: c-version/ directory c-version/complex.c : a C implementation of complex_t structure cxx-versions/ directory cxx-versions/complex-v1.cc : version 1 of our C++ implementation of Complex structure. This version introduces C++ structure and static member functions cxx-versions/complex-v2.cc : version 2 of our C++ implementation of Complex structure. This version introduces non-static member functions for a structure in C++ and how to call them. cxx-versions/complex-v3.cc : version 3 of our C++ implementation of Complex structure. This version introduces how to define and use constructors for a structure in C++. Students will also practice how to pass a variable to a function by reference. cxx-versions/complex-v4.cc : version 4 of our C++ implementation of Complex structure. This version introduces copy constructor and operator overloading. 1. Step 1: C version Understand the implementation of complex_t structure in c-version/complex.c Compile and run the program like this 1 2 3 cd c-version/ gcc -Wall -o complex complex.c ./complex 2. Step 2: First C++ version of complex_t In this version, we're making the first steps toward C++. First, we change how to declare a structure. We use C++ coding convention to name our structure Complex instead of complex_t in C. Second, we move add and print functions inside the definition of Complex , and make the functions static . Third, in main , we call the two functions using a namespace Complex Your task : Implement the add function 3. Step 3: Second C++ version In this version, we make both add and print functions non-static. In main , we change how we call the two functions. Now every call to add and print is associated with a specific instance of Complex . Also you may notice that, the this_ variables in complex-v1.cc are replaced with C++ keyword this . In C++, this is a pointer to the current instance of a structure or class. Your task : Implement the add function 4. Step 4: Third C++ version In this version, we introduce a constructor for our Complex structure. The constructor helps us initialize member fields of the structure. In main , we use the constructor to initialize a structure instance instead of initializing each member field directly. Your task : Implement the add function. The function now takes a reference to a structure instance instead of a pointer. 5. Step 5: Fourth C++ version Your tasks First, you make a copy constructor that takes a constant reference to an instance of Complex and initialize all member fields by copying real and imag from the input x object. Second, you overload the operator+ so that we can add two Complex instances together.","title":"Ece2400 sec7 cxx intro"},{"location":"ece2400-sec7-cxx-intro/#section-7-introduction-to-c","text":"In this discussion, we will transition from C to C++ by incrementally moving a simple C structure into C++. We will work on the following concepts in this section: C++ Structure and Class Static member functions in C++ structure Non-static member functions in C++ structure/class Before you start, let's source our setup script like this: 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec7-cxx-intro.git sec7 % cd sec7 % ls The repo includes the following files: c-version/ directory c-version/complex.c : a C implementation of complex_t structure cxx-versions/ directory cxx-versions/complex-v1.cc : version 1 of our C++ implementation of Complex structure. This version introduces C++ structure and static member functions cxx-versions/complex-v2.cc : version 2 of our C++ implementation of Complex structure. This version introduces non-static member functions for a structure in C++ and how to call them. cxx-versions/complex-v3.cc : version 3 of our C++ implementation of Complex structure. This version introduces how to define and use constructors for a structure in C++. Students will also practice how to pass a variable to a function by reference. cxx-versions/complex-v4.cc : version 4 of our C++ implementation of Complex structure. This version introduces copy constructor and operator overloading. 1. Step 1: C version Understand the implementation of complex_t structure in c-version/complex.c Compile and run the program like this 1 2 3 cd c-version/ gcc -Wall -o complex complex.c ./complex 2. Step 2: First C++ version of complex_t In this version, we're making the first steps toward C++. First, we change how to declare a structure. We use C++ coding convention to name our structure Complex instead of complex_t in C. Second, we move add and print functions inside the definition of Complex , and make the functions static . Third, in main , we call the two functions using a namespace Complex Your task : Implement the add function 3. Step 3: Second C++ version In this version, we make both add and print functions non-static. In main , we change how we call the two functions. Now every call to add and print is associated with a specific instance of Complex . Also you may notice that, the this_ variables in complex-v1.cc are replaced with C++ keyword this . In C++, this is a pointer to the current instance of a structure or class. Your task : Implement the add function 4. Step 4: Third C++ version In this version, we introduce a constructor for our Complex structure. The constructor helps us initialize member fields of the structure. In main , we use the constructor to initialize a structure instance instead of initializing each member field directly. Your task : Implement the add function. The function now takes a reference to a structure instance instead of a pointer. 5. Step 5: Fourth C++ version Your tasks First, you make a copy constructor that takes a constant reference to an instance of Complex and initialize all member fields by copying real and imag from the input x object. Second, you overload the operator+ so that we can add two Complex instances together.","title":"Section 7: Introduction to C++"},{"location":"ece2400-sec8-cxx-class/","text":"Section 8: C++ Class Before you start, let's source our setup script like this: 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec8-cxx-class.git sec8 % cd sec8 % ls 1. Part 1: Organize your code in C++ So far in lectures, we have seen C++ code written all together in one single .cc file. That's not the case in practice when you need to deal with large and complex code base. Let's consider an example of the Complex class in our discussion section last week. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 # include cstdio //======================================================================== // Complex //======================================================================== // Declaration and definition of Complex class and its members class Complex { public : //---------------------------------------------------------------------- // constructors //---------------------------------------------------------------------- Complex ( double real_ , double imag_ ) { real = real_ ; imag = imag_ ; } Complex ( const Complex x ) { real = x . real ; imag = x . imag ; } //---------------------------------------------------------------------- // add //---------------------------------------------------------------------- // Add x complex number to this complex number void add ( const Complex x ) { real += x . real ; imag += x . imag ; } //------------------------------------------------------------------------ // print //------------------------------------------------------------------------ // Print this complex number void print () { std :: printf ( %.2f+%.2fi , real , imag ); } private : double real ; double imag ; }; //======================================================================== // operator+ overload //======================================================================== Complex operator + ( const Complex x , const Complex y ) { Complex tmp = x ; tmp . add ( y ); return tmp ; } //======================================================================== // main //======================================================================== int main ( void ) { // Create complex number a by calling the constructor of Complex Complex a ( 1.5 , 2.5 ); std :: printf ( a = ); a . print (); printf ( \\n ); // Create complex number b by calling the constructor of Complex Complex b ( 3.5 , 4.5 ); std :: printf ( b = ); b . print (); printf ( \\n ); // Add a and b together and store the sum to c std :: printf ( Doing c = a + b ...\\n ); Complex c = a + b ; // Print out c std :: printf ( c = ); c . print (); printf ( \\n ); // Add b to a std :: printf ( Doing a += b ...\\n ); a . add ( b ); // Print out a std :: printf ( a = ); a . print (); printf ( \\n ); return 0 ; } Here we declare and define Complex class and its members (i.e., member functions and member fields) all together in one .cc file. We also have a main function that uses the class. Let's imagine that your class has tens of member functions, each of which takes many lines of code to implement. How would your source file look like? Gigantic! Following are some drawbacks of this monolithic approach: Very large code base - very hard to maintain and debug Declarations and definitions are put together - very hard to see the interface of a class Hard to include a class into another file or project Instead, we should break the code into multiple files complex.h : contains only declarations of related classes, functions, and variables and no implementation detail. complex.cc : contains only definition/implementation of classes, functions, and variables declared in the header file complex.h . This file needs to include the header file. complex-main.cc : contains only user code that uses the class. This file needs to include the header file. Your tasks Go to part1/ directory We already provide you the header file complex.h Copy the implementation of Complex class's functions and the overloaded operator++ into complex.cc . We already give you an example of the class's default constructor. Copy the main function into complex-main.cc Compile your code using g++ 2. Part 2: Make your RVector class In this part, we will implement an RVector data structure in C++. RVector works exactly like the rvector_int_t that you implemented in PA 2. You will need to implement the following functions in part2/rvector.cc RVector::RVector() - default constructor: initialize m_max_size , m_size , and m_arr to default values. Remember that the RVector is empty initially. RVector::RVector( size_t max_size ) - a constructor: initialize m_max_size to max_size , m_size and m_arr to default values. Remember that the RVector is empty initially. RVector::RVector( const RVector x ) - a copy constructor: copy all numbers from vector x to this vector. Remember to allocate memory properly for this constructor. RVector::~RVector() - a destructor: deallocate any dynamically allocated memory associated with this RVector . void RVector::push_back( int num ) : push back a new number into this vector int RVector::at( size_t index ) : return a number at a given index. Throw an OutOfRangeException when the index is out of bound After you finish implementing all functions, you will need to write a small ad-hoc tests in part2/rvector-main.cc to test them. Compile and run the test using g++ .","title":"Ece2400 sec8 cxx class"},{"location":"ece2400-sec8-cxx-class/#section-8-c-class","text":"Before you start, let's source our setup script like this: 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec8-cxx-class.git sec8 % cd sec8 % ls 1. Part 1: Organize your code in C++ So far in lectures, we have seen C++ code written all together in one single .cc file. That's not the case in practice when you need to deal with large and complex code base. Let's consider an example of the Complex class in our discussion section last week. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 # include cstdio //======================================================================== // Complex //======================================================================== // Declaration and definition of Complex class and its members class Complex { public : //---------------------------------------------------------------------- // constructors //---------------------------------------------------------------------- Complex ( double real_ , double imag_ ) { real = real_ ; imag = imag_ ; } Complex ( const Complex x ) { real = x . real ; imag = x . imag ; } //---------------------------------------------------------------------- // add //---------------------------------------------------------------------- // Add x complex number to this complex number void add ( const Complex x ) { real += x . real ; imag += x . imag ; } //------------------------------------------------------------------------ // print //------------------------------------------------------------------------ // Print this complex number void print () { std :: printf ( %.2f+%.2fi , real , imag ); } private : double real ; double imag ; }; //======================================================================== // operator+ overload //======================================================================== Complex operator + ( const Complex x , const Complex y ) { Complex tmp = x ; tmp . add ( y ); return tmp ; } //======================================================================== // main //======================================================================== int main ( void ) { // Create complex number a by calling the constructor of Complex Complex a ( 1.5 , 2.5 ); std :: printf ( a = ); a . print (); printf ( \\n ); // Create complex number b by calling the constructor of Complex Complex b ( 3.5 , 4.5 ); std :: printf ( b = ); b . print (); printf ( \\n ); // Add a and b together and store the sum to c std :: printf ( Doing c = a + b ...\\n ); Complex c = a + b ; // Print out c std :: printf ( c = ); c . print (); printf ( \\n ); // Add b to a std :: printf ( Doing a += b ...\\n ); a . add ( b ); // Print out a std :: printf ( a = ); a . print (); printf ( \\n ); return 0 ; } Here we declare and define Complex class and its members (i.e., member functions and member fields) all together in one .cc file. We also have a main function that uses the class. Let's imagine that your class has tens of member functions, each of which takes many lines of code to implement. How would your source file look like? Gigantic! Following are some drawbacks of this monolithic approach: Very large code base - very hard to maintain and debug Declarations and definitions are put together - very hard to see the interface of a class Hard to include a class into another file or project Instead, we should break the code into multiple files complex.h : contains only declarations of related classes, functions, and variables and no implementation detail. complex.cc : contains only definition/implementation of classes, functions, and variables declared in the header file complex.h . This file needs to include the header file. complex-main.cc : contains only user code that uses the class. This file needs to include the header file. Your tasks Go to part1/ directory We already provide you the header file complex.h Copy the implementation of Complex class's functions and the overloaded operator++ into complex.cc . We already give you an example of the class's default constructor. Copy the main function into complex-main.cc Compile your code using g++ 2. Part 2: Make your RVector class In this part, we will implement an RVector data structure in C++. RVector works exactly like the rvector_int_t that you implemented in PA 2. You will need to implement the following functions in part2/rvector.cc RVector::RVector() - default constructor: initialize m_max_size , m_size , and m_arr to default values. Remember that the RVector is empty initially. RVector::RVector( size_t max_size ) - a constructor: initialize m_max_size to max_size , m_size and m_arr to default values. Remember that the RVector is empty initially. RVector::RVector( const RVector x ) - a copy constructor: copy all numbers from vector x to this vector. Remember to allocate memory properly for this constructor. RVector::~RVector() - a destructor: deallocate any dynamically allocated memory associated with this RVector . void RVector::push_back( int num ) : push back a new number into this vector int RVector::at( size_t index ) : return a number at a given index. Throw an OutOfRangeException when the index is out of bound After you finish implementing all functions, you will need to write a small ad-hoc tests in part2/rvector-main.cc to test them. Compile and run the test using g++ .","title":"Section 8: C++ Class"},{"location":"ece2400-sec9-pa5-walkthrough/","text":"Section 9: PA 5 Walkthrough The goal of this discussion section is to help you get started in PA 5. In this section, we will get familiar with some utility classes provided in the PA, and implement a brute-force version of the KNN algorithm (i.e., K is limited to 1) to find the nearest neighbor of a given point in a point dataset. Before you start, let's source our setup script like this: 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec9-pa5-walkthrough.git sec9 % cd sec9 % ls You will see the following files in the directory: CMakeLists.txt : CMake build configuration file src/constants.h : header file declaring some necessary constants src/digits.dat : a small image dataset src/knn-brute-force.h : header file declaring knn function src/knn-brute-force.cc : source file implementing the knn function src/point.h : header file containing definition of Point class src/drawing.h : header file containing definition of Drawing class src/types.h : header file declaring Image , Label , and LabledImage class src/types.cc and src/types.inl : source file implementing Image , Label , and LabledImage class and some inline functions src/types-adhoc.cc : an ad-hoc program that uses classes declared in src/types.h tests/knn-test.cc : test program for the knn function tests/utst.h : unit testing macros 1. Part 1: Getting familiar with Image, Label, and LabeledImage classes Before you start this part, read section 2.1 in the PA 5's handout to understand: (1) the interface of Image , Label , and LabledImage classes, (2) what they do, and (3) member functions that you will use in the PA. We provide some small activities in src/types-adhoc.cc for you to practice using some member functions in the three classes. Instructions are provided in the code. After you complete each activity, you can run types-adhoc like this to see results on your terminal: 1 2 3 4 5 % cd ${HOME}/ece2400/sec9 % mkdir -p build % cd build % cmake .. % make run-types-adhoc 2. Part 2: Brainstorming and implementing HandwritingRecSysClassifyOnes Now let's start working on the first part of your PA. Read the section 2.3 in the PA's handout to understand what you are asked to implement for this part. Basically you will implement a system that can only classify images of ones. This system does not use any training dataset to do the classification, but uses an algorithmic approach instead. Think about if you're given an image of an unlabeled handwritten digit. How can you recognize if the digit is 1 or not? See the following figures of digit 1 and 2 represented as 2-D arrays of pixel values. Discuss your solutions with the rest of the class. Now clone your group's repo like this: 1 2 3 % cd ~/ece2400 % git clone git@github.com:cornell-ece2400/group_ group-id % cd group_ group-id Start implementing your algorithm in src/hrs-ones.cc . 3. Part 3: Implementing a KNN algorithm working with Point (take-home exercise) In this part, we go back to the section 9's repository. 1 % cd ~/ece2400/sec9 Before you start working on this part, read section 2.4 in the PA 5's handout to understand the following concepts: KNN algorithm Euclidean distance How to calculate the Euclidean distance between two points Then, you will implement a simple KNN algorithm that takes a dataset of points and a target point, and returns the point nearest to the target point in the dataset. It's essentially the KNN algorithm with K equal to one. A brute-force implementation of the KNN algorithm simply computes the distance between the target point and every single point in the dataset. It returns the point that is closest to the target point. After you complete your implementation, add more tests in tests/knn-test.cc . Look at the given test case. You will see that we use Drawing class to draw points on the terminal so that you can visualize where your points are in a 2-D space. Play around with this drawing feature. It will become handy when you work on your PA 5. You can run the test like this: 1 2 3 4 5 % cd ${HOME}/ece2400/sec9 % mkdir -p build % cd build % cmake .. % make check-knn","title":"Ece2400 sec9 pa5 walkthrough"},{"location":"ece2400-sec9-pa5-walkthrough/#section-9-pa-5-walkthrough","text":"The goal of this discussion section is to help you get started in PA 5. In this section, we will get familiar with some utility classes provided in the PA, and implement a brute-force version of the KNN algorithm (i.e., K is limited to 1) to find the nearest neighbor of a given point in a point dataset. Before you start, let's source our setup script like this: 1 % source setup-ece2400.sh Now clone the github repo for this discussion section. No need to fork the repo, just clone it. 1 2 3 4 5 % mkdir -p ${HOME}/ece2400 % cd ${HOME}/ece2400 % git clone git@github.com:cornell-ece2400/ece2400-sec9-pa5-walkthrough.git sec9 % cd sec9 % ls You will see the following files in the directory: CMakeLists.txt : CMake build configuration file src/constants.h : header file declaring some necessary constants src/digits.dat : a small image dataset src/knn-brute-force.h : header file declaring knn function src/knn-brute-force.cc : source file implementing the knn function src/point.h : header file containing definition of Point class src/drawing.h : header file containing definition of Drawing class src/types.h : header file declaring Image , Label , and LabledImage class src/types.cc and src/types.inl : source file implementing Image , Label , and LabledImage class and some inline functions src/types-adhoc.cc : an ad-hoc program that uses classes declared in src/types.h tests/knn-test.cc : test program for the knn function tests/utst.h : unit testing macros 1. Part 1: Getting familiar with Image, Label, and LabeledImage classes Before you start this part, read section 2.1 in the PA 5's handout to understand: (1) the interface of Image , Label , and LabledImage classes, (2) what they do, and (3) member functions that you will use in the PA. We provide some small activities in src/types-adhoc.cc for you to practice using some member functions in the three classes. Instructions are provided in the code. After you complete each activity, you can run types-adhoc like this to see results on your terminal: 1 2 3 4 5 % cd ${HOME}/ece2400/sec9 % mkdir -p build % cd build % cmake .. % make run-types-adhoc 2. Part 2: Brainstorming and implementing HandwritingRecSysClassifyOnes Now let's start working on the first part of your PA. Read the section 2.3 in the PA's handout to understand what you are asked to implement for this part. Basically you will implement a system that can only classify images of ones. This system does not use any training dataset to do the classification, but uses an algorithmic approach instead. Think about if you're given an image of an unlabeled handwritten digit. How can you recognize if the digit is 1 or not? See the following figures of digit 1 and 2 represented as 2-D arrays of pixel values. Discuss your solutions with the rest of the class. Now clone your group's repo like this: 1 2 3 % cd ~/ece2400 % git clone git@github.com:cornell-ece2400/group_ group-id % cd group_ group-id Start implementing your algorithm in src/hrs-ones.cc . 3. Part 3: Implementing a KNN algorithm working with Point (take-home exercise) In this part, we go back to the section 9's repository. 1 % cd ~/ece2400/sec9 Before you start working on this part, read section 2.4 in the PA 5's handout to understand the following concepts: KNN algorithm Euclidean distance How to calculate the Euclidean distance between two points Then, you will implement a simple KNN algorithm that takes a dataset of points and a target point, and returns the point nearest to the target point in the dataset. It's essentially the KNN algorithm with K equal to one. A brute-force implementation of the KNN algorithm simply computes the distance between the target point and every single point in the dataset. It returns the point that is closest to the target point. After you complete your implementation, add more tests in tests/knn-test.cc . Look at the given test case. You will see that we use Drawing class to draw points on the terminal so that you can visualize where your points are in a 2-D space. Play around with this drawing feature. It will become handy when you work on your PA 5. You can run the test like this: 1 2 3 4 5 % cd ${HOME}/ece2400/sec9 % mkdir -p build % cd build % cmake .. % make check-knn","title":"Section 9: PA 5 Walkthrough"},{"location":"ece2400-tut1-linux-git/","text":"Tutorial 1: Linux and Git","title":"Ece2400 tut1 linux git"},{"location":"ece2400-tut1-linux-git/#tutorial-1-linux-and-git","text":"","title":"Tutorial 1: Linux and Git"},{"location":"ece2400-tut2-c-basics/","text":"Tutorial 2 : Compiling and Running C Programs The first few programming assignments for this course will use the C programming language. In lecture we use Compiler Explorer and Repl.it to quickly experiment with small C programs, but eventually we need to actually write and compile C programs on a real machine. This tutorial discusses how we can use the open-source GNU C compiler ( gcc ) to compile our C programs on the \\TT{ecelinux} machines. We will experiment with both single-file C programs (simple but not representative of real C projects) and multi-file programs (more complex but also more realistic). In this tutorial, we will be running \\TT{gcc} directly from the command line so we can understand each step. In the next tutorial, we will see how we can use various tools to automate this process. All of the tools are installed and available on the ecelinux machines. This tutorial assumes that students have completed the tutorial on Linux and Git. We strongly recommend students also read Chapters 1-6 in the course text book, ``All of Programming,'' by A. Hilton and A. Bracy (2015). Chapters 5-6 are particularly relevant since they discuss the general process of compiling, testing, and debugging C programs. To follow along with the tutorial, access the course computing resources, and type the commands without the % character (for the bash prompt). In addition to working through the commands in the tutorial, you should also try the more open-ended tasks marked To-Do On Your Own . Before you begin, make sure that you have sourced the setup-ece2400.sh script or that you have added it to your .bashrc script, which will then source the script every time you login. Sourcing the setup script sets up the environment required for this class. You should start by forking the tutorial repository on GitHub. Go to the GitHub page for the tutorial repository located here: https://github.com/cornell-ece2400/ece2400-tut2-c-basics . Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a new repository in your account: https://github.com/githubid/ece2400-tut2-c-basics Where githubid is your GitHub username on github.com . Now access an ecelinux machine and clone your copy of the tutorial repository as follows: 1 2 3 4 5 6 % source setup-ece2400.sh % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone https://github.com/githubid/ece2400-tut3-c-basics.git tut3 % cd tut3 % TUTROOT = ${ PWD } Note It should be possible to experiment with this tutorial even if you are not enrolled in the course and/or do not have access to the course computing resources. All of the code for the tutorial is located on GitHub. You will not use the setup-ece2400.sh script, and your specific environment may be different from what is assumed in this tutorial. 1. Using the C Preprocessor Before we can understand how to write and compile C programs, we need to understand the C preprocessor. The preprocessor takes an input C source file, preprocesses it, and generates the preprocessed version of the C source file. It is important to realize that the C preprocesor is not really part of the C programming language. The C preprocessor simply manipulates the text in the C source files and knows nothing about the C programming language's syntax or semantics. The C preprocessor is powerful but also very easy to abuse. Using the C preprocessor can cause subtle bugs and is usually not necessary. Unfortunately, there are a few cases where we have no choice but to use the C preprocessor, so we must learn at least the basics. You can find out more about the C preprocessor here: http://en.cppreference.com/w/c/preprocessor https://en.wikibooks.org/wiki/C_Programming/Preprocessor 1.1. The #define Directive The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we are writing a report on the history of Cornell University, and we have a common snippet of text that we use often in our text file. text with many of same code define that mention ALL_CAPS define with argument try to avoid this -- will see it in our test macros 1.2. The #ifdef Directive 1.3. The #include Directive The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we wish to create a text file which lists pioneering women and men in the field of computer science. We might start with a text file of pioneering women: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation and a separate text file of pioneering men: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer These two files require some duplication, since both files include a short introductory paragraph. To avoid this redundancy, we can first refactor this introductory paragraph into its own dedicated text file, and we can then use the C processor to include this file at the beginning of each list of pioneers. This new approach is illustrated below. First, we have a file named cs-pioneers-intro.txt with the introductory paragraph. 1 2 3 4 5 6 7 8 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. Then, we have a file named cs-pioneers-women-in.txt containing a list of pioneering women in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation Finally, we have a file named cs-pioneers-men-in.txt containing a list of pioneering men in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer We can then use the C preprocessor to preprocess these files. The C preprocessor copies the input source file to the output source file, while also looking for C preprocessor directives . All C preprocessor directives begin with the special # character. Line 1 in cs-pioneers-women-in.txt and cs-pioneers-men-in.txt uses the #include directive which specifies the file name of a different text file to include. The file name should be be specified using double quotes ( \"\" ). You should have already cloned the tutorial repository and set the TUTROOT environment variable at the beginning of this tutorial. Let's make a new directory to work in for this section: 1 2 % mkdir ${ TUTROOT } /tut3-cpp % cd ${ TUTROOT } /tut3-cpp Now create the three text files mentioned above: cs-pioneers-intro.txt , cs-pioneers-women-in.txt , and cs-pioneers-men-in.txt using Geany or the text editor of your choice. See the first tutorial for more on using Geany or other text editors. The three files should be in the tut3-cpp subdirectory. All text files have a .txt filename extension. In general, we prefer using dashes ( - ) instead of underscores to separate words in file names. Let's use the C preprocessor ( cpp ) to preprocess the -in.txt files into two final text files that contain both the introductory paragraph and the list of pionners in computer science. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt The -o command line option is used to specify the name of the output file. The outpfile cs-pioneers-women.txt should look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 1 cs-pioneers-women-in.txt # 1 built-in # 1 command-line # 1 cs-pioneers-women-in.txt # 1 cs-pioneers-intro.txt 1 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. # 2 cs-pioneers-women-in.txt 2 - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation The C preprocessor included the introductory paragraph correctly, but it has also included some additional lines beginning with the # character to specify information about where all of the pieces of text originally came from. For example, Line 5 indicates that the introductory paragraph came from the cs-pioneers-intro.txt file. We can tell the cpp to not include this extra metadata with the -P command line option. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -P -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -P -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt This example illustrates the first way we will use the C preprocessor. We will use the #include directive to include common C source files in several of our own C source files. This approach avoids redundancy and makes our programs much easier to maintain since we can make changes in a single C source file, and those changes can be immediately reflected in any program which includes that C source file. We have actually already seen this use of the C preprocessor in the previous section when we included the \\TT{stdio.h} header file which includes the declaration of the \\TT{printf} function (see Line~1 in Figure~\\ref{fig-tut3-code-avg-main}). If the file in an \\verb|#include| directive is specified using angle brackets (\\TT{ }) then this tells the C preprocessor that the file to include is part of the system and is installed in a default location. If the given file is specified using double quotes (\\TT{\"\"}), then this tells the C preprocessor that the file to be included is part of the user program. The C preprocessor does not automatically know where to find extra user files, so we might need to add extra command line options to \\TT{cpp} to tell the C preprocessor where to search for files. 1.4. Include Guards 2. Writing a Single-File C Program 3. Compiling a Single-File C Program 4. Writing a Multi-File C Program 5. Compiling a Multi-File C Program","title":"Ece2400 tut2 c basics"},{"location":"ece2400-tut2-c-basics/#tutorial-2-compiling-and-running-c-programs","text":"The first few programming assignments for this course will use the C programming language. In lecture we use Compiler Explorer and Repl.it to quickly experiment with small C programs, but eventually we need to actually write and compile C programs on a real machine. This tutorial discusses how we can use the open-source GNU C compiler ( gcc ) to compile our C programs on the \\TT{ecelinux} machines. We will experiment with both single-file C programs (simple but not representative of real C projects) and multi-file programs (more complex but also more realistic). In this tutorial, we will be running \\TT{gcc} directly from the command line so we can understand each step. In the next tutorial, we will see how we can use various tools to automate this process. All of the tools are installed and available on the ecelinux machines. This tutorial assumes that students have completed the tutorial on Linux and Git. We strongly recommend students also read Chapters 1-6 in the course text book, ``All of Programming,'' by A. Hilton and A. Bracy (2015). Chapters 5-6 are particularly relevant since they discuss the general process of compiling, testing, and debugging C programs. To follow along with the tutorial, access the course computing resources, and type the commands without the % character (for the bash prompt). In addition to working through the commands in the tutorial, you should also try the more open-ended tasks marked To-Do On Your Own . Before you begin, make sure that you have sourced the setup-ece2400.sh script or that you have added it to your .bashrc script, which will then source the script every time you login. Sourcing the setup script sets up the environment required for this class. You should start by forking the tutorial repository on GitHub. Go to the GitHub page for the tutorial repository located here: https://github.com/cornell-ece2400/ece2400-tut2-c-basics . Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a new repository in your account: https://github.com/githubid/ece2400-tut2-c-basics Where githubid is your GitHub username on github.com . Now access an ecelinux machine and clone your copy of the tutorial repository as follows: 1 2 3 4 5 6 % source setup-ece2400.sh % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone https://github.com/githubid/ece2400-tut3-c-basics.git tut3 % cd tut3 % TUTROOT = ${ PWD } Note It should be possible to experiment with this tutorial even if you are not enrolled in the course and/or do not have access to the course computing resources. All of the code for the tutorial is located on GitHub. You will not use the setup-ece2400.sh script, and your specific environment may be different from what is assumed in this tutorial.","title":"Tutorial 2 : Compiling and Running C Programs"},{"location":"ece2400-tut2-c-basics/#1-using-the-c-preprocessor","text":"Before we can understand how to write and compile C programs, we need to understand the C preprocessor. The preprocessor takes an input C source file, preprocesses it, and generates the preprocessed version of the C source file. It is important to realize that the C preprocesor is not really part of the C programming language. The C preprocessor simply manipulates the text in the C source files and knows nothing about the C programming language's syntax or semantics. The C preprocessor is powerful but also very easy to abuse. Using the C preprocessor can cause subtle bugs and is usually not necessary. Unfortunately, there are a few cases where we have no choice but to use the C preprocessor, so we must learn at least the basics. You can find out more about the C preprocessor here: http://en.cppreference.com/w/c/preprocessor https://en.wikibooks.org/wiki/C_Programming/Preprocessor","title":"1. Using the C Preprocessor"},{"location":"ece2400-tut2-c-basics/#11-the-define-directive","text":"The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we are writing a report on the history of Cornell University, and we have a common snippet of text that we use often in our text file. text with many of same code define that mention ALL_CAPS define with argument try to avoid this -- will see it in our test macros","title":"1.1. The #define Directive"},{"location":"ece2400-tut2-c-basics/#12-the-ifdef-directive","text":"","title":"1.2. The #ifdef Directive"},{"location":"ece2400-tut2-c-basics/#13-the-include-directive","text":"The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we wish to create a text file which lists pioneering women and men in the field of computer science. We might start with a text file of pioneering women: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation and a separate text file of pioneering men: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer These two files require some duplication, since both files include a short introductory paragraph. To avoid this redundancy, we can first refactor this introductory paragraph into its own dedicated text file, and we can then use the C processor to include this file at the beginning of each list of pioneers. This new approach is illustrated below. First, we have a file named cs-pioneers-intro.txt with the introductory paragraph. 1 2 3 4 5 6 7 8 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. Then, we have a file named cs-pioneers-women-in.txt containing a list of pioneering women in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation Finally, we have a file named cs-pioneers-men-in.txt containing a list of pioneering men in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer We can then use the C preprocessor to preprocess these files. The C preprocessor copies the input source file to the output source file, while also looking for C preprocessor directives . All C preprocessor directives begin with the special # character. Line 1 in cs-pioneers-women-in.txt and cs-pioneers-men-in.txt uses the #include directive which specifies the file name of a different text file to include. The file name should be be specified using double quotes ( \"\" ). You should have already cloned the tutorial repository and set the TUTROOT environment variable at the beginning of this tutorial. Let's make a new directory to work in for this section: 1 2 % mkdir ${ TUTROOT } /tut3-cpp % cd ${ TUTROOT } /tut3-cpp Now create the three text files mentioned above: cs-pioneers-intro.txt , cs-pioneers-women-in.txt , and cs-pioneers-men-in.txt using Geany or the text editor of your choice. See the first tutorial for more on using Geany or other text editors. The three files should be in the tut3-cpp subdirectory. All text files have a .txt filename extension. In general, we prefer using dashes ( - ) instead of underscores to separate words in file names. Let's use the C preprocessor ( cpp ) to preprocess the -in.txt files into two final text files that contain both the introductory paragraph and the list of pionners in computer science. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt The -o command line option is used to specify the name of the output file. The outpfile cs-pioneers-women.txt should look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 1 cs-pioneers-women-in.txt # 1 built-in # 1 command-line # 1 cs-pioneers-women-in.txt # 1 cs-pioneers-intro.txt 1 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. # 2 cs-pioneers-women-in.txt 2 - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation The C preprocessor included the introductory paragraph correctly, but it has also included some additional lines beginning with the # character to specify information about where all of the pieces of text originally came from. For example, Line 5 indicates that the introductory paragraph came from the cs-pioneers-intro.txt file. We can tell the cpp to not include this extra metadata with the -P command line option. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -P -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -P -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt This example illustrates the first way we will use the C preprocessor. We will use the #include directive to include common C source files in several of our own C source files. This approach avoids redundancy and makes our programs much easier to maintain since we can make changes in a single C source file, and those changes can be immediately reflected in any program which includes that C source file. We have actually already seen this use of the C preprocessor in the previous section when we included the \\TT{stdio.h} header file which includes the declaration of the \\TT{printf} function (see Line~1 in Figure~\\ref{fig-tut3-code-avg-main}). If the file in an \\verb|#include| directive is specified using angle brackets (\\TT{ }) then this tells the C preprocessor that the file to include is part of the system and is installed in a default location. If the given file is specified using double quotes (\\TT{\"\"}), then this tells the C preprocessor that the file to be included is part of the user program. The C preprocessor does not automatically know where to find extra user files, so we might need to add extra command line options to \\TT{cpp} to tell the C preprocessor where to search for files.","title":"1.3. The #include Directive"},{"location":"ece2400-tut2-c-basics/#14-include-guards","text":"","title":"1.4. Include Guards"},{"location":"ece2400-tut2-c-basics/#2-writing-a-single-file-c-program","text":"","title":"2. Writing a Single-File C Program"},{"location":"ece2400-tut2-c-basics/#3-compiling-a-single-file-c-program","text":"","title":"3. Compiling a Single-File C Program"},{"location":"ece2400-tut2-c-basics/#4-writing-a-multi-file-c-program","text":"","title":"4. Writing a Multi-File C Program"},{"location":"ece2400-tut2-c-basics/#5-compiling-a-multi-file-c-program","text":"","title":"5. Compiling a Multi-File C Program"},{"location":"ece2400-tut3-c-basics/","text":"Tutorial 3 : Compiling and Running C Programs The first few programming assignments for this course will use the C programming language. In lecture we use Compiler Explorer and Repl.it to quickly experiment with small C programs, but eventually we need to actually write and compile C programs on a real machine. This tutorial discusses how we can use the open-source GNU C compiler ( gcc ) to compile our C programs on the \\TT{ecelinux} machines. We will experiment with both single-file C programs (simple but not representative of real C projects) and multi-file programs (more complex but also more realistic). In this tutorial, we will be running \\TT{gcc} directly from the command line so we can understand each step. In the next tutorial, we will see how we can use various tools to automate this process. All of the tools are installed and available on the ecelinux machines. This tutorial assumes that students have completed the tutorial on Linux and Git. We strongly recommend students also read Chapters 1-6 in the course text book, ``All of Programming,'' by A. Hilton and A. Bracy (2015). Chapters 5-6 are particularly relevant since they discuss the general process of compiling, testing, and debugging C programs. To follow along with the tutorial, access the course computing resources, and type the commands without the % character (for the bash prompt). In addition to working through the commands in the tutorial, you should also try the more open-ended tasks marked To-Do On Your Own . Before you begin, make sure that you have sourced the setup-ece2400.sh script or that you have added it to your .bashrc script, which will then source the script every time you login. Sourcing the setup script sets up the environment required for this class. You should start by forking the tutorial repository on GitHub. Go to the GitHub page for the tutorial repository located here: https://github.com/cornell-ece2400/ece2400-tut2-c-basics . Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a new repository in your account: https://github.com/githubid/ece2400-tut2-c-basics Where githubid is your GitHub username on github.com . Now access an ecelinux machine and clone your copy of the tutorial repository as follows: 1 2 3 4 5 6 % source setup-ece2400.sh % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone https://github.com/githubid/ece2400-tut3-c-basics.git tut3 % cd tut3 % TUTROOT = ${ PWD } Note It should be possible to experiment with this tutorial even if you are not enrolled in the course and/or do not have access to the course computing resources. All of the code for the tutorial is located on GitHub. You will not use the setup-ece2400.sh script, and your specific environment may be different from what is assumed in this tutorial. 1. Using the C Preprocessor Before we can understand how to write and compile C programs, we need to understand the C preprocessor. The preprocessor takes an input C source file, preprocesses it, and generates the preprocessed version of the C source file. It is important to realize that the C preprocesor is not really part of the C programming language. The C preprocessor simply manipulates the text in the C source files and knows nothing about the C programming language's syntax or semantics. The C preprocessor is powerful but also very easy to abuse. Using the C preprocessor can cause subtle bugs and is usually not necessary. Unfortunately, there are a few cases where we have no choice but to use the C preprocessor, so we must learn at least the basics. You can find out more about the C preprocessor here: http://en.cppreference.com/w/c/preprocessor https://en.wikibooks.org/wiki/C_Programming/Preprocessor 1.1. The #define Directive The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we are writing a report on the history of Cornell University, and we have a common snippet of text that we use often in our text file. text with many of same code define that mention ALL_CAPS define with argument try to avoid this -- will see it in our test macros 1.2. The #ifdef Directive 1.3. The #include Directive The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we wish to create a text file which lists pioneering women and men in the field of computer science. We might start with a text file of pioneering women: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation and a separate text file of pioneering men: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer These two files require some duplication, since both files include a short introductory paragraph. To avoid this redundancy, we can first refactor this introductory paragraph into its own dedicated text file, and we can then use the C processor to include this file at the beginning of each list of pioneers. This new approach is illustrated below. First, we have a file named cs-pioneers-intro.txt with the introductory paragraph. 1 2 3 4 5 6 7 8 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. Then, we have a file named cs-pioneers-women-in.txt containing a list of pioneering women in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation Finally, we have a file named cs-pioneers-men-in.txt containing a list of pioneering men in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer We can then use the C preprocessor to preprocess these files. The C preprocessor copies the input source file to the output source file, while also looking for C preprocessor directives . All C preprocessor directives begin with the special # character. Line 1 in cs-pioneers-women-in.txt and cs-pioneers-men-in.txt uses the #include directive which specifies the file name of a different text file to include. The file name should be be specified using double quotes ( \"\" ). You should have already cloned the tutorial repository and set the TUTROOT environment variable at the beginning of this tutorial. Let's make a new directory to work in for this section: 1 2 % mkdir ${ TUTROOT } /tut3-cpp % cd ${ TUTROOT } /tut3-cpp Now create the three text files mentioned above: cs-pioneers-intro.txt , cs-pioneers-women-in.txt , and cs-pioneers-men-in.txt using Geany or the text editor of your choice. See the first tutorial for more on using Geany or other text editors. The three files should be in the tut3-cpp subdirectory. All text files have a .txt filename extension. In general, we prefer using dashes ( - ) instead of underscores to separate words in file names. Let's use the C preprocessor ( cpp ) to preprocess the -in.txt files into two final text files that contain both the introductory paragraph and the list of pionners in computer science. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt The -o command line option is used to specify the name of the output file. The outpfile cs-pioneers-women.txt should look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 1 cs-pioneers-women-in.txt # 1 built-in # 1 command-line # 1 cs-pioneers-women-in.txt # 1 cs-pioneers-intro.txt 1 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. # 2 cs-pioneers-women-in.txt 2 - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation The C preprocessor included the introductory paragraph correctly, but it has also included some additional lines beginning with the # character to specify information about where all of the pieces of text originally came from. For example, Line 5 indicates that the introductory paragraph came from the cs-pioneers-intro.txt file. We can tell the cpp to not include this extra metadata with the -P command line option. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -P -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -P -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt This example illustrates the first way we will use the C preprocessor. We will use the #include directive to include common C source files in several of our own C source files. This approach avoids redundancy and makes our programs much easier to maintain since we can make changes in a single C source file, and those changes can be immediately reflected in any program which includes that C source file. We have actually already seen this use of the C preprocessor in the previous section when we included the \\TT{stdio.h} header file which includes the declaration of the \\TT{printf} function (see Line~1 in Figure~\\ref{fig-tut3-code-avg-main}). If the file in an \\verb|#include| directive is specified using angle brackets (\\TT{ }) then this tells the C preprocessor that the file to include is part of the system and is installed in a default location. If the given file is specified using double quotes (\\TT{\"\"}), then this tells the C preprocessor that the file to be included is part of the user program. The C preprocessor does not automatically know where to find extra user files, so we might need to add extra command line options to \\TT{cpp} to tell the C preprocessor where to search for files. 1.4. Include Guards 2. Writing a Single-File C Program 3. Compiling a Single-File C Program 4. Writing a Multi-File C Program 5. Compiling a Multi-File C Program","title":"Ece2400 tut3 c basics"},{"location":"ece2400-tut3-c-basics/#tutorial-3-compiling-and-running-c-programs","text":"The first few programming assignments for this course will use the C programming language. In lecture we use Compiler Explorer and Repl.it to quickly experiment with small C programs, but eventually we need to actually write and compile C programs on a real machine. This tutorial discusses how we can use the open-source GNU C compiler ( gcc ) to compile our C programs on the \\TT{ecelinux} machines. We will experiment with both single-file C programs (simple but not representative of real C projects) and multi-file programs (more complex but also more realistic). In this tutorial, we will be running \\TT{gcc} directly from the command line so we can understand each step. In the next tutorial, we will see how we can use various tools to automate this process. All of the tools are installed and available on the ecelinux machines. This tutorial assumes that students have completed the tutorial on Linux and Git. We strongly recommend students also read Chapters 1-6 in the course text book, ``All of Programming,'' by A. Hilton and A. Bracy (2015). Chapters 5-6 are particularly relevant since they discuss the general process of compiling, testing, and debugging C programs. To follow along with the tutorial, access the course computing resources, and type the commands without the % character (for the bash prompt). In addition to working through the commands in the tutorial, you should also try the more open-ended tasks marked To-Do On Your Own . Before you begin, make sure that you have sourced the setup-ece2400.sh script or that you have added it to your .bashrc script, which will then source the script every time you login. Sourcing the setup script sets up the environment required for this class. You should start by forking the tutorial repository on GitHub. Go to the GitHub page for the tutorial repository located here: https://github.com/cornell-ece2400/ece2400-tut2-c-basics . Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a new repository in your account: https://github.com/githubid/ece2400-tut2-c-basics Where githubid is your GitHub username on github.com . Now access an ecelinux machine and clone your copy of the tutorial repository as follows: 1 2 3 4 5 6 % source setup-ece2400.sh % mkdir -p ${ HOME } /ece2400 % cd ${ HOME } /ece2400 % git clone https://github.com/githubid/ece2400-tut3-c-basics.git tut3 % cd tut3 % TUTROOT = ${ PWD } Note It should be possible to experiment with this tutorial even if you are not enrolled in the course and/or do not have access to the course computing resources. All of the code for the tutorial is located on GitHub. You will not use the setup-ece2400.sh script, and your specific environment may be different from what is assumed in this tutorial.","title":"Tutorial 3 : Compiling and Running C Programs"},{"location":"ece2400-tut3-c-basics/#1-using-the-c-preprocessor","text":"Before we can understand how to write and compile C programs, we need to understand the C preprocessor. The preprocessor takes an input C source file, preprocesses it, and generates the preprocessed version of the C source file. It is important to realize that the C preprocesor is not really part of the C programming language. The C preprocessor simply manipulates the text in the C source files and knows nothing about the C programming language's syntax or semantics. The C preprocessor is powerful but also very easy to abuse. Using the C preprocessor can cause subtle bugs and is usually not necessary. Unfortunately, there are a few cases where we have no choice but to use the C preprocessor, so we must learn at least the basics. You can find out more about the C preprocessor here: http://en.cppreference.com/w/c/preprocessor https://en.wikibooks.org/wiki/C_Programming/Preprocessor","title":"1. Using the C Preprocessor"},{"location":"ece2400-tut3-c-basics/#11-the-define-directive","text":"The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we are writing a report on the history of Cornell University, and we have a common snippet of text that we use often in our text file. text with many of same code define that mention ALL_CAPS define with argument try to avoid this -- will see it in our test macros","title":"1.1. The #define Directive"},{"location":"ece2400-tut3-c-basics/#12-the-ifdef-directive","text":"","title":"1.2. The #ifdef Directive"},{"location":"ece2400-tut3-c-basics/#13-the-include-directive","text":"The best way to understand the C preprocessor is actually to use it to preprocess standard text files as opposed to C source files. Assume we wish to create a text file which lists pioneering women and men in the field of computer science. We might start with a text file of pioneering women: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation and a separate text file of pioneering men: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer These two files require some duplication, since both files include a short introductory paragraph. To avoid this redundancy, we can first refactor this introductory paragraph into its own dedicated text file, and we can then use the C processor to include this file at the beginning of each list of pioneers. This new approach is illustrated below. First, we have a file named cs-pioneers-intro.txt with the introductory paragraph. 1 2 3 4 5 6 7 8 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. Then, we have a file named cs-pioneers-women-in.txt containing a list of pioneering women in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation Finally, we have a file named cs-pioneers-men-in.txt containing a list of pioneering men in computer science: 1 2 3 4 5 6 7 8 9 #include cs-pioneers-intro.txt - Donald Knuth : fundamental contributions to algorithm analysis - John Mauchly : designed and built first modern computer - J. Presper Eckert : designed and built first modern computer - John Von Neumann : formulated the von Neumann architecture - Maurice Wilkes : built first practical stored program computer - Alan Turing : invented Turning model, stored program concept - Charles Babbage : originated concept of programmable computer We can then use the C preprocessor to preprocess these files. The C preprocessor copies the input source file to the output source file, while also looking for C preprocessor directives . All C preprocessor directives begin with the special # character. Line 1 in cs-pioneers-women-in.txt and cs-pioneers-men-in.txt uses the #include directive which specifies the file name of a different text file to include. The file name should be be specified using double quotes ( \"\" ). You should have already cloned the tutorial repository and set the TUTROOT environment variable at the beginning of this tutorial. Let's make a new directory to work in for this section: 1 2 % mkdir ${ TUTROOT } /tut3-cpp % cd ${ TUTROOT } /tut3-cpp Now create the three text files mentioned above: cs-pioneers-intro.txt , cs-pioneers-women-in.txt , and cs-pioneers-men-in.txt using Geany or the text editor of your choice. See the first tutorial for more on using Geany or other text editors. The three files should be in the tut3-cpp subdirectory. All text files have a .txt filename extension. In general, we prefer using dashes ( - ) instead of underscores to separate words in file names. Let's use the C preprocessor ( cpp ) to preprocess the -in.txt files into two final text files that contain both the introductory paragraph and the list of pionners in computer science. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt The -o command line option is used to specify the name of the output file. The outpfile cs-pioneers-women.txt should look like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 1 cs-pioneers-women-in.txt # 1 built-in # 1 command-line # 1 cs-pioneers-women-in.txt # 1 cs-pioneers-intro.txt 1 ========================================================================== Pioneers in Computer Science ========================================================================== Computer science is a relatively recent field which focuses on the theory, experimentation, and engineering that form the basis for the design and use of computers. Here is a very small subset of the many individuals who helped in the creation, development, and imagining of what computers and electronics could do. # 2 cs-pioneers-women-in.txt 2 - Eva Tardos : fundamental contributions to algorithm analysis - Mary Jane Irwin : early work on design automation and computer arch - Barbara Liskov : fundamental contributions to obj-oriented progr - Frances Allen : pioneer in optimizing compilers - Grace Hopper : pioneer in computer prog and high-level languages - Jean Bartik : one of the first computer programmers - Ada Lovelace : began the study of scientific computation The C preprocessor included the introductory paragraph correctly, but it has also included some additional lines beginning with the # character to specify information about where all of the pieces of text originally came from. For example, Line 5 indicates that the introductory paragraph came from the cs-pioneers-intro.txt file. We can tell the cpp to not include this extra metadata with the -P command line option. 1 2 3 4 5 % cd ${ TUTROOT } /tut3-cpp % cpp -P -o cs-pioneers-women.txt cs-pioneers-women-in.txt % cat cs-pioneers-women.txt % cpp -P -o cs-pioneers-men.txt cs-pioneers-men-in.txt % cat cs-pioneers-men.txt This example illustrates the first way we will use the C preprocessor. We will use the #include directive to include common C source files in several of our own C source files. This approach avoids redundancy and makes our programs much easier to maintain since we can make changes in a single C source file, and those changes can be immediately reflected in any program which includes that C source file. We have actually already seen this use of the C preprocessor in the previous section when we included the \\TT{stdio.h} header file which includes the declaration of the \\TT{printf} function (see Line~1 in Figure~\\ref{fig-tut3-code-avg-main}). If the file in an \\verb|#include| directive is specified using angle brackets (\\TT{ }) then this tells the C preprocessor that the file to include is part of the system and is installed in a default location. If the given file is specified using double quotes (\\TT{\"\"}), then this tells the C preprocessor that the file to be included is part of the user program. The C preprocessor does not automatically know where to find extra user files, so we might need to add extra command line options to \\TT{cpp} to tell the C preprocessor where to search for files.","title":"1.3. The #include Directive"},{"location":"ece2400-tut3-c-basics/#14-include-guards","text":"","title":"1.4. Include Guards"},{"location":"ece2400-tut3-c-basics/#2-writing-a-single-file-c-program","text":"","title":"2. Writing a Single-File C Program"},{"location":"ece2400-tut3-c-basics/#3-compiling-a-single-file-c-program","text":"","title":"3. Compiling a Single-File C Program"},{"location":"ece2400-tut3-c-basics/#4-writing-a-multi-file-c-program","text":"","title":"4. Writing a Multi-File C Program"},{"location":"ece2400-tut3-c-basics/#5-compiling-a-multi-file-c-program","text":"","title":"5. Compiling a Multi-File C Program"}]}